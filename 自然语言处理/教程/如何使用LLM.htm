<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:dt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=OneNote.File>
<meta name=Generator content="Microsoft OneNote 15">
<link id=Main-File rel=Main-File href=如何使用LLM.htm>
<link rel=File-List href="如何使用LLM.files/filelist.xml">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:36.0pt'>

<div style='direction:ltr;border-width:100%'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:34.5548in'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:2.2027in'>

<p style='margin:0in;font-family:微软雅黑;font-size:20.0pt'><span lang=zh-CN>如何使用</span><span
lang=en-US>LLM</span></p>

</div>

<div style='direction:ltr;margin-top:.0423in;margin-left:0in;width:1.6687in'>

<p style='margin:0in;font-size:10.0pt;color:#767676'><span style='font-family:
Calibri'>2025</span><span style='font-family:微软雅黑'>年</span><span
style='font-family:Calibri'>7</span><span style='font-family:微软雅黑'>月</span><span
style='font-family:Calibri'>13</span><span style='font-family:微软雅黑'>日</span></p>

<p style='margin:0in;font-family:Calibri;font-size:10.0pt;color:#767676'>15:44</p>

</div>

<div style='direction:ltr;margin-top:.7444in;margin-left:.4326in;width:21.2465in'>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span style='font-weight:
bold' lang=zh-CN>后训练，</span><span style='font-weight:bold' lang=en-US>SFT RLHF
RL</span><span style='font-weight:bold' lang=zh-CN>是让模型获得个性化助手</span><span
style='font-weight:bold' lang=en-US>persona</span><span style='font-weight:
bold' lang=zh-CN>的地方。</span><span style='font-weight:bold' lang=en-US>LLM</span><span
style='font-weight:bold' lang=zh-CN>的知识来源于预训练。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'>&nbsp;</p>

</div>

<div style='direction:ltr;margin-top:.1319in;margin-left:.1951in;width:34.3597in'><nobr><img
src="如何使用LLM.files/image001.png" width=2880 height=1440
alt="未命名图片.jpg 计算机生成了可选文字:&#10;LargeLanguageModel(LLM)～=ITBlossy,probabilistic&quot;zip而尾oftheinternet&quot;&#10;(parametersstoreworldknowledge,thoughusuallyoutOfdateby、fewmonths)&#10;。HiIamChatGPT。&#10;Iam01terabyte2土pfile．&#10;MyknowledgeC鲡eSfromtheinternet，&#10;whichIread～5months0g0andremember&#10;onlyvaguely．&#10;Mywinningpersonalitywasprogrammed,&#10;byexample，byhumanlabelersatOpenAI&#10;pre-training:、910M，3monthsOftrainingoninternetdocuments&#10;post-training:muchmuchcheaperfinetuningwithSFT，RLHFonConversations&#10;ReinforcementLearning(RL)&#10;T00[use&#10;ZIP&#10;internet&#10;'deep&#10;巧&#10;0&#10;tokens&#10;（https://tiktokenizer.vercel.app/》&#10;copypaste&#10;User&#10;QuiofLifefeatures&#10;-Cl-matGM-memory&#10;-Cust0M%nstructions&#10;-Cust0MGPI-s&#10;pytkon&#10;cÅatGFT;」丷nee心。tAnalysis&#10;interpreter&#10;cl艹巳ÅrtGcts&#10;(i.e.computer&#10;Cursor;COMPOSer&#10;prosrams)&#10;contextwindow&#10;Modi骯&#10;-u女。input(Superwksper,WisprFlow,Nacwksper,etc.)&#10;-u女。output〈usuallyapp)&#10;-True」u。tke乙乙&#10;-Podcast&amp;interaction@。t硅。。嶷L凹）&#10;-'&quot;put(see,OCaskagout...)&#10;-工灬output@ÅLL-E)&#10;-Videoinput艹Voice+。）&#10;-Videooutput(Sora'otÅers)&#10;孬0&#10;000河0@0000&#10;00包000也00&#10;0到0@000一&#13;&#10;"><img
src="如何使用LLM.files/image002.png" width=2068 height=1440
alt="未命名图片.jpg 计算机生成了可选文字:&#10;LargeLanguageModel(LLM)～=ITBlossy,probabilistic&quot;zip而尾oftheinternet&quot;&#10;(parametersstoreworldknowledge,thoughusuallyoutOfdateby、fewmonths)&#10;。HiIamChatGPT。&#10;Iam01terabyte2土pfile．&#10;MyknowledgeC鲡eSfromtheinternet，&#10;whichIread～5months0g0andremember&#10;onlyvaguely．&#10;Mywinningpersonalitywasprogrammed,&#10;byexample，byhumanlabelersatOpenAI&#10;pre-training:、910M，3monthsOftrainingoninternetdocuments&#10;post-training:muchmuchcheaperfinetuningwithSFT，RLHFonConversations&#10;ReinforcementLearning(RL)&#10;T00[use&#10;ZIP&#10;internet&#10;'deep&#10;巧&#10;0&#10;tokens&#10;（https://tiktokenizer.vercel.app/》&#10;copypaste&#10;User&#10;QuiofLifefeatures&#10;-Cl-matGM-memory&#10;-Cust0M%nstructions&#10;-Cust0MGPI-s&#10;pytkon&#10;cÅatGFT;」丷nee心。tAnalysis&#10;interpreter&#10;cl艹巳ÅrtGcts&#10;(i.e.computer&#10;Cursor;COMPOSer&#10;prosrams)&#10;contextwindow&#10;Modi骯&#10;-u女。input(Superwksper,WisprFlow,Nacwksper,etc.)&#10;-u女。output〈usuallyapp)&#10;-True」u。tke乙乙&#10;-Podcast&amp;interaction@。t硅。。嶷L凹）&#10;-'&quot;put(see,OCaskagout...)&#10;-工灬output@ÅLL-E)&#10;-Videoinput艹Voice+。）&#10;-Videooutput(Sora'otÅers)&#10;孬0&#10;000河0@0000&#10;00包000也00&#10;0到0@000一&#13;&#10;"><br>
<img src="如何使用LLM.files/image003.png" width=2880 height=1440
alt="未命名图片.jpg 计算机生成了可选文字:&#10;LargeLanguageModel(LLM)～=ITBlossy,probabilistic&quot;zip而尾oftheinternet&quot;&#10;(parametersstoreworldknowledge,thoughusuallyoutOfdateby、fewmonths)&#10;。HiIamChatGPT。&#10;Iam01terabyte2土pfile．&#10;MyknowledgeC鲡eSfromtheinternet，&#10;whichIread～5months0g0andremember&#10;onlyvaguely．&#10;Mywinningpersonalitywasprogrammed,&#10;byexample，byhumanlabelersatOpenAI&#10;pre-training:、910M，3monthsOftrainingoninternetdocuments&#10;post-training:muchmuchcheaperfinetuningwithSFT，RLHFonConversations&#10;ReinforcementLearning(RL)&#10;T00[use&#10;ZIP&#10;internet&#10;'deep&#10;巧&#10;0&#10;tokens&#10;（https://tiktokenizer.vercel.app/》&#10;copypaste&#10;User&#10;QuiofLifefeatures&#10;-Cl-matGM-memory&#10;-Cust0M%nstructions&#10;-Cust0MGPI-s&#10;pytkon&#10;cÅatGFT;」丷nee心。tAnalysis&#10;interpreter&#10;cl艹巳ÅrtGcts&#10;(i.e.computer&#10;Cursor;COMPOSer&#10;prosrams)&#10;contextwindow&#10;Modi骯&#10;-u女。input(Superwksper,WisprFlow,Nacwksper,etc.)&#10;-u女。output〈usuallyapp)&#10;-True」u。tke乙乙&#10;-Podcast&amp;interaction@。t硅。。嶷L凹）&#10;-'&quot;put(see,OCaskagout...)&#10;-工灬output@ÅLL-E)&#10;-Videoinput艹Voice+。）&#10;-Videooutput(Sora'otÅers)&#10;孬0&#10;000河0@0000&#10;00包000也00&#10;0到0@000一&#13;&#10;&#13;&#10;&#13;&#10;thinking model，在需要解决困难的问题时使用，简单的问题不需要使用，太慢且没有必要。&#13;&#10;&#13;&#10;LLM可以看作是一个压缩文件，是封闭的，需要赋予它使用tools的能力。最常用的tool是web search，有的模型会自动检测是否需要进行web search，有的大模型需要用户手动指定开启web search。&#13;&#10;"><img
src="如何使用LLM.files/image004.png" width=2068 height=1440
alt="未命名图片.jpg 计算机生成了可选文字:&#10;LargeLanguageModel(LLM)～=ITBlossy,probabilistic&quot;zip而尾oftheinternet&quot;&#10;(parametersstoreworldknowledge,thoughusuallyoutOfdateby、fewmonths)&#10;。HiIamChatGPT。&#10;Iam01terabyte2土pfile．&#10;MyknowledgeC鲡eSfromtheinternet，&#10;whichIread～5months0g0andremember&#10;onlyvaguely．&#10;Mywinningpersonalitywasprogrammed,&#10;byexample，byhumanlabelersatOpenAI&#10;pre-training:、910M，3monthsOftrainingoninternetdocuments&#10;post-training:muchmuchcheaperfinetuningwithSFT，RLHFonConversations&#10;ReinforcementLearning(RL)&#10;T00[use&#10;ZIP&#10;internet&#10;'deep&#10;巧&#10;0&#10;tokens&#10;（https://tiktokenizer.vercel.app/》&#10;copypaste&#10;User&#10;QuiofLifefeatures&#10;-Cl-matGM-memory&#10;-Cust0M%nstructions&#10;-Cust0MGPI-s&#10;pytkon&#10;cÅatGFT;」丷nee心。tAnalysis&#10;interpreter&#10;cl艹巳ÅrtGcts&#10;(i.e.computer&#10;Cursor;COMPOSer&#10;prosrams)&#10;contextwindow&#10;Modi骯&#10;-u女。input(Superwksper,WisprFlow,Nacwksper,etc.)&#10;-u女。output〈usuallyapp)&#10;-True」u。tke乙乙&#10;-Podcast&amp;interaction@。t硅。。嶷L凹）&#10;-'&quot;put(see,OCaskagout...)&#10;-工灬output@ÅLL-E)&#10;-Videoinput艹Voice+。）&#10;-Videooutput(Sora'otÅers)&#10;孬0&#10;000河0@0000&#10;00包000也00&#10;0到0@000一&#13;&#10;thinking model，在需要解决困难的问题时使用，简单的问题不需要使用，太慢且没有必要。&#13;&#10;LLM可以看作是一个压缩文件，是封闭的，需要赋予它使用tools的能力。最常用的tool是web search，有的模型会自动检测是否需要进行web search，有的大模型需要用户手动指定开启web search。&#13;&#10;"><br>
<img src="如何使用LLM.files/image005.png" width=2880 height=1440
alt="LLM可以看作是一个压缩文件，是封闭的，需要赋予它使用tools的能力。最常用的tool是web search，有的模型会自动检测是否需要进行web search，有的大模型需要用户手动指定开启web search。&#13;&#10;&#13;&#10;deep research。基本上是web search +thinking。&#13;&#10;&#13;&#10;在context window中可以上传文件，如pdf文件，本质上将pdf转成文本，输入到context window中。&#13;&#10;&#13;&#10;Openai训练了chatgpt，以判断在什么情况下使用tools，通过示例（训练数据）教会了chatgpt使用tools，so human labelers are involved in curating datasets that tell the model by example in what kinds of situations it should use on tools and how to use tools。&#13;&#10;&#13;&#10;一些其他功能，如chatgpt的数据分析，作图。claude的artifacts，生成网页react组件构建app、思维导图等。&#13;&#10;&#13;&#10;"><img
src="如何使用LLM.files/image006.png" width=2068 height=1440
alt="LLM可以看作是一个压缩文件，是封闭的，需要赋予它使用tools的能力。最常用的tool是web search，有的模型会自动检测是否需要进行web search，有的大模型需要用户手动指定开启web search。&#13;&#10;在context window中可以上传文件，如pdf文件，本质上将pdf转成文本，输入到context window中。&#13;&#10;Openai训练了chatgpt，以判断在什么情况下使用tools，通过示例（训练数据）教会了chatgpt使用tools，so human labelers are involved in curating datasets that tell the model by example in what kinds of situations it should use on tools and how to use tools。&#13;&#10;一些其他功能，如chatgpt的数据分析，作图。claude的artifacts，生成网页react组件构建app、思维导图等。&#13;&#10;"><br>
<img src="如何使用LLM.files/image007.png" width=2880 height=1373
alt="&#13;&#10;使用chatgpt或deepseek写代码的问题是，无法获取到你代码文件的context，写写单独的一个函数还可以。&#13;&#10;Cursor，可以获取到文件系统 ，也就是拥有你项目目录中所有文件的上下文。&#13;&#10;Cursor的composer 功能，可以从0创建整个项目，就像一个自主的agent来管理你的代码库，它可以执行命令，根据需要更改所有文件，跨多个文件进行编辑，你所做的只有发布命令，告诉它该做什么，就像产品经理一样。&#13;&#10;&#13;&#10;Google的notebooklm，可以将一个文件pdf或网页等，生成podcast。这个很有意思 。可以将你懒得看的文件，转成podcast的形式听。&#13;&#10;&#13;&#10;当创建新聊天时，上下文会被清空，chatgpt可以使用memory功能，跨对话框记住一些东西。memory会 被添加到所有对话中.&#13;&#10;&#13;&#10;&#13;&#10;使用few shot prompt，通常总是好的，相比于zero shot。&#13;&#10;"><img
src="如何使用LLM.files/image008.png" width=2068 height=1373
alt="使用chatgpt或deepseek写代码的问题是，无法获取到你代码文件的context，写写单独的一个函数还可以。&#13;&#10;Cursor的composer 功能，可以从0创建整个项目，就像一个自主的agent来管理你的代码库，它可以执行命令，根据需要更改所有文件，跨多个文件进行编辑，你所做的只有发布命令，告诉它该做什么，就像产品经理一样。&#13;&#10;Google的notebooklm，可以将一个文件pdf或网页等，生成podcast。这个很有意思 。可以将你懒得看的文件，转成podcast的形式听。&#13;&#10;当创建新聊天时，上下文会被清空，chatgpt可以使用memory功能，跨对话框记住一些东西。memory会 被添加到所有对话中.&#13;&#10;"><br>
</nobr></div>

</div>

</div>

<div>

<p style='margin:0in'>&nbsp;</p>

<p style='text-align:left;margin:0in;font-family:Arial;font-size:9pt;
color:#969696;direction:ltr'>已使用 OneNote 创建。</p>

</div>

</body>

</html>
