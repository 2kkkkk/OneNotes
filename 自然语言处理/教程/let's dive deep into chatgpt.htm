<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:dt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=OneNote.File>
<meta name=Generator content="Microsoft OneNote 15">
<link id=Main-File rel=Main-File href="let's%20dive%20deep%20into%20chatgpt.htm">
<link rel=File-List
href="let's%20dive%20deep%20into%20chatgpt.files/filelist.xml">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:12.0pt'>

<div style='direction:ltr;border-width:100%'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:13.1291in'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:3.593in'>

<p style='margin:0in;font-size:20.0pt'><span style='font-family:"Calibri Light"'
lang=zh-CN>let's</span><span style='font-family:Calibri' lang=en-US> dive deep
into chatgpt</span></p>

</div>

<div style='direction:ltr;margin-top:.0423in;margin-left:0in;width:2.0562in'>

<p style='margin:0in;font-size:10.0pt;color:#767676'><span style='font-family:
Calibri'>2025</span><span style='font-family:"Microsoft YaHei"'>年</span><span
style='font-family:Calibri'>7</span><span style='font-family:"Microsoft YaHei"'>月</span><span
style='font-family:Calibri'>6</span><span style='font-family:"Microsoft YaHei"'>日
星期日</span></p>

<p style='margin:0in;font-family:Calibri;font-size:10.0pt;color:#767676'>16:59</p>

</div>

<div style='direction:ltr;margin-top:.2847in;margin-left:.4597in;width:12.6694in'>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt' lang=yo>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=en-US>1.</span><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>对于</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>base</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>模型来说，</span><span style='font-family:微软雅黑'
lang=zh-CN>如果输入</span><span style='font-family:Calibri' lang=en-US>wikipieda</span><span
style='font-family:微软雅黑' lang=zh-CN>上某个词条的前几句话，</span><span style='font-family:
Calibri' lang=en-US>base model</span><span style='font-family:微软雅黑' lang=zh-CN>很可能完全复述</span><span
style='font-family:Calibri' lang=en-US>wikipieda</span><span style='font-family:
微软雅黑' lang=zh-CN>上的内容，因为可能在这个</span><span style='font-family:Calibri'
lang=en-US>wiki</span><span style='font-family:微软雅黑' lang=zh-CN>上训练了</span><span
style='font-family:Calibri' lang=en-US>10</span><span style='font-family:微软雅黑'
lang=zh-CN>个</span><span style='font-family:Calibri' lang=en-US>epoch</span><span
style='font-family:微软雅黑' lang=zh-CN>，</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>就像读了</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>10</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>遍，</span><span style='font-weight:bold;font-family:
Calibri' lang=en-US>base</span><span style='font-weight:bold;font-family:微软雅黑'
lang=zh-CN>模型直接把这篇文章背诵下来了。</span></p>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-family:Calibri'
lang=en-US>base</span><span style='font-family:微软雅黑' lang=zh-CN>模型是一个</span><span
style='font-family:Calibri' lang=en-US>token</span><span style='font-family:
微软雅黑' lang=zh-CN>补全器，而我们需要的是助手，所以需要进行</span><span style='font-family:Calibri'
lang=en-US>SFT</span><span style='font-family:微软雅黑' lang=zh-CN>。</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Calibri' lang=en-US>2.</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>关于大模型的幻觉：</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>模型将学到的知识存储在模型的参数中，可以把这</span><span style='font-family:Calibri'
lang=en-US>405B</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>（以lamma</span><span
style='font-family:"Microsoft YaHei"' lang=en-US> 3为例</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>）</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>个参数视为对互联网的压缩</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，这种压缩当然是有损的，大模型生成的内容仅仅是对互联网的一些回忆，所以，互联网数据中经常出现的内容，可能会被更容易记住，不能完全相信生成的内容，以为这</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>只是对互联网文档的模糊回忆，这些内容是概率性的，统计性的。模型只是按照概率进行最佳推测。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'>即大模型捏造信息。</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold'>为什么会有幻觉，幻觉是从哪来的？</span></p>

<p style='margin:0in;margin-left:.75in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image001.jpg" width=640
height=365></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
lang=zh-CN>模型在统计上模仿训练集，比如训练集中有如上图所示的</span><span lang=en-US>3</span><span
lang=zh-CN>条数据，并自信地回答了正确答案，当推理时被问一个新的不存在的人物时，</span><span style='font-weight:
bold' lang=zh-CN>模型会模仿这种回答</span><span lang=zh-CN>，并给出统计上的最佳推测，结果就是编造信息。</span><span
style='font-weight:bold' lang=zh-CN>也就是，模型并不会表达出自己不知道，而是尽力模仿训练集，从而进行编造。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold'>如何缓解？</span></p>

<p style='margin:0in;margin-left:.75in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image002.jpg" width=828
height=477></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'
lang=en-US>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>1</span><span style='font-weight:bold'
lang=zh-CN>）</span><span lang=zh-CN>在训练集中包含新的示例数据，当模型不知道示例的答案时，这些数据的答案是不知道，从而让模型能够表达出自己不知道这件事，而不是胡编乱造。现在的问题是，如何知道模型不知道这个问题的答案？</span><span
lang=en-US>M</span><span lang=zh-CN>eta</span><span lang=en-US> LLAMA3</span><span
lang=zh-CN>的做法是进行</span><span lang=en-US>knowledge probe</span><span
lang=zh-CN>，从训练集中采样一段文字，让另一个</span><span lang=en-US>LLM</span><span lang=zh-CN>生成关于这段文字的几个</span><span
lang=en-US>QA pair</span><span lang=zh-CN>，用这几个</span><span lang=en-US>QA</span><span
lang=zh-CN>向</span><span lang=en-US>LLM</span><span lang=zh-CN>提问，用</span><span
lang=en-US>llm as judge</span><span lang=zh-CN>进行打分，重复多次，如果</span><span
lang=en-US>LLM</span><span lang=zh-CN>不知道这个答案，那么就构造一条新的数据，</span><span
lang=en-US>Q</span><span lang=zh-CN>不变，</span><span lang=en-US>A</span><span
lang=zh-CN>是</span><span lang=en-US>I don’t kno</span><span lang=zh-CN>w</span><span
lang=en-US> </span><span lang=zh-CN>等类似的</span><span lang=en-US>refusal</span><span
lang=zh-CN>回答。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.75in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image003.jpg" width=1036
height=358></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'
lang=en-US>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>2</span><span style='font-weight:bold'
lang=zh-CN>）</span><span lang=zh-CN>让</span><span lang=en-US>LLM</span><span
lang=zh-CN>可以使用</span><span lang=en-US>tools</span><span lang=zh-CN>，可以创造一个机制，使</span><span
lang=en-US>LLM</span><span lang=zh-CN>能够生成特殊的</span><span lang=en-US>token</span><span
lang=zh-CN>，</span><span lang=en-US>&lt;search_start&gt; &lt;search_end&gt;</span><span
lang=zh-CN>，当模型发出这个</span><span lang=en-US>token</span><span lang=zh-CN>时，会停止后续生成，并进行网络搜索，然后将检索到的文本返回给模型，拼接到</span><span
lang=en-US>context window</span><span lang=zh-CN>中，然后继续生成</span><span
style='font-weight:bold' lang=zh-CN>。</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>现在的问题是，如何教会模型发出使用这种</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>tool</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>token</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>呢，还是通过在训练集中构建几千几万个这种数据来训练模型。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>总结：当我们问</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>某个问题时，如果</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>对它的权重</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US> </span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>、参数、激活值等有足够的信心，认为这个问题的答案可以从记忆中检索，它会直接生成答案。如果它不确定，就会使用网络搜索。对于</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>user</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>来说，要对自己问的问题有一个大致的判断，</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US> </span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>这个问题是否是很清晰地容易回答的，是否能让</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>LLM</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>仅通过本身几百</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>B</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>的参数（对互联网的模糊记忆）就能正确回答的，如果不是，要进行网络搜索，来确保答案的正确性。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.75in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image004.jpg" width=1066
height=152></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>神经网络的参数是一种模糊的回忆，而上下文窗口是模型的工作记忆，和人类类似。上下文的数据可以被模型直接访问，它直接输入到神经网络中，而不是模糊的记忆。这对我们使用</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>LLM</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>也有帮助，例如，问</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>LLM</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>，</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US> can you summarize
chapter1 of Pride and Prejudice? LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>可以很好地回答，因为</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>看过傲慢与偏见，</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>有足够的记忆。但是比起让</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>LLM</span><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>回忆，更有效的方式是直接提供给他们信息，将第一章的内容也输入到上下文窗口中，这样</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>LLM</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>可以直接访问他们，而不需要回忆。</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>LLM</span><span
style='font-weight:bold;font-family:微软雅黑' lang=zh-CN>回答的质量也会显著提高。（这和人类一样，在总结之间重新阅读了文章，会做得更好。）</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Calibri' lang=en-US>3.</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>后训练，用人类标注的多轮对话进行</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>SFT</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US>&nbsp;</p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image005.jpg" width=1098
height=534></p>

<p style='margin:0in;margin-left:4.5in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold' lang=en-US><span style='mso-spacerun:yes'> </span></span><span
lang=en-US>openai</span><span lang=zh-CN>的</span><span lang=en-US>InstructGPT</span><span
lang=zh-CN>，雇了几十个外包人员</span><span lang=en-US>labelers</span><span lang=zh-CN>，生成多轮对话的数据集，生成的原则大概是</span><span
lang=en-US>1)helpful</span><span lang=zh-CN>，</span><span lang=en-US>2</span><span
lang=zh-CN>）</span><span lang=en-US>truthful, 3)harmless</span><span
lang=zh-CN>，</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=en-US><span
style='mso-spacerun:yes'> </span></span><span lang=zh-CN>这些对话数据集当然无法</span><span
lang=en-US>cover</span><span lang=zh-CN>所有的</span><span lang=en-US>prompt</span><span
lang=zh-CN>，</span><span style='font-weight:bold' lang=zh-CN>但是模型经过这样的</span><span
style='font-weight:bold' lang=en-US>helpful</span><span style='font-weight:
bold' lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>truthful</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>harmless</span><span style='font-weight:bold' lang=zh-CN>数据集训练之后，模型就会开始表现出这种类似的乐于助人、真实、无害的助手个性</span><span
style='font-weight:bold' lang=en-US>persona</span><span style='font-weight:
bold' lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=zh-CN>近些年，随着技术发展，更多的是使用</span><span
lang=en-US>LLM</span><span lang=zh-CN>合成数据，人类进行轻微地干预，来生成数据集。</span><span
lang=en-US>Ultrachat</span><span lang=zh-CN>数据集。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=zh-CN>当你问</span><span
lang=en-US>chatgpt</span><span lang=zh-CN>时，</span><span lang=en-US>chatgpt</span><span
lang=zh-CN>给你回复，这些回复并不是来自什么神奇魔法</span><span lang=en-US>AI</span><span
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>it's coming from
something that is statistically </span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US><span
style='font-weight:bold'>imitating human labels which comes from labeling
instructions written by companies like openai. </span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold' lang=zh-CN>问</span><span style='font-weight:bold' lang=en-US>chatgpt</span><span
style='font-weight:bold' lang=zh-CN>就像在问</span><span style='font-weight:bold'
lang=en-US>human labeler</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>human labeler</span><span style='font-weight:
bold' lang=zh-CN>会说什么，</span><span style='font-weight:bold' lang=en-US>it's
kind of like asking what would human labeler say in this conversation.</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold' lang=zh-CN>当然这些</span><span style='font-weight:bold' lang=en-US>human
labelers</span><span style='font-weight:bold' lang=zh-CN>不是一些随便的人，而是一些领域的专家。例如，当你询问代码问题时，参与代码对话数据集的</span><span
style='font-weight:bold' lang=en-US>human labelers</span><span
style='font-weight:bold' lang=zh-CN>是</span><span style='font-weight:bold'
lang=en-US>eduated expert</span><span style='font-weight:bold' lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold' lang=en-US>4.</span><span style='font-weight:bold' lang=zh-CN>关于</span><span
style='font-weight:bold' lang=en-US>LLM</span><span style='font-weight:bold'
lang=zh-CN>的自我认知</span></p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image006.jpg" width=725
height=218></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=zh-CN>当问</span><span
lang=en-US>chatgpt</span><span lang=zh-CN>，</span><span lang=en-US>who are you
,who built you? chatgpt</span><span lang=zh-CN>回答，</span><span lang=en-US>I was
built by openai based on gpt model</span><span lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=zh-CN>这不代表</span><span
lang=en-US>LLM</span><span lang=zh-CN>有自我意识，它之所以这样说，是因为它的训练数据里有大量关于此的回答。作为开发者，有</span><span
lang=en-US>2</span><span lang=zh-CN>种方式可以覆盖这个标签。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=en-US>1</span><span
lang=zh-CN>）硬编码，在</span><span lang=en-US>SFT</span><span lang=zh-CN>数据集中指定这种问题的答案。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=en-US>2</span><span
lang=zh-CN>）</span><span lang=en-US>system message</span><span lang=zh-CN>。在上下文窗口中的不可见</span><span
lang=en-US>token</span><span lang=zh-CN>，</span><span lang=en-US> </span><span
lang=zh-CN>提醒模型它的身份（用来防止客服机器人变成虚拟女友）。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt' lang=en-US><span
style='font-weight:bold'>5.LLM need tokens to think</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>当模型进行训练和推理时，是在一维</span><span lang=en-US>token</span><span
lang=zh-CN>序列进行工作，是从左到右的顺序进行演变，并给出下一个</span><span lang=en-US>token</span><span
lang=zh-CN>的概率。</span><span style='font-weight:bold' lang=zh-CN>每一个</span><span
style='font-weight:bold' lang=en-US>token</span><span style='font-weight:bold'
lang=zh-CN>的计算量是有限的</span><span lang=zh-CN>（当然输入序列越长，计算量越大，但可以忽略不计），因此，我们希望将计算分布在多个</span><span
lang=en-US>token</span><span lang=zh-CN>上。</span><span style='font-weight:bold'
lang=zh-CN>知道这一点对我们训练</span><span style='font-weight:bold' lang=en-US>LLM</span><span
style='font-weight:bold' lang=zh-CN>和使用</span><span style='font-weight:bold'
lang=en-US>LLM</span><span style='font-weight:bold' lang=zh-CN>都有帮助。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>1</span><span style='font-weight:bold'
lang=zh-CN>）训练时，下图右边的答案要好于左边，所以</span><span style='font-weight:bold'
lang=en-US>SFT</span><span style='font-weight:bold' lang=zh-CN>数据集应该是右边这种数据，而不是左边的。因为左边是先直接回答，也就是在训练模型在单个</span><span
style='font-weight:bold' lang=en-US>token</span><span style='font-weight:bold'
lang=zh-CN>中得到答案，这是行不通的，因为每个</span><span style='font-weight:bold' lang=en-US>token</span><span
style='font-weight:bold' lang=zh-CN>的计算量是有限的。而右边是让模型慢慢得出答案，也就是训练模型在多个to</span><span
style='font-weight:bold' lang=en-US>ken</span><span style='font-weight:bold'
lang=zh-CN>上分散计算，每个</span><span style='font-weight:bold' lang=en-US>token</span><span
style='font-weight:bold' lang=zh-CN>上的计算都相对简单，多个</span><span style='font-weight:
bold' lang=en-US>token</span><span style='font-weight:bold' lang=zh-CN>上的计算进行累加，得到最终的答案。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:1.5in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image007.jpg" width=775
height=368></p>

<p style='margin:0in;margin-left:5.25in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>2)</span><span style='font-weight:bold'
lang=zh-CN>在推理时，</span><span style='font-weight:bold;text-decoration:line-through'
lang=en-US>promt</span><span style='font-weight:bold;text-decoration:line-through'
lang=zh-CN>中加入</span><span style='font-weight:bold;text-decoration:line-through'
lang=en-US>let's think step by step</span><span style='font-weight:bold;
text-decoration:line-through' lang=zh-CN>，将计算分散在更多的</span><span
style='font-weight:bold;text-decoration:line-through' lang=en-US>token</span><span
style='font-weight:bold;text-decoration:line-through' lang=zh-CN>上。</span><span
style='font-weight:bold' lang=zh-CN>实际上通常不需要</span><span style='font-weight:
bold' lang=en-US>user</span><span style='font-weight:bold' lang=zh-CN>来显式地考虑这个问题，这个问题是</span><span
style='font-weight:bold' lang=en-US>openai</span><span style='font-weight:bold'
lang=zh-CN>的数据标注人员考虑的，他们确保</span><span style='font-weight:bold' lang=en-US>SFT</span><span
style='font-weight:bold' lang=zh-CN>数据集中的数据是这样的就可以了，这样训练出来的</span><span
style='font-weight:bold' lang=en-US>LLM</span><span style='font-weight:bold'
lang=zh-CN>回答时会自动生成中间结果</span><span style='font-weight:bold' lang=en-US> </span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>think step by step.</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'
lang=en-US>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>PS</span><span style='font-weight:bold'
lang=zh-CN>：在现实中，这种需要数学计算或者心算的问题，通常</span><span style='font-weight:bold'
lang=en-US>use code</span><span style='font-weight:bold' lang=zh-CN>来解决，而不是完全依赖</span><span
style='font-weight:bold' lang=en-US>LLM</span><span style='font-weight:bold'
lang=zh-CN>进行下图中的心算，</span><span lang=zh-CN>这种心算不是</span><span lang=en-US>100%</span><span
lang=zh-CN>可靠的，特别是当数字很大时，任何一个步骤都可能出错</span><span lang=en-US> </span><span
lang=zh-CN>。当使用代码时，就不需要依赖</span><span lang=en-US>LLM</span><span lang=zh-CN>的心算了，</span><span
lang=en-US>LLM</span><span lang=zh-CN>只需要生成代码，使用</span><span lang=en-US>python
interpreter</span><span lang=zh-CN>执行，得到结果，会可靠得多。</span></p>

<p style='margin:0in;margin-left:1.5in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image008.jpg" width=551
height=378></p>

<p style='margin:0in;margin-left:5.625in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=zh-CN>总结：</span><span style='font-weight:bold'
lang=en-US>LLM</span><span style='font-weight:bold' lang=zh-CN>需要</span><span
style='font-weight:bold' lang=en-US>tokens to think</span><span
style='font-weight:bold' lang=zh-CN>，将计算分散到多个</span><span style='font-weight:
bold' lang=en-US>token</span><span style='font-weight:bold' lang=zh-CN>上，要求模型创建中间结果</span><span
style='font-weight:bold' lang=en-US> </span><span style='font-weight:bold'
lang=zh-CN>，并尽量使用</span><span style='font-weight:bold' lang=en-US>tools</span><span
style='font-weight:bold' lang=zh-CN>，而不是让模型纯粹依赖它的记忆参数来处理这一切。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=en-US>LLM</span><span lang=zh-CN>需要</span><span lang=en-US>tokens to think</span><span
lang=zh-CN>的另一个例子是</span><span style='font-weight:bold' lang=en-US>count</span><span
style='font-weight:bold' lang=zh-CN>ing</span><span lang=zh-CN>。如下所示，这就是让</span><span
lang=en-US>llm</span><span lang=zh-CN>在单个</span><span lang=en-US>token</span><span
lang=zh-CN>中完成计数这个操作。此时好的做法是让</span><span lang=en-US>LLM</span><span
lang=zh-CN>用代码</span><span lang=en-US>tool</span><span lang=zh-CN>，</span><span
lang=en-US>LLM</span><span lang=zh-CN>很擅长</span><span lang=en-US>copy paste</span><span
lang=zh-CN>，只需要把这个字符串复制粘贴到代码中，执行，就可以得到长度了。</span></p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image009.jpg" width=998
height=241></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>另一个例子是问</span><span lang=en-US>LLM</span><span lang=zh-CN>，</span><span
lang=en-US>how many 'r' in 'strawberry'</span><span lang=zh-CN>？这个问题的难点有</span><span
lang=en-US>2</span><span lang=zh-CN>个，一个是</span><span lang=en-US>LLM</span><span
lang=zh-CN>看到的是</span><span lang=en-US>token</span><span lang=zh-CN>而不是</span><span
lang=en-US>letter</span><span lang=zh-CN>，第二个是这个问题是个计数问题，计数问题是</span><span
lang=en-US>ll</span><span lang=zh-CN>m不擅长的，因为</span><span lang=en-US>llm</span><span
lang=zh-CN>需要</span><span lang=en-US>tokens </span><span lang=zh-CN>to</span><span
lang=en-US> think</span><span lang=zh-CN>。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>LLM</span><span style='font-weight:bold'
lang=zh-CN>会在一些很简单的问题上出错，</span><span lang=zh-CN>如认为</span><span lang=en-US>9.11</span><span
lang=zh-CN>比</span><span lang=en-US>9.9</span><span lang=zh-CN>大。原因是在圣经中，章节</span><span
lang=en-US>9.11</span><span lang=zh-CN>在</span><span lang=en-US>9.9</span><span
lang=zh-CN>之后出现，所以模型认为</span><span lang=en-US>9.11</span><span lang=zh-CN>比</span><span
lang=en-US>9.9</span><span lang=zh-CN>大。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold' lang=en-US>6.</span><span style='font-weight:bold' lang=zh-CN>强化学习</span></p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image010.jpg" width=824
height=665></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'
lang=en-US>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=en-US>LLM</span><span lang=zh-CN>的训练可以类比上学学习书本上的知识。书本上的大部分知识是阐述性的知识，</span><span
lang=en-US>exposition</span><span lang=zh-CN>，就像是背景知识，当人在阅读背景知识时，可以粗略地视为在该数据上的训练，等同于</span><span
lang=en-US>LLM</span><span lang=zh-CN>的预训练。书本上的第二类信息是问题及专家的解答过程，这个解答相当于</span><span
lang=en-US>LLM</span><span lang=zh-CN>助手的理想回答，相当于</span><span lang=en-US>SFT</span><span
lang=zh-CN>训练。</span><span style='font-weight:bold' lang=zh-CN>书本上的第三类信息是每个章节的练习题，这部分只有问题，没有解答过程，但是有标准正确答案</span><span
lang=zh-CN>，这个部分相当于强化学习，自己尝试不同的解决方法，并观察哪些方法能达到最终正确答案。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold'>为什么需要强化学习？</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>1</span><span style='font-weight:bold'
lang=zh-CN>）</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:1.5in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image011.jpg" width=511
height=491></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>当构建</span><span lang=en-US>SFT</span><span lang=zh-CN>数据集时，如上图所示，有</span><span
lang=en-US>4</span><span lang=zh-CN>种re</span><span lang=en-US>sponse</span><span
lang=zh-CN>，</span><span lang=en-US>4</span><span lang=zh-CN>个</span><span
lang=en-US>response</span><span lang=zh-CN>的答案都是正确的</span><span lang=en-US>3</span><span
lang=zh-CN>，但是具体选择哪种</span><span lang=en-US>response</span><span lang=zh-CN>作为</span><span
lang=en-US>SFT</span><span lang=zh-CN>的训练数据呢，是不确定的，因为我们和</span><span
lang=en-US>LLM</span><span lang=zh-CN>的思考方式不同，我们的知识和</span><span lang=en-US>LLM</span><span
lang=zh-CN>不同，</span><span lang=en-US>LLM</span><span lang=zh-CN>可能认为某种</span><span
lang=en-US>response</span><span lang=zh-CN>是</span><span lang=en-US>trivial</span><span
lang=zh-CN>的，过长的</span><span lang=en-US>response</span><span lang=zh-CN>仅仅是浪费</span><span
lang=en-US>token</span><span lang=zh-CN>，也可能认为某种</span><span lang=en-US>response</span><span
lang=zh-CN>是它不曾掌握的知识，这种</span><span lang=en-US>response</span><span lang=zh-CN>会让它感到困惑。</span><span
style='font-weight:bold' lang=zh-CN>我们并不知道最适合</span><span style='font-weight:
bold' lang=en-US>LLM</span><span style='font-weight:bold' lang=zh-CN>的</span><span
style='font-weight:bold' lang=en-US>response </span><span style='font-weight:
bold' lang=zh-CN>是什么，因此，我们需要允许</span><span style='font-weight:bold' lang=en-US>LLM</span><span
style='font-weight:bold' lang=zh-CN>发现适用于它的</span><span style='font-weight:
bold' lang=en-US>response </span><span style='font-weight:bold' lang=zh-CN>to</span><span
style='font-weight:bold' lang=en-US>ken</span><span style='font-weight:bold'
lang=zh-CN>序列，可以可靠地得到答案，此时就需要强化学习来不断试错</span><span style='font-weight:bold'
lang=en-US> </span><span style='font-weight:bold' lang=zh-CN>。如下图所示，</span><span
style='font-weight:bold' lang=en-US>prompt----&gt;s</span><span
style='font-weight:bold' lang=zh-CN>o</span><span style='font-weight:bold'
lang=en-US>lution-----&gt;correct answer</span><span style='font-weight:bold'
lang=zh-CN>。</span><span style='font-weight:bold' lang=en-US>prompt</span><span
style='font-weight:bold' lang=zh-CN>和</span><span style='font-weight:bold'
lang=en-US>correct answer</span><span style='font-weight:bold' lang=zh-CN>是确实的，</span><span
style='font-weight:bold' lang=en-US>solution</span><span style='font-weight:
bold' lang=zh-CN>是要</span><span style='font-weight:bold' lang=en-US>LLM</span><span
style='font-weight:bold' lang=zh-CN>自己通过试错生成的，而不是人类标注员提供。（</span><span
style='font-weight:bold' lang=en-US>LLM</span><span style='font-weight:bold'
lang=zh-CN>就像在游乐场玩耍，它知道要达到什么目标，它发现了适合它的</span><span style='font-weight:bold'
lang=en-US>response<span style='mso-spacerun:yes'>  </span>solution </span><span
style='font-weight:bold' lang=zh-CN>序列，这个序列在统计上更平滑，充分利用了模型已有的知识）</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image012.jpg" width=929
height=551></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>2</span><span style='font-weight:bold'
lang=zh-CN>）一味模仿无法超越，只有自己探索才能超越</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>监督学习是模型在模仿人类专家，但是永远无法超越顶尖专家。</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=en-US>A</span><span lang=zh-CN>lph</span><span lang=en-US>ago</span><span
lang=zh-CN>超越了人类的围棋水平，例如在第</span><span lang=en-US>37</span><span lang=zh-CN>步中走了非常不同寻常的一步，人类几乎不会走的一步，这实际上是超越了人类。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>同理，将强化学习应用于训练</span><span lang=en-US>LLM</span><span lang=zh-CN>，理论上</span><span
lang=en-US>LLM</span><span lang=zh-CN>可以在推理或思考上超越人类。</span><span lang=en-US>what
does this mean?</span><span lang=zh-CN>也许是</span><span lang=en-US>LLM</span><span
lang=zh-CN>发现了一种完全不同的类比，或思考方式，或新的语言类似编程语言。</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='font-weight:bold' lang=en-US>D</span><span style='font-weight:bold'
lang=zh-CN>eep</span><span style='font-weight:bold' lang=en-US>seek r1</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>随着训练步数增加，推理准确率增加，与此同时推理的</span><span lang=en-US>tokens</span><span
lang=zh-CN>序列也增加，因为</span><span lang=en-US>LLM</span><span lang=zh-CN>涌现出了类似</span><span
lang=en-US>wait, that an aha moment</span><span lang=zh-CN>这种情况。模型发展了自己的认知策略，自己的思考方式，re</span><span
lang=en-US>evaluate</span><span lang=zh-CN>，多方面思考，思维链，这就是导致响应长度增加的原因，同时也是提高推理准确性的原因。</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image013.jpg" width=822
height=691></p>

<p style='margin:0in;margin-left:2.625in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'
lang=en-US><span style='font-weight:bold'>RLHF</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'>当问题没有答案时，即不可验证，如创意写作，给不同解决方法评分变得困难。</p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>用神经网络来模拟人类偏好，即训练一个</span><span lang=en-US>reward model</span><span
lang=zh-CN>。</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
lang=en-US>RLHF</span><span lang=zh-CN>的好处：可以在任意领域进行</span><span lang=en-US>RL</span><span
lang=zh-CN>，即使是不可验证，而且</span><span lang=en-US>empirically</span><span
lang=zh-CN>效果提升。</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>坏处：</span><span lang=en-US>reward </span><span lang=zh-CN>m</span><span
lang=en-US>odel</span><span lang=zh-CN>是有损的，而且</span><span lang=en-US>reward
model</span><span lang=zh-CN>本质上是神经网络，</span><span lang=en-US>RL</span><span
lang=zh-CN>非常擅长愚弄</span><span lang=en-US>reward model</span><span lang=zh-CN>，生成对抗性样本。</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
lang=zh-CN>因此在实际中，</span><span lang=en-US>RLHF</span><span lang=zh-CN>通常只运行几百</span><span
lang=en-US>step</span><span lang=zh-CN>s，如果一直运行，就会开始愚弄</span><span lang=en-US>reward
model</span><span lang=zh-CN>。而</span><span lang=en-US>RL</span><span
lang=zh-CN>则可以无限运行。从这个意义上说，</span><span lang=en-US>RLHF</span><span lang=zh-CN>不是</span><span
lang=en-US>RL</span><span lang=zh-CN>，而是一种微调。</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:1.125in'><img
src="let's%20dive%20deep%20into%20chatgpt.files/image014.jpg" width=796
height=719></p>

<p style='margin:0in;margin-left:3.75in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold'>PREVIEW OF THINGS TO COME</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>- multimodal (not just
text but audio, images, video, natural conversations)</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span lang=zh-CN>-
tasks -&gt; agents (long, coherent, error-correcting contexts</span><span
style='font-weight:bold' lang=zh-CN>)现在大多数情况是将单个任务交给模型，仍然需要我们来</span><span
style='font-weight:bold' lang=en-US>organize a coherent execution of tasks</span><span
style='font-weight:bold' lang=zh-CN>，模型不能修正错误，尤其是长时间运行。</span><span
style='font-weight:bold' lang=en-US>A</span><span style='font-weight:bold'
lang=zh-CN>ge</span><span style='font-weight:bold' lang=en-US>nts</span><span
style='font-weight:bold' lang=zh-CN>随着时间执行任务，人类负责监督，</span><span
style='font-weight:bold' lang=en-US>agents</span><span style='font-weight:bold'
lang=zh-CN>偶尔会报告进展，</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>- pervasive, invisible</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>- computer-using</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>- test-time training?,
etc.</p>

</div>

<div style='direction:ltr;margin-top:.152in;margin-left:0in;width:1.0347in'>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'>，</p>

</div>

</div>

</div>

<div>

<p style='margin:0in'>&nbsp;</p>

<p style='text-align:left;margin:0in;font-family:Arial;font-size:9pt;
color:#969696;direction:ltr'>已使用 OneNote 创建。</p>

</div>

</body>

</html>
