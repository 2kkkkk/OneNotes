<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:dt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=OneNote.File>
<meta name=Generator content="Microsoft OneNote 15">
<link id=Main-File rel=Main-File href="Build%20makemore.htm">
<link rel=File-List href="Build%20makemore.files/filelist.xml">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:12.0pt'>

<div style='direction:ltr;border-width:100%'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:11.8895in'>

<div style='direction:ltr;margin-top:0in;margin-left:.0215in;width:2.3652in'>

<p style='margin:0in;font-family:"Calibri Light";font-size:20.0pt' lang=en-US>Build
makemore</p>

</div>

<div style='direction:ltr;margin-top:.0423in;margin-left:.0215in;width:1.5979in'>

<p style='margin:0in;font-size:10.0pt;color:#767676'><span style='font-family:
Calibri'>2025</span><span style='font-family:"Microsoft YaHei"'>年</span><span
style='font-family:Calibri'>4</span><span style='font-family:"Microsoft YaHei"'>月</span><span
style='font-family:Calibri'>2</span><span style='font-family:"Microsoft YaHei"'>日</span></p>

<p style='margin:0in;font-family:Calibri;font-size:10.0pt;color:#767676'>18:49</p>

</div>

<div style='direction:ltr;margin-top:.3652in;margin-left:0in;width:11.8895in'>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'><span lang=en-US>MLP:
</span><span style='font-weight:bold;color:#0F0F0F' lang=zh-CN>Activations
&amp; Gradients, BatchNorm</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold'>关于初始化神经网络的参数，网络训练之前应该考虑的问题：</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>what loss do you expect
at initialization? like uniform distribution of 27 characters</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>You don't want the
output of tanh function to be land on -1 or 1 region, because the gradient of
tanh in this region is zero , therefore can't pass gradient backwards.</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>tanh ,sigmoid,
relu都有这个问题，即都存在导数等于0的平坦区域。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>如果一个神经元dead，说明无论input如何变化
，该神经元的激活值，即tanh(h)总是落在导数为0的区域，使得梯度无法传播。相当于never activates.</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>神经元永久失活可能发生在Initialization时，也可能发生在训练过程中，比如在某个batch上更新参数后，下一个batch中所有样本在该神经元上的激活值都落在了导数为0的区域，反向传播也就不会对参数进行更新，也就相当于这个batch没有对参数进行更新,下下一个batch进来，可能还是不会更新...一直重复下去。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>关于Initialization的另一点，x和w都是标准正态分布,x@w的均值是0，但是方差不是1，要想使(x@w)的分布也是均值为0，方差为1（落在激活区域），那么在初始化w的时候就不应该用标准正态分布初始化，详见pytorch中的kaiming_normal及paper。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>Batchnorm的出发点，你想让隐藏层神经层的激活值分布在均值=0，方差为1，为什么不直接对激活值做standardization呢。因此Batchnorm层在激活函数之前
。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>我们只是想在initialization的时候，不想让神经元失活，而不是一直让神经元的预激活值在训练过程中保持标准正态分布，我们想让back
propogate告诉我们预激活值应该如何分布，所以batchnorm有两个可学习参数。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>Batchnorm的inefficiency。Batch中的每个样本不是独立的了，当前样本的forward
pass需要计算与batch中其他样本的均值，也就将batch中各个样本的前向传播耦合在了一起，而非独立进行。另一方面，当batch中其他样本换成别的样本，forward
pass 也会发生变化 ，也就是与batch如何划分有关，使得模型训练变得不desireable。</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-style:italic'># Let's train a deeper network</span><br>
<span style='font-style:italic'># The classes we create here are the same API
as nn.Module in PyTorch</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>class</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> Linear:<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>def</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> __init__(self, fan_in,
fan_out, bias</span><span style='font-weight:bold;font-family:Consolas;
color:#212121' lang=zh-CN>=True</span><span style='font-family:Consolas;
color:#212121' lang=zh-CN>):<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>weight </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>randn((fan_in, fan_out),
generator</span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>=</span><span style='font-family:Consolas;color:#212121' lang=zh-CN>g)
</span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>/</span><span style='font-family:Consolas;color:#212121' lang=zh-CN>
fan_in</span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>**</span><span style='font-family:Consolas;color:#212121'
lang=zh-CN>0.5</span><span style='font-family:Calibri;color:#212121'
lang=en-US><span style='mso-spacerun:yes'>  </span></span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>W</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的初始化，假设x是no</span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>rmal gaussion</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>分布，</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>w</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>也是</span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>normal gaussion</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>，那么</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>w*x</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的均值仍是</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>0</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>，但标准差不是</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>1</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>，会被放大，也就是说</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=en-US>w*x</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>不是</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>norm gaussion</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>。所以</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>w</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN> 除以fan_in**0.5的目的是</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US> </span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>防止</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>wx</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的分布不是均值为</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>0</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>，方差为</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>1</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的分布。关于为什么除以</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>fan_in**0.5</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>，而与</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>fan_out</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>的维度无关，我的想法是因为</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=en-US>x</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>是个</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>n*fan_in</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>矩阵，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>w</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>是个</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>fan_in*fan_out</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>矩阵，w</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>*x</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>中的每个元素是两个向量的点积，向量的长度是</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>fan_in</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>，所以</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>w*</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>x的缩放取决于</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>fan_in</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>，而与</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>fan_out</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>无关。</span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>pytorch</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>里是均匀分布。但是当网络很深时，it</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US> becomes harder and harder to precisely set the weights and bias in
such way that activations are roughly uniform, </span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>从而引出了</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>batchnorm</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self<span style='font-weight:bold'>.</span>bias
<span style='font-weight:bold'>=</span> torch<span style='font-weight:bold'>.</span>zeros(fan_out)
<span style='font-weight:bold'>if</span> bias <span style='font-weight:bold'>else
None</span><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>def</span>
__call__(self, x):<br>
<span style='mso-spacerun:yes'>    </span>self<span style='font-weight:bold'>.</span>out
<span style='font-weight:bold'>=</span> x <span style='font-weight:bold'>@</span>
self<span style='font-weight:bold'>.</span>weight<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>if</span>
self<span style='font-weight:bold'>.</span>bias <span style='font-weight:bold'>is
not None</span>:<br>
<span style='mso-spacerun:yes'>      </span>self<span style='font-weight:bold'>.</span>out
<span style='font-weight:bold'>+=</span> self<span style='font-weight:bold'>.</span>bias<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>return</span>
self<span style='font-weight:bold'>.</span>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>def</span>
parameters(self):<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>return</span>
[self<span style='font-weight:bold'>.</span>weight] <span style='font-weight:
bold'>+</span> ([] <span style='font-weight:bold'>if</span> self<span
style='font-weight:bold'>.</span>bias <span style='font-weight:bold'>is None
else</span> [self<span style='font-weight:bold'>.</span>bias])</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>class</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> BatchNorm1d:<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>def</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> __init__(self, dim, eps</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>1e-5, momentum</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>0.1):</span><span
style='font-family:Calibri;color:#212121' lang=en-US><span
style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:"Segoe UI Symbol";color:#C00000' lang=en-US>★</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN> </span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>pytorch</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>默认是</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>momentum</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>是</span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>0.1</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>，公式是</span><span style='font-weight:
bold;font-family:Consolas;color:#C00000' lang=en-US>(1-momentum)*v +
momentum*v' </span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>。</span></p>

<p style='margin:0in;font-size:12.0pt;color:#C00000'><span style='font-weight:
bold;font-family:Consolas' lang=en-US>momentum</span><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>的设置需要考虑</span><span
style='font-weight:bold;font-family:Consolas' lang=en-US>batchsize</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，如果</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>batchsize<span
style='mso-spacerun:yes'>   </span></span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>很大，那么每个</span><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=en-US>batch</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的均值和方差基本没啥变化，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>momentum</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>可以设置的大一些，如</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>0.1</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，表示用最近</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>10</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>个</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>batch</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的平均，如果</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>batchsize</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>很小，那么</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>momentum</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>应该设置的小一些。</span></p>

<p style='margin:0in;font-size:12.0pt;color:#212121'><span style='font-family:
Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>eps </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN>
eps<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>momentum </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> momentum</span><span
style='font-family:Calibri' lang=en-US> </span><span style='font-family:Consolas'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>training </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>= True</span><span style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
font-family:Consolas' lang=zh-CN># parameters (trained with backprop)</span><span
style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>gamma </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>ones(dim)<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>beta </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>zeros(dim)<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
font-family:Consolas' lang=zh-CN># buffers (trained with a running 'momentum
update')</span><span style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>running_mean </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>zeros(dim)<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>running_var </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>ones(dim)<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>def</span><span style='font-family:Consolas'
lang=zh-CN> __call__(self, x):<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
font-family:Consolas' lang=zh-CN># calculate the forward pass</span><span
style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>if</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>training:<br>
<span style='mso-spacerun:yes'>      </span>xmean </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>=</span><span
style='font-family:Consolas' lang=zh-CN> x</span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>mean(0, keepdim</span><span style='font-weight:bold;font-family:
Consolas' lang=zh-CN>=True</span><span style='font-family:Consolas' lang=zh-CN>)
</span><span style='font-style:italic;font-family:Consolas' lang=zh-CN># batch
mean</span><span style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span>xvar </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>=</span><span style='font-family:Consolas'
lang=zh-CN> x</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>var(0, keepdim</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>=True</span><span
style='font-family:Consolas' lang=zh-CN>) </span><span style='font-style:italic;
font-family:Consolas' lang=zh-CN># batch variance</span><span style='font-family:
Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>else</span><span style='font-family:Consolas'
lang=zh-CN>:<br>
<span style='mso-spacerun:yes'>      </span>xmean </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>=</span><span
style='font-family:Consolas' lang=zh-CN> self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>running_mean<br>
<span style='mso-spacerun:yes'>      </span>xvar </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>=</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>running_var<br>
<span style='mso-spacerun:yes'>    </span>xhat </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>=</span><span style='font-family:Consolas'
lang=zh-CN> (x </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>-</span><span style='font-family:Consolas' lang=zh-CN> xmean) </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>/</span><span
style='font-family:Consolas' lang=zh-CN> torch</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>sqrt(xvar </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>+</span><span style='font-family:Consolas' lang=zh-CN> self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>eps) </span><span style='font-style:
italic;font-family:Consolas' lang=zh-CN># normalize to unit variance</span><span
style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>out </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>=</span><span style='font-family:Consolas' lang=zh-CN> self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>gamma </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>*</span><span style='font-family:Consolas'
lang=zh-CN> xhat </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>+</span><span style='font-family:Consolas' lang=zh-CN> self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>beta<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
font-family:Consolas' lang=zh-CN># update the buffers</span><span
style='font-family:Consolas' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>if</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>training:<br>
<span style='mso-spacerun:yes'>      </span></span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>with</span><span style='font-family:Consolas'
lang=zh-CN> torch</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>no_grad():<br>
<span style='mso-spacerun:yes'>        </span>self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>running_mean </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>=</span><span
style='font-family:Consolas' lang=zh-CN> (1 </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>-</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>momentum) </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>*</span><span
style='font-family:Consolas' lang=zh-CN> self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>running_mean </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>+</span><span style='font-family:Consolas' lang=zh-CN> self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>momentum </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>*</span><span style='font-family:Consolas'
lang=zh-CN> xmean<br>
<span style='mso-spacerun:yes'>        </span>self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>running_var </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>=</span><span
style='font-family:Consolas' lang=zh-CN> (1 </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>-</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>momentum) </span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>*</span><span
style='font-family:Consolas' lang=zh-CN> self</span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>.</span><span style='font-family:Consolas'
lang=zh-CN>running_var </span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>+</span><span style='font-family:Consolas' lang=zh-CN> self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>momentum </span><span style='font-weight:
bold;font-family:Consolas' lang=zh-CN>*</span><span style='font-family:Consolas'
lang=zh-CN> xvar<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>return</span><span style='font-family:Consolas'
lang=zh-CN> self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>def</span><span style='font-family:Consolas'
lang=zh-CN> parameters(self):<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas' lang=zh-CN>return</span><span style='font-family:Consolas'
lang=zh-CN> [self</span><span style='font-weight:bold;font-family:Consolas'
lang=zh-CN>.</span><span style='font-family:Consolas' lang=zh-CN>gamma, self</span><span
style='font-weight:bold;font-family:Consolas' lang=zh-CN>.</span><span
style='font-family:Consolas' lang=zh-CN>beta]</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-weight:bold'>class</span> Tanh:<br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>def</span>
__call__(self, x):<br>
<span style='mso-spacerun:yes'>    </span>self<span style='font-weight:bold'>.</span>out
<span style='font-weight:bold'>=</span> torch<span style='font-weight:bold'>.</span>tanh(x)<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>return</span>
self<span style='font-weight:bold'>.</span>out<br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>def</span>
parameters(self):<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>return</span>
[]</p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'>n_embd
<span style='font-weight:bold'>=</span> 10 <span style='font-style:italic'>#
the dimensionality of the character embedding vectors</span><br>
n_hidden <span style='font-weight:bold'>=</span> 100 <span style='font-style:
italic'># the number of neurons in the hidden layer of the MLP</span><br>
g <span style='font-weight:bold'>=</span> torch<span style='font-weight:bold'>.</span>Generator()<span
style='font-weight:bold'>.</span>manual_seed(2147483647) <span
style='font-style:italic'># for reproducibility</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-family:Consolas;
color:#212121' lang=zh-CN>C </span><span style='font-weight:bold;font-family:
Consolas;color:#212121' lang=zh-CN>=</span><span style='font-family:Consolas;
color:#212121' lang=zh-CN> torch</span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>.</span><span style='font-family:
Consolas;color:#212121' lang=zh-CN>randn((vocab_size, n_embd),<span
style='mso-spacerun:yes'>            </span>generator</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>g)<br>
layers </span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>=</span><span style='font-family:Consolas;color:#212121' lang=zh-CN>
[<br>
<span style='mso-spacerun:yes'>  </span>Linear(n_embd </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>*</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> block_size, n_hidden,
bias</span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>=False</span><span style='font-family:Consolas;color:#212121'
lang=zh-CN>), BatchNorm1d(n_hidden), Tanh(),</span><span style='font-family:
Calibri;color:#212121' lang=en-US> </span><span style='font-family:微软雅黑;
color:#C00000' lang=en-US>★ </span><span style='font-weight:bold;font-family:
微软雅黑;color:#C00000' lang=zh-CN>加了batchnorm层之后 ，之前的全连接层就不需要加偏置b了。即bias=False</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>Linear(<span
style='mso-spacerun:yes'>           </span>n_hidden, n_hidden, bias<span
style='font-weight:bold'>=False</span>), BatchNorm1d(n_hidden),
Tanh(),<br>
<span style='mso-spacerun:yes'>  </span>Linear(<span
style='mso-spacerun:yes'>           </span>n_hidden, n_hidden, bias<span
style='font-weight:bold'>=False</span>), BatchNorm1d(n_hidden),
Tanh(),<br>
<span style='mso-spacerun:yes'>  </span>Linear(<span
style='mso-spacerun:yes'>           </span>n_hidden, n_hidden, bias<span
style='font-weight:bold'>=False</span>), BatchNorm1d(n_hidden),
Tanh(),<br>
<span style='mso-spacerun:yes'>  </span>Linear(<span
style='mso-spacerun:yes'>           </span>n_hidden, n_hidden, bias<span
style='font-weight:bold'>=False</span>), BatchNorm1d(n_hidden),
Tanh(),<br>
<span style='mso-spacerun:yes'>  </span>Linear(<span
style='mso-spacerun:yes'>           </span>n_hidden, vocab_size, bias<span
style='font-weight:bold'>=False</span>), BatchNorm1d(vocab_size),<br>
]<br>
<span style='font-style:italic'># layers = [</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(n_embd * block_size, n_hidden), Tanh(),</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(<span style='mso-spacerun:yes'>           </span>n_hidden,
n_hidden), Tanh(),</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(<span style='mso-spacerun:yes'>           </span>n_hidden,
n_hidden), Tanh(),</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(<span style='mso-spacerun:yes'>           </span>n_hidden,
n_hidden), Tanh(),</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(<span style='mso-spacerun:yes'>           </span>n_hidden,
n_hidden), Tanh(),</span><br>
<span style='font-style:italic'>#<span style='mso-spacerun:yes'>  
</span>Linear(<span style='mso-spacerun:yes'>           </span>n_hidden,
vocab_size),</span><br>
<span style='font-style:italic'># ]</span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>with</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>no_grad():<br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># last layer: make less
confident</span><span style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>layers[</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>-</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>1]</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>gamma </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>*=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> 0.1<br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN>#layers[-1].weight *= 0.1</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># all other layers: apply gain</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layer </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layers[:</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>-</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>1]:<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>if</span><span style='font-family:
Consolas;color:#212121' lang=zh-CN> isinstance(layer, Linear):<br>
<span style='mso-spacerun:yes'>      </span>layer</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>weight </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>*=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> 1.0 </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN>#5/3</span><span
style='font-style:italic;font-family:Calibri;color:#212121' lang=en-US><span
style='mso-spacerun:yes'>                     </span></span><span
style='font-style:italic;font-family:"Segoe UI Symbol";color:#212121'
lang=en-US>★</span><span style='font-weight:bold;font-family:微软雅黑;color:#C00000'
lang=zh-CN>当不加</span><span style='font-weight:bold;font-family:Calibri;
color:#C00000' lang=en-US>batchnorm</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>时，需要乘</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>以</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>5/3</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>相当于把</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>w</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>放大了一些，原因是</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>tanh</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>将输出缩小到</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>-1</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>，</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>1,</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>所以需要放大来抵消</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>tanh</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>的缩小作用。加了</span><span
style='font-weight:bold;font-family:Calibri;color:#C00000' lang=en-US>batchnorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>后，就不需要</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>*5/3</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>了，乘以</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>1</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>保持原状即可。</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>5/3</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>被称为</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>tanh</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>gain</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>，lin</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>ear</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>和</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>conv,sigmoid</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>gain</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>都是</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>1, relu</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>的</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>gain</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>是根号</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>2</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'>parameters
<span style='font-weight:bold'>=</span> [C] <span style='font-weight:bold'>+</span>
[p <span style='font-weight:bold'>for</span> layer <span style='font-weight:
bold'>in</span> layers <span style='font-weight:bold'>for</span> p <span
style='font-weight:bold'>in</span> layer<span style='font-weight:bold'>.</span>parameters()]<br>
print(sum(p<span style='font-weight:bold'>.</span>nelement() <span
style='font-weight:bold'>for</span> p <span style='font-weight:bold'>in</span>
parameters)) <span style='font-style:italic'># number of parameters in total</span><br>
<span style='font-weight:bold'>for</span> p <span style='font-weight:bold'>in</span>
parameters:<br>
<span style='mso-spacerun:yes'>  </span>p<span style='font-weight:bold'>.</span>requires_grad
<span style='font-weight:bold'>= True</span></p>

<p style='margin:0in;line-height:12pt;font-family:Consolas;font-size:12.0pt;
color:#212121'>&nbsp;</p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-style:italic'># same optimization as last time</span><br>
max_steps <span style='font-weight:bold'>=</span> 200000<br>
batch_size <span style='font-weight:bold'>=</span> 32<br>
lossi <span style='font-weight:bold'>=</span> []<br>
ud <span style='font-weight:bold'>=</span> []</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> i </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>
range(max_steps):<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># minibatch construct</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>ix </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> torch</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>randint(0, Xtr</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>shape[0], (batch_size,),
generator</span><span style='font-weight:bold;font-family:Consolas;color:#212121'
lang=zh-CN>=</span><span style='font-family:Consolas;color:#212121' lang=zh-CN>g)<br>
<span style='mso-spacerun:yes'>  </span>Xb, Yb </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> Xtr[ix], Ytr[ix] </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN># batch
X,Y</span><span style='font-style:italic;font-family:微软雅黑;color:#212121'
lang=en-US> </span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US><span style='mso-spacerun:yes'>       </span></span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>Xb</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>shape:
(batch_size, context length)</span><span style='font-family:Consolas;
color:#212121' lang=zh-CN><span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># forward pass</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>emb </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> C[Xb] </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN># embed
the characters into vectors</span><span style='font-style:italic;font-family:
微软雅黑;color:#212121' lang=en-US><span style='mso-spacerun:yes'>   </span></span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>emb</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:微软雅黑;color:#C00000' lang=en-US>shape:
(batch_size, context length,embedding_length)</span><span style='font-family:
Consolas;color:#212121' lang=zh-CN><span style='mso-spacerun:yes'>  </span></span></p>

<p style='margin:0in;font-size:12.0pt'><span style='font-family:Consolas;
color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>x </span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>=</span><span style='font-family:
Consolas;color:#212121' lang=zh-CN> emb</span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>.</span><span style='font-family:
Consolas;color:#212121' lang=zh-CN>view(emb</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>shape[0], </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>-</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>1) </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN>#
concatenate the vectors</span><span style='font-style:italic;font-family:Consolas;
color:#212121' lang=en-US> </span><span style='font-weight:bold;font-family:
Consolas;color:#C00000' lang=en-US>x</span><span style='font-weight:bold;
font-family:微软雅黑;color:#C00000' lang=zh-CN>的</span><span style='font-weight:
bold;font-family:微软雅黑;color:#C00000' lang=en-US>shape: (batch_size</span><span
style='font-weight:bold;font-family:Consolas;color:#C00000' lang=en-US>,context_length
* embedding_</span><span style='font-weight:bold;font-family:微软雅黑;color:#C00000'
lang=en-US>length)</span><span style='font-weight:bold;font-family:微软雅黑;
color:#C00000' lang=zh-CN>，也就相当于把</span><span style='font-weight:bold;
font-family:微软雅黑;color:#C00000' lang=en-US>context_length</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>个字母的</span><span style='font-weight:bold;font-family:Consolas;
color:#C00000' lang=en-US>embedding concat</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>起来。也就是将</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>context</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>中所有</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>token</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>（这里是单个字母）的</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>embedding concat</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>起来，平等地对待，而没有按照每个</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>token</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>的</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>embedding</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>区分对待。</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>wavenet</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>缓解了这个问题，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>wavene</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>t逐级分层地将</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=en-US>context</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>中所有</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>token</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>的Emb</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>edding </span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>fuse起来，而不是一下子</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>concat</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>。</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>wavenet</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>每次</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>concat 2</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>个相邻的</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US>token</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>的</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=en-US>embedding</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>，经过</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=en-US> context_length/2</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>次操作，实现了将所有</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>token </span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>c</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>oncat</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>起来的目标。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-family:Consolas;
color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layer </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layers:<br>
<span style='mso-spacerun:yes'>    </span>x </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layer(x)<br>
<span style='mso-spacerun:yes'>  </span>loss </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> F</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>cross_entropy(x, Yb) </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN># loss
function</span><span style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># backward pass</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layer </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> layers:<br>
<span style='mso-spacerun:yes'>    </span>layer</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>out</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>retain_grad() </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN>#
AFTER_DEBUG: would take out retain_graph</span><span style='font-style:italic;
font-family:Calibri;color:#212121' lang=en-US><span
style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>默认情况下，非叶节点的梯度值在反向传播过程中使用完后就会被清除，不会被保留。只有叶节点的梯度值能够被保留下来。</span><span
style='font-weight:bold;font-family:Calibri;color:#C00000' lang=en-US> </span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>叶子节点是由用户创建的，如</span><span style='font-weight:bold;font-family:Calibri;
color:#C00000' lang=en-US>w</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=zh-CN>和</span><span style='font-weight:
bold;font-family:Calibri;color:#C00000' lang=en-US>b</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>，非叶子节点即中间节点如这里的</span><span style='font-weight:bold;font-family:
Calibri;color:#C00000' lang=en-US>out</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>，在</span><span
style='font-weight:bold;font-family:Calibri;color:#C00000' lang=en-US>loss.backwad</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=zh-CN>执行后，默认不会保存非叶子节点的</span><span style='font-weight:bold;font-family:
Calibri;color:#C00000' lang=en-US>grad</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>。</span><span
style='font-family:微软雅黑;color:#C00000' lang=zh-CN><br>
</span><span style='font-family:Consolas;color:#212121' lang=zh-CN><span
style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> p </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> parameters:<br>
<span style='mso-spacerun:yes'>    </span>p</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>grad </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>= None</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>loss</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>backward()<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-style:italic;
font-family:Consolas;color:#212121' lang=zh-CN># update</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>lr </span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>=</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> 0.1 </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>if</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> i </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>&lt;</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> 150000 </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>else</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> 0.01 </span><span
style='font-style:italic;font-family:Consolas;color:#212121' lang=zh-CN># step
learning rate decay</span><span style='font-family:Consolas;color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
font-family:Consolas;color:#212121' lang=zh-CN>for</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> p </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>in</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> parameters:<br>
<span style='mso-spacerun:yes'>    </span>p</span><span style='font-weight:
bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>data </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>+= -</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>lr </span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>*</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN> p</span><span
style='font-weight:bold;font-family:Consolas;color:#212121' lang=zh-CN>.</span><span
style='font-family:Consolas;color:#212121' lang=zh-CN>grad</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-style:italic'># track stats</span><br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>if</span>
i <span style='font-weight:bold'>%</span> 10000 <span style='font-weight:bold'>==</span>
0: <span style='font-style:italic'># print every once in a while</span><br>
<span style='mso-spacerun:yes'>    </span>print(f'{i:7d}/{max_steps:7d}: {loss<span
style='font-weight:bold'>.</span>item():.4f}')<br>
<span style='mso-spacerun:yes'>  </span>lossi<span style='font-weight:bold'>.</span>append(loss<span
style='font-weight:bold'>.</span>log10()<span style='font-weight:bold'>.</span>item())<br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>with</span>
torch<span style='font-weight:bold'>.</span>no_grad():<br>
<span style='mso-spacerun:yes'>    </span>ud<span style='font-weight:bold'>.</span>append([((lr<span
style='font-weight:bold'>*</span>p<span style='font-weight:bold'>.</span>grad)<span
style='font-weight:bold'>.</span>std() <span style='font-weight:bold'>/</span>
p<span style='font-weight:bold'>.</span>data<span style='font-weight:bold'>.</span>std())<span
style='font-weight:bold'>.</span>log10()<span style='font-weight:bold'>.</span>item()
<span style='font-weight:bold'>for</span> p <span style='font-weight:bold'>in</span>
parameters])</p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-weight:bold'>if</span> i <span style='font-weight:bold'>&gt;=</span>
1000:<br>
<span style='mso-spacerun:yes'>    </span><span style='font-weight:bold'>break </span><span
style='font-style:italic'># AFTER_DEBUG: would take out obviously to run full
optimization</span></p>

<p style='margin:0in;line-height:12pt;font-family:Consolas;font-size:12.0pt;
color:#212121'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#212121'><span
style='font-weight:bold' lang=zh-CN>可视化各层的激活值，</span><span style='font-weight:
bold' lang=en-US>forward</span><span style='font-weight:bold' lang=zh-CN>方向</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-style:italic'># visualize histograms</span><br>
plt<span style='font-weight:bold'>.</span>figure(figsize<span style='font-weight:
bold'>=</span>(20, 4)) <span style='font-style:italic'># width and height of
the plot</span><br>
legends <span style='font-weight:bold'>=</span> []<br>
<span style='font-weight:bold'>for</span> i, layer <span style='font-weight:
bold'>in</span> enumerate(layers[:<span style='font-weight:bold'>-</span>1]): <span
style='font-style:italic'># note: exclude the output layer</span><br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>if</span>
isinstance(layer, Tanh):<br>
<span style='mso-spacerun:yes'>    </span>t <span style='font-weight:bold'>=</span>
layer<span style='font-weight:bold'>.</span>out<br>
<span style='mso-spacerun:yes'>    </span>print('layer %d (%10s): mean %+.2f,
std %.2f, saturated: %.2f%%' <span style='font-weight:bold'>%</span> (i, layer<span
style='font-weight:bold'>.</span>__class__<span style='font-weight:bold'>.</span>__name__,
t<span style='font-weight:bold'>.</span>mean(), t<span style='font-weight:bold'>.</span>std(),
(t<span style='font-weight:bold'>.</span>abs() <span style='font-weight:bold'>&gt;</span>
0.97)<span style='font-weight:bold'>.</span>float()<span style='font-weight:
bold'>.</span>mean()<span style='font-weight:bold'>*</span>100))<br>
<span style='mso-spacerun:yes'>    </span>hy, hx <span style='font-weight:bold'>=</span>
torch<span style='font-weight:bold'>.</span>histogram(t, density<span
style='font-weight:bold'>=True</span>)<br>
<span style='mso-spacerun:yes'>    </span>plt<span style='font-weight:bold'>.</span>plot(hx[:<span
style='font-weight:bold'>-</span>1]<span style='font-weight:bold'>.</span>detach(),
hy<span style='font-weight:bold'>.</span>detach())<br>
<span style='mso-spacerun:yes'>    </span>legends<span style='font-weight:bold'>.</span>append(f'layer
{i} ({layer<span style='font-weight:bold'>.</span>__class__<span
style='font-weight:bold'>.</span>__name__}')<br>
plt<span style='font-weight:bold'>.</span>legend(legends);<br>
plt<span style='font-weight:bold'>.</span>title('activation distribution')</p>

<p style='margin:0in;font-size:12.0pt;color:#212121'><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>我们希望各层的激活值，也就是</span><span style='font-family:
Calibri' lang=en-US>tanh</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>的输出不要落在接近</span><span style='font-family:"Microsoft YaHei"'
lang=en-US>-1</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>或</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>1</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>的区域，因为该区域梯度为</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>0</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，</span></p>

<p style='margin:0in;font-size:12.0pt;color:#212121'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>我们不希望如下的结果，各层的饱和率太高，各层的激活值大部分落在接近</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>-1</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>和</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>1</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的区域</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
1 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.04, std 0.80,
saturated: 30.34%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
3 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.01, std 0.77,
saturated: 20.75%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
5 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.01, std 0.78,
saturated: 22.75%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
7 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.05, std 0.78,
saturated: 21.50%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
9 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.00, std 0.77,
saturated: 20.38%</p>

<p style='margin:0in'><img src="Build%20makemore.files/image001.png"
width=1064 height=250></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>我们希望如下图的结果，</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
1 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.04, std 0.64,
saturated: 5.19%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
3 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.01, std 0.54,
saturated: 0.41%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
5 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.01, std 0.53,
saturated: 0.47%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
7 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.02, std 0.53,
saturated: 0.28%</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
9 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.01, std 0.54,
saturated: 0.25%</p>

<p style='margin:0in'><img src="Build%20makemore.files/image002.png"
width=1069 height=249></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#212121'><span
style='font-weight:bold' lang=zh-CN>可视化各输出的梯度值，back</span><span
style='font-weight:bold' lang=en-US>ward</span><span style='font-weight:bold'
lang=zh-CN>方向</span></p>

<p style='margin:0in;font-family:Consolas;font-size:12.0pt;color:#212121'><span
style='font-style:italic'># visualize histograms</span><br>
plt<span style='font-weight:bold'>.</span>figure(figsize<span style='font-weight:
bold'>=</span>(20, 4)) <span style='font-style:italic'># width and height of
the plot</span><br>
legends <span style='font-weight:bold'>=</span> []<br>
<span style='font-weight:bold'>for</span> i, layer <span style='font-weight:
bold'>in</span> enumerate(layers[:<span style='font-weight:bold'>-</span>1]): <span
style='font-style:italic'># note: exclude the output layer</span><br>
<span style='mso-spacerun:yes'>  </span><span style='font-weight:bold'>if</span>
isinstance(layer, Tanh):<br>
<span style='mso-spacerun:yes'>    </span>t <span style='font-weight:bold'>=</span>
layer<span style='font-weight:bold'>.</span>out<span style='font-weight:bold'>.</span>grad<br>
<span style='mso-spacerun:yes'>    </span>print('layer %d (%10s): mean %+f, std
%e' <span style='font-weight:bold'>%</span> (i, layer<span style='font-weight:
bold'>.</span>__class__<span style='font-weight:bold'>.</span>__name__, t<span
style='font-weight:bold'>.</span>mean(), t<span style='font-weight:bold'>.</span>std()))<br>
<span style='mso-spacerun:yes'>    </span>hy, hx <span style='font-weight:bold'>=</span>
torch<span style='font-weight:bold'>.</span>histogram(t, density<span
style='font-weight:bold'>=True</span>)<br>
<span style='mso-spacerun:yes'>    </span>plt<span style='font-weight:bold'>.</span>plot(hx[:<span
style='font-weight:bold'>-</span>1]<span style='font-weight:bold'>.</span>detach(),
hy<span style='font-weight:bold'>.</span>detach())<br>
<span style='mso-spacerun:yes'>    </span>legends<span style='font-weight:bold'>.</span>append(f'layer
{i} ({layer<span style='font-weight:bold'>.</span>__class__<span
style='font-weight:bold'>.</span>__name__}')<br>
plt<span style='font-weight:bold'>.</span>legend(legends);<br>
plt<span style='font-weight:bold'>.</span>title('gradient distribution')</p>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>我们希望各层out的梯度值，是均匀的，而不是有些层梯度过大，有些层梯度过小，</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'><span
lang=zh-CN>我们不希望如下</span><span lang=en-US> </span><span lang=zh-CN>的结果：前面几层梯度大，越往后面层梯度过小</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
1 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.000086, std
1.620851e-02</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
3 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000071, std
1.012546e-02</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
5 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000057, std
5.541695e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
7 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000013, std
3.469306e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
9 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000030, std
2.318119e-03</p>

<p style='margin:0in'><img src="Build%20makemore.files/image003.png"
width=1129 height=262></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>我们希望如下的结果：</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
1 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000033, std
2.641852e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
3 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000043, std
2.440831e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
5 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.000004, std
2.338152e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
7 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000006, std
2.283551e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
9 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000040, std
2.059027e-03</p>

<p style='margin:0in'><img src="Build%20makemore.files/image004.png"
width=1120 height=260></p>

<p style='margin:0in;line-height:12pt;font-family:"Microsoft YaHei";font-size:
12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;line-height:14pt;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt'><span style='font-weight:bold;
font-family:微软雅黑' lang=zh-CN>参数</span><span style='font-weight:bold;font-family:
Calibri' lang=en-US>w</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>的</span><span style='font-weight:bold;font-family:Calibri'
lang=en-US>scale</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>及</span><span style='font-weight:bold;font-family:Calibri'
lang=en-US>w</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>的梯度的</span><span style='font-weight:bold;font-family:Calibri'
lang=en-US>scale</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:green'>#
visualize histograms</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>plt.figure(figsize=(</span><span style='color:#116644'>20</span><span
style='color:black'>, </span><span style='color:#116644'>4</span><span
style='color:black'>)) </span><span style='color:green'># width and height of
the plot</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:black'>legends
= []</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:#AF00DB'>for</span><span style='color:black'> i,p </span><span
style='color:blue'>in </span><span style='color:#795E26'>enumerate</span><span
style='color:black'>(parameters):</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:black'>&nbsp;
t = p.grad</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>&nbsp; </span><span style='color:#AF00DB'>if</span><span
style='color:black'> p.ndim == </span><span style='color:#116644'>2</span><span
style='color:black'>:</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>&nbsp; &nbsp; </span><span style='color:#795E26'>print</span><span
style='color:black'>(</span><span style='color:#A31515'>'weight %10s | mean %+f
| std %e | grad:data ratio %e'</span><span style='color:black'> % (</span><span
style='color:#257693'>tuple</span><span style='color:black'>(p.shape),
t.mean(), t.std(), t.std() / p.std()))</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>&nbsp; &nbsp; hy, hx = torch.histogram(t, density=</span><span
style='color:blue'>True</span><span style='color:black'>)</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>&nbsp; &nbsp; plt.plot(hx[:</span><span style='color:#116644'>-1</span><span
style='color:black'>].detach(), hy.detach())</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>&nbsp; &nbsp; legends.append(</span><span style='color:
blue'>f</span><span style='color:#A31515'>'</span><span style='color:black'>{i}
{</span><span style='color:#257693'>tuple</span><span style='color:black'>(p.shape)}</span><span
style='color:#A31515'>'</span><span style='color:black'>)</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:black'>plt.legend(legends)</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:black'>plt.title(</span><span style='color:#A31515'>'weights
gradient distribution'</span><span style='color:black'>);</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:black'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
1 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000033, std
2.641852e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
3 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000043, std
2.440831e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
5 (<span style='mso-spacerun:yes'>      </span>Tanh): mean -0.000004, std
2.338152e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
7 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000006, std
2.283551e-03</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#212121'>layer
9 (<span style='mso-spacerun:yes'>      </span>Tanh): mean +0.000040, std
2.059027e-03</p>

<p style='margin:0in;font-size:12.0pt;color:#212121'><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>我们希望</span><span style='font-family:Calibri'
lang=en-US>w.grad.std()/w.std()</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>的</span><span style='font-family:Calibri' lang=en-US>ratio</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>在</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>1</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>e</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>-3</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>左右。也就是不希望</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>w.grad</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>相比于</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>w</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>变化太快。</span></p>

<p style='margin:0in;line-height:12pt;font-family:"Microsoft YaHei";font-size:
12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#212121'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>总结：加了</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>batchnorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>后，模型训练</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US> </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>变得</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>robust</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，不需要考虑如何初始化参数，以及</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>gain</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>w=w*fan_in**0.05</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>这些。</span></p>

<p style='margin:0in;line-height:12pt;font-family:"Microsoft YaHei";font-size:
12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;line-height:12pt;font-family:"Microsoft YaHei";font-size:
12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;line-height:12pt;font-family:"Microsoft YaHei";font-size:
12.0pt;color:#212121'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#0F0F0F'><span
style='font-weight:bold'>Building makemore Part 5: Building a WaveNet</span></p>

<p style='margin:0in'><img src="Build%20makemore.files/image005.png" width=823
height=364></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#C00000'><span
style='font-weight:bold' lang=zh-CN>★上图中红框表示</span><span style='font-weight:
bold' lang=en-US> linear</span><span style='font-weight:bold' lang=zh-CN>层，</span><span
style='font-weight:bold' lang=en-US>8</span><span style='font-weight:bold'
lang=zh-CN>个</span><span style='font-weight:bold' lang=en-US>linear</span><span
style='font-weight:bold' lang=zh-CN>层的参数是共享的。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-style:
italic;color:#59636E' lang=zh-CN>#
-----------------------------------------------------------------------------------------------</span><span
style='color:#212121' lang=zh-CN><br>
</span><span style='font-weight:bold;color:#C00000' lang=en-US>Linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层的定义不需要改变，</span><span
style='font-weight:bold;color:#C00000' lang=en-US>linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层的核心是self.out = x @
self.weight，本质是</span><span style='font-weight:bold;color:#C00000' lang=en-US>pytorch</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>矩阵乘法，而矩阵乘法不需要两个矩阵都是</span><span
style='font-weight:bold;color:#C00000' lang=en-US>2</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>维的，只需要保证第一个矩阵的最后一维的维数和第二个矩阵第一个维度的维数相等即可。利用这个性质，当需要将输入</span><span
style='font-weight:bold;color:#C00000' lang=en-US>x</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>两两一组进行分组，然后将分组后的数据输入到</span><span
style='font-weight:bold;color:#C00000' lang=en-US>Linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层时，可以只创建一个</span><span
style='font-weight:bold;color:#C00000' lang=en-US>linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层，即参数共享</span><span
style='font-weight:bold;color:#C00000' lang=en-US>+</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>并行，而不是创建</span><span
style='font-weight:bold;color:#C00000' lang=en-US>context_length/2</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>个</span><span
style='font-weight:bold;color:#C00000' lang=en-US>linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层，（当然也可以实现创建</span><span
style='font-weight:bold;color:#C00000' lang=en-US>context_length/2</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>个</span><span
style='font-weight:bold;color:#C00000' lang=en-US>linear</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>层）。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>class Linear</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span>def __init__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> fan_in</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> fan_out</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> bias</span><span
style='color:#8250DF'>=</span><span style='color:#212121'>True</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>weight </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> torch</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>randn</span><span style='color:#0055AA'>((</span><span
style='color:#212121'>fan_in</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> fan_out</span><span style='color:#0055AA'>)) </span><span
style='color:#8250DF'>/</span><span style='color:#212121'> fan_in</span><span
style='color:#8250DF'>**</span><span style='color:#212121'>0.5 </span><span
style='font-style:italic;color:#59636E'># note: kaiming init</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>bias </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> torch</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>zeros</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>fan_out</span><span style='color:#0055AA'>)</span><span
style='color:#212121'> if bias else None<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span>def __call__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> x</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>out </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> x </span><span style='color:#8250DF'>@</span><span
style='color:#212121'> self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>weight<br>
<span style='mso-spacerun:yes'>    </span>if self</span><span style='color:
#8250DF'>.</span><span style='color:#212121'>bias </span><span
style='color:#8250DF'>is not</span><span style='color:#212121'> None</span><span
style='color:#0055AA'>:</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>      </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>out </span><span style='color:#8250DF'>+=</span><span
style='color:#212121'> self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>bias<br>
<span style='mso-spacerun:yes'>    </span>return self</span><span
style='color:#8250DF'>.</span><span style='color:#212121'>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span>def parameters</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>return </span><span style='color:
#0055AA'>[</span><span style='color:#212121'>self</span><span style='color:
#8250DF'>.</span><span style='color:#212121'>weight</span><span
style='color:#0055AA'>] </span><span style='color:#8250DF'>+ </span><span
style='color:#0055AA'>([]</span><span style='color:#212121'> if self</span><span
style='color:#8250DF'>.</span><span style='color:#212121'>bias </span><span
style='color:#8250DF'>is</span><span style='color:#212121'> None else </span><span
style='color:#0055AA'>[</span><span style='color:#212121'>self</span><span
style='color:#8250DF'>.</span><span style='color:#212121'>bias</span><span
style='color:#0055AA'>])</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-style:
italic;color:#59636E' lang=zh-CN>#
-----------------------------------------------------------------------------------------------</span><span
style='color:#212121' lang=zh-CN><br>
</span><span style='font-weight:bold;color:#1A7F37' lang=zh-CN>class</span><span
style='color:#212121' lang=zh-CN> BatchNorm1d</span><span style='color:#0055AA'
lang=zh-CN>:</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>def</span><span style='color:#212121' lang=zh-CN>
__init__</span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#212121' lang=zh-CN>self</span><span style='color:#0055AA'
lang=zh-CN>,</span><span style='color:#212121' lang=zh-CN> dim</span><span
style='color:#0055AA' lang=zh-CN>,</span><span style='color:#212121'
lang=zh-CN> eps</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#1A7F37' lang=zh-CN>1e-5</span><span style='color:#0055AA'
lang=zh-CN>,</span><span style='color:#212121' lang=zh-CN> momentum</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#1A7F37' lang=zh-CN>0.1</span><span style='color:#0055AA'
lang=zh-CN>):</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>eps
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> eps<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>momentum
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> momentum<br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>training
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>= </span><span
style='font-weight:bold;color:#1A7F37' lang=zh-CN>True</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
color:#59636E' lang=zh-CN># parameters (trained with backprop)</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>gamma
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> torch</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>ones</span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#212121'
lang=zh-CN>dim</span><span style='color:#0055AA' lang=zh-CN>)</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>beta
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> torch</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>zeros</span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#212121'
lang=zh-CN>dim</span><span style='color:#0055AA' lang=zh-CN>)</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
color:#59636E' lang=zh-CN># buffers (trained with a running 'momentum update')</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>running_mean
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> torch</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>zeros</span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#212121'
lang=zh-CN>dim</span><span style='color:#0055AA' lang=zh-CN>)</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>running_var
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> torch</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>ones</span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#212121'
lang=zh-CN>dim</span><span style='color:#0055AA' lang=zh-CN>)</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>def</span><span style='color:#212121' lang=zh-CN>
__call__</span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#212121' lang=zh-CN>self</span><span style='color:#0055AA'
lang=zh-CN>,</span><span style='color:#212121' lang=zh-CN> x</span><span
style='color:#0055AA' lang=zh-CN>):</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
color:#59636E' lang=zh-CN># calculate the forward pass</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>if</span><span style='color:#212121' lang=zh-CN> self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>training</span><span style='color:#0055AA'
lang=zh-CN>:</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span></span><span style='font-weight:
bold;color:#1A7F37' lang=zh-CN>if</span><span style='color:#212121' lang=zh-CN>
x</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>ndim </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>== </span><span style='color:#1A7F37' lang=zh-CN>2</span><span
style='color:#0055AA' lang=zh-CN>:</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>        </span>dim </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>= </span><span
style='color:#1A7F37' lang=zh-CN>0</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span></span><span style='font-weight:
bold;color:#1A7F37' lang=zh-CN>elif</span><span style='color:#212121'
lang=zh-CN> x</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>ndim </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>== </span><span style='color:#1A7F37' lang=zh-CN>3</span><span
style='color:#0055AA' lang=zh-CN>:</span><span style='color:#0055AA'
lang=en-US><span style='mso-spacerun:yes'>    </span></span><span
style='color:#C00000' lang=en-US>★</span><span style='font-weight:bold;
color:#C00000' lang=zh-CN>注意这里</span><span style='font-weight:bold;color:#C00000'
lang=en-US>batchnorm</span><span style='font-weight:bold;color:#C00000'
lang=zh-CN>的实现和我理解总结的</span><span style='font-weight:bold;color:#C00000'
lang=en-US>pytorch</span><span style='font-weight:bold;color:#C00000'
lang=zh-CN>的</span><span style='font-weight:bold;color:#C00000' lang=en-US>batchnorm</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>用法一致，</span><span
style='font-weight:bold;color:#C00000' lang=en-US>nlp</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>中</span><span
style='font-weight:bold;color:#C00000' lang=en-US>feature</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>个数是</span><span
style='font-weight:bold;color:#C00000' lang=en-US>n_embedding</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>的个数，统计均值时，计算的时当前</span><span
style='font-weight:bold;color:#C00000' lang=en-US>batch</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>中所有句子的所有</span><span
style='font-weight:bold;color:#C00000' lang=en-US>token</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>的某一维</span><span
style='font-weight:bold;color:#C00000' lang=en-US>embedding</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>的均值。</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>        </span>dim </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>= </span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#1A7F37'
lang=zh-CN>0</span><span style='color:#0055AA' lang=zh-CN>,</span><span
style='color:#1A7F37' lang=zh-CN>1</span><span style='color:#0055AA'
lang=zh-CN>)</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span>xmean </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> x</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>mean</span><span
style='color:#0055AA' lang=zh-CN>(</span><span style='color:#212121'
lang=zh-CN>dim</span><span style='color:#0055AA' lang=zh-CN>,</span><span
style='color:#212121' lang=zh-CN> keepdim</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>=</span><span style='font-weight:bold;color:#1A7F37'
lang=zh-CN>True</span><span style='color:#0055AA' lang=zh-CN>) </span><span
style='font-style:italic;color:#59636E' lang=zh-CN># batch mean</span><span
style='font-style:italic;color:#59636E' lang=en-US> </span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span>xvar </span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>=</span><span style='color:#212121' lang=zh-CN>
x</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>var</span><span style='color:#0055AA'
lang=zh-CN>(</span><span style='color:#212121' lang=zh-CN>dim</span><span
style='color:#0055AA' lang=zh-CN>,</span><span style='color:#212121'
lang=zh-CN> keepdim</span><span style='font-weight:bold;color:#8250DF'
lang=zh-CN>=</span><span style='font-weight:bold;color:#1A7F37' lang=zh-CN>True</span><span
style='color:#0055AA' lang=zh-CN>) </span><span style='font-style:italic;
color:#59636E' lang=zh-CN># batch variance</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>else</span><span style='color:#0055AA' lang=zh-CN>:</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span>xmean </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>running_mean<br>
<span style='mso-spacerun:yes'>      </span>xvar </span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>=</span><span style='color:#212121' lang=zh-CN>
self</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>running_var<br>
<span style='mso-spacerun:yes'>    </span>xhat </span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>= </span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#212121' lang=zh-CN>x </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>-</span><span style='color:#212121' lang=zh-CN> xmean</span><span
style='color:#0055AA' lang=zh-CN>) </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>/</span><span style='color:#212121' lang=zh-CN> torch</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>sqrt</span><span style='color:#0055AA'
lang=zh-CN>(</span><span style='color:#212121' lang=zh-CN>xvar </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>+</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>eps</span><span
style='color:#0055AA' lang=zh-CN>) </span><span style='font-style:italic;
color:#59636E' lang=zh-CN># normalize to unit variance</span><span
style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>out
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>=</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>gamma </span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>*</span><span
style='color:#212121' lang=zh-CN> xhat </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>+</span><span style='color:#212121' lang=zh-CN> self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>beta<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
color:#59636E' lang=zh-CN># update the buffers</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>if</span><span style='color:#212121' lang=zh-CN> self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>training</span><span style='color:#0055AA'
lang=zh-CN>:</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>      </span></span><span style='font-weight:
bold;color:#1A7F37' lang=zh-CN>with</span><span style='color:#212121'
lang=zh-CN> torch</span><span style='font-weight:bold;color:#8250DF'
lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>no_grad</span><span
style='color:#0055AA' lang=zh-CN>():</span><span style='color:#212121'
lang=zh-CN><br>
<span style='mso-spacerun:yes'>        </span>self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>running_mean </span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>= </span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#1A7F37' lang=zh-CN>1 </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>-</span><span style='color:#212121' lang=zh-CN> self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>momentum</span><span style='color:#0055AA'
lang=zh-CN>) </span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>*</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>running_mean
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>+</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>momentum
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>*</span><span
style='color:#212121' lang=zh-CN> xmean<br>
<span style='mso-spacerun:yes'>        </span>self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>running_var </span><span style='font-weight:
bold;color:#8250DF' lang=zh-CN>= </span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#1A7F37' lang=zh-CN>1 </span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>-</span><span style='color:#212121' lang=zh-CN> self</span><span
style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>momentum</span><span style='color:#0055AA'
lang=zh-CN>) </span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>*</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>running_var
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>+</span><span
style='color:#212121' lang=zh-CN> self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>momentum
</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>*</span><span
style='color:#212121' lang=zh-CN> xvar<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>return</span><span style='color:#212121' lang=zh-CN>
self</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>def</span><span style='color:#212121' lang=zh-CN>
parameters</span><span style='color:#0055AA' lang=zh-CN>(</span><span
style='color:#212121' lang=zh-CN>self</span><span style='color:#0055AA'
lang=zh-CN>):</span><span style='color:#212121' lang=zh-CN><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37' lang=zh-CN>return </span><span style='color:#0055AA' lang=zh-CN>[</span><span
style='color:#212121' lang=zh-CN>self</span><span style='font-weight:bold;
color:#8250DF' lang=zh-CN>.</span><span style='color:#212121' lang=zh-CN>gamma</span><span
style='color:#0055AA' lang=zh-CN>,</span><span style='color:#212121'
lang=zh-CN> self</span><span style='font-weight:bold;color:#8250DF' lang=zh-CN>.</span><span
style='color:#212121' lang=zh-CN>beta</span><span style='color:#0055AA'
lang=zh-CN>]</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-style:
italic;color:#59636E'>#
-----------------------------------------------------------------------------------------------</span><span
style='color:#212121'><br>
</span><span style='font-weight:bold;color:#1A7F37'>class</span><span
style='color:#212121'> Tanh</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37'>def</span><span style='color:#212121'> __call__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> x</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF'>.</span><span style='color:#212121'>out </span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='color:#212121'>
torch</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>tanh</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>x</span><span style='color:#0055AA'>)</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37'>return</span><span style='color:#212121'> self</span><span
style='font-weight:bold;color:#8250DF'>.</span><span style='color:#212121'>out<br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37'>def</span><span style='color:#212121'> parameters</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37'>return </span><span style='color:#0055AA'>[]</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#59636E'><span
style='font-style:italic'>#
-----------------------------------------------------------------------------------------------</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#C00000'><span
style='font-weight:bold' lang=zh-CN>定义</span><span style='font-weight:bold'
lang=en-US>E</span><span style='font-weight:bold' lang=zh-CN>m</span><span
style='font-weight:bold' lang=en-US>bedding</span><span style='font-weight:
bold' lang=zh-CN>层，原来</span><span style='font-weight:bold' lang=en-US>E</span><span
style='font-weight:bold' lang=zh-CN>mbe</span><span style='font-weight:bold'
lang=en-US>dding</span><span style='font-weight:bold' lang=zh-CN>层就是个权重表。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>class Embedding</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span>def __init__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> num_embeddings</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> embedding_dim</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>weight </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> torch</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>randn</span><span style='color:#0055AA'>((</span><span
style='color:#212121'>num_embeddings</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> embedding_dim</span><span style='color:#0055AA'>))</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span><br>
<span style='mso-spacerun:yes'>  </span>def __call__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> IX</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>out </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>weight</span><span style='color:#0055AA'>[</span><span
style='color:#212121'>IX</span><span style='color:#0055AA'>]</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>return self</span><span
style='color:#8250DF'>.</span><span style='color:#212121'>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span>def parameters</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>return </span><span style='color:
#0055AA'>[</span><span style='color:#212121'>self</span><span style='color:
#8250DF'>.</span><span style='color:#212121'>weight</span><span
style='color:#0055AA'>]</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#59636E'><span
style='font-style:italic'>#
-----------------------------------------------------------------------------------------------</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#C00000'><span
style='font-weight:bold' lang=zh-CN>FlattenConsecutive的作用：输入</span><span
style='font-weight:bold' lang=en-US>x</span><span style='font-weight:bold'
lang=zh-CN>的</span><span style='font-weight:bold' lang=en-US>shape</span><span
style='font-weight:bold' lang=zh-CN>是</span><span style='font-weight:bold'
lang=en-US> B,T,C</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>B</span><span style='font-weight:bold'
lang=zh-CN>是</span><span style='font-weight:bold' lang=en-US>batchsize</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>T</span><span style='font-weight:bold' lang=zh-CN>是</span><span
style='font-weight:bold' lang=en-US>context_length</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>C</span><span style='font-weight:bold' lang=zh-CN>是</span><span
style='font-weight:bold' lang=en-US>n_embedding</span><span style='font-weight:
bold' lang=zh-CN>，在</span><span style='font-weight:bold' lang=en-US>build
makemore mlp</span><span style='font-weight:bold' lang=zh-CN>部分中，是将</span><span
style='font-weight:bold' lang=en-US>context_length</span><span
style='font-weight:bold' lang=zh-CN>个字母的</span><span style='font-weight:bold'
lang=en-US>embedding</span><span style='font-weight:bold' lang=zh-CN>直接</span><span
style='font-weight:bold' lang=en-US>concat</span><span style='font-weight:bold'
lang=zh-CN>起来，即输出的</span><span style='font-weight:bold' lang=en-US>shape</span><span
style='font-weight:bold' lang=zh-CN>是</span><span style='font-weight:bold'
lang=en-US> B</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>T*C</span><span style='font-weight:bold'
lang=zh-CN>。而</span><span style='font-weight:bold' lang=en-US>wavenet</span><span
style='font-weight:bold' lang=zh-CN>现在需要将</span><span style='font-weight:bold'
lang=en-US>context_length</span><span style='font-weight:bold' lang=zh-CN>个字母进行相邻字母两两组合，输出的</span><span
style='font-weight:bold' lang=en-US>shape</span><span style='font-weight:bold'
lang=zh-CN>是</span><span style='font-weight:bold' lang=en-US> B</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>T//2</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>C*2</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#1A7F37'>class</span><span style='color:#212121'> FlattenConsecutive</span><span
style='color:#0055AA'>:</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='color:#1A7F37'>def</span><span
style='color:#212121'> __init__</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>self</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> n</span><span style='color:#0055AA'>):</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>n </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> n<br>
<span style='mso-spacerun:yes'>    </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='color:#1A7F37'>def</span><span
style='color:#212121'> __call__</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>self</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> x</span><span style='color:#0055AA'>):</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>B</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> T</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> C </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> x</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>shape<br>
<span style='mso-spacerun:yes'>    </span>x </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> x</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>view</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>B</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> T</span><span style='color:#8250DF'>//</span><span
style='color:#212121'>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>n</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> C</span><span style='color:#8250DF'>*</span><span
style='color:#212121'>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>n</span><span style='color:#0055AA'>)</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='color:#1A7F37'>if</span><span
style='color:#212121'> x</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>shape</span><span style='color:#0055AA'>[</span><span
style='color:#1A7F37'>1</span><span style='color:#0055AA'>] </span><span
style='color:#8250DF'>== </span><span style='color:#1A7F37'>1</span><span
style='color:#0055AA'>:</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>      </span>x </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> x</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>squeeze</span><span style='color:#0055AA'>(</span><span
style='color:#1A7F37'>1</span><span style='color:#0055AA'>)</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>out </span><span style='color:#8250DF'>=</span><span
style='color:#212121'> x<br>
<span style='mso-spacerun:yes'>    </span></span><span style='color:#1A7F37'>return</span><span
style='color:#212121'> self</span><span style='color:#8250DF'>.</span><span
style='color:#212121'>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='color:#1A7F37'>def</span><span
style='color:#212121'> parameters</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>self</span><span style='color:#0055AA'>):</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='color:#1A7F37'>return
</span><span style='color:#0055AA'>[]</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-style:
italic;color:#59636E'>#
-----------------------------------------------------------------------------------------------</span><span
style='color:#212121'><br>
</span><span style='font-weight:bold;color:#1A7F37'>class</span><span
style='color:#212121'> Sequential</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37'>def</span><span style='color:#212121'> __init__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> layers</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF'>.</span><span style='color:#212121'>layers </span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='color:#212121'>
layers<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37'>def</span><span style='color:#212121'> __call__</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> x</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37'>for</span><span style='color:#212121'> layer </span><span
style='font-weight:bold;color:#8250DF'>in</span><span style='color:#212121'>
self</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>layers</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>      </span>x </span><span style='font-weight:
bold;color:#8250DF'>=</span><span style='color:#212121'> layer</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>x</span><span
style='color:#0055AA'>)</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>self</span><span style='font-weight:
bold;color:#8250DF'>.</span><span style='color:#212121'>out </span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='color:#212121'>
x<br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37'>return</span><span style='color:#212121'> self</span><span
style='font-weight:bold;color:#8250DF'>.</span><span style='color:#212121'>out<br>
<span style='mso-spacerun:yes'>  </span><br>
<span style='mso-spacerun:yes'>  </span></span><span style='font-weight:bold;
color:#1A7F37'>def</span><span style='color:#212121'> parameters</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>self</span><span
style='color:#0055AA'>):</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-style:italic;
color:#59636E'># get parameters of all layers and stretch them out into one
list</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span></span><span style='font-weight:bold;
color:#1A7F37'>return </span><span style='color:#0055AA'>[</span><span
style='color:#212121'>p </span><span style='font-weight:bold;color:#1A7F37'>for</span><span
style='color:#212121'> layer </span><span style='font-weight:bold;color:#8250DF'>in</span><span
style='color:#212121'> self</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>layers </span><span style='font-weight:bold;color:#1A7F37'>for</span><span
style='color:#212121'> p </span><span style='font-weight:bold;color:#8250DF'>in</span><span
style='color:#212121'> layer</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>parameters</span><span style='color:#0055AA'>()]</span></p>

<p style='margin:0in;line-height:12pt;font-family:微软雅黑;font-size:12.0pt;
color:#0055AA'>&nbsp;</p>

<p style='margin:0in;line-height:12pt;font-family:微软雅黑;font-size:12.0pt;
color:#0055AA'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-weight:
bold'>开始构建模型</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>torch</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>manual_seed</span><span style='color:#0055AA'>(</span><span
style='color:#1A7F37'>42</span><span style='color:#0055AA'>); </span><span
style='font-style:italic;color:#59636E'># seed rng for reproducibility</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='font-style:
italic;color:#59636E'># original network</span><span style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'># n_embd = 10 # the
dimensionality of the character embedding vectors</span><span style='color:
#212121'><br>
</span><span style='font-style:italic;color:#59636E'># n_hidden = 300 # the
number of neurons in the hidden layer of the MLP</span><span style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'># model = Sequential([</span><span
style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'>#<span
style='mso-spacerun:yes'>   </span>Embedding(vocab_size, n_embd),</span><span
style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'>#<span
style='mso-spacerun:yes'>   </span>FlattenConsecutive(8), Linear(n_embd * 8,
n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),</span><span
style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'>#<span
style='mso-spacerun:yes'>   </span>Linear(n_hidden, vocab_size),</span><span
style='color:#212121'><br>
</span><span style='font-style:italic;color:#59636E'># ])</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#59636E'><span
style='font-style:italic'># hierarchical network</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>block_size </span><span style='font-weight:bold;color:#8250DF'>= </span><span
style='color:#1A7F37'>8 </span><span style='font-style:italic;color:#59636E'>#
context length: how many characters do we take to predict the next one?</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>n_embd </span><span style='font-weight:bold;color:#8250DF'>= </span><span
style='color:#1A7F37'>24 </span><span style='font-style:italic;color:#59636E'>#
the dimensionality of the character embedding vectors</span><span
style='color:#212121'><br>
n_hidden </span><span style='font-weight:bold;color:#8250DF'>= </span><span
style='color:#1A7F37'>128 </span><span style='font-style:italic;color:#59636E'>#
the number of neurons in the hidden layer of the MLP</span><span
style='color:#212121'><br>
model </span><span style='font-weight:bold;color:#8250DF'>=</span><span
style='color:#212121'> Sequential</span><span style='color:#0055AA'>([</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>Embedding</span><span style='color:
#0055AA'>(</span><span style='color:#212121'>vocab_size</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> n_embd</span><span
style='color:#0055AA'>),</span><span style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>FlattenConsecutive</span><span
style='color:#0055AA'>(</span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>),</span><span style='color:#212121'> Linear</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>n_embd </span><span
style='font-weight:bold;color:#8250DF'>* </span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> n_hidden</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> bias</span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='font-weight:bold;
color:#1A7F37'>False</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> BatchNorm1d</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>n_hidden</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> Tanh</span><span style='color:#0055AA'>(),</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>FlattenConsecutive</span><span
style='color:#0055AA'>(</span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>),</span><span style='color:#212121'> Linear</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>n_hidden</span><span
style='font-weight:bold;color:#8250DF'>*</span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> n_hidden</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> bias</span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='font-weight:bold;
color:#1A7F37'>False</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> BatchNorm1d</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>n_hidden</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> Tanh</span><span style='color:#0055AA'>(),</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>FlattenConsecutive</span><span
style='color:#0055AA'>(</span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>),</span><span style='color:#212121'> Linear</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>n_hidden</span><span
style='font-weight:bold;color:#8250DF'>*</span><span style='color:#1A7F37'>2</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> n_hidden</span><span
style='color:#0055AA'>,</span><span style='color:#212121'> bias</span><span
style='font-weight:bold;color:#8250DF'>=</span><span style='font-weight:bold;
color:#1A7F37'>False</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> BatchNorm1d</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>n_hidden</span><span style='color:#0055AA'>),</span><span
style='color:#212121'> Tanh</span><span style='color:#0055AA'>(),</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>Linear</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>n_hidden</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> vocab_size</span><span style='color:#0055AA'>),</span><span
style='color:#212121'><br>
</span><span style='color:#0055AA'>])</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#C00000'><span
style='font-weight:bold' lang=zh-CN>输入</span><span style='font-weight:bold'
lang=en-US>x</span><span style='font-weight:bold' lang=zh-CN>的</span><span
style='font-weight:bold' lang=en-US>shape</span><span style='font-weight:bold'
lang=zh-CN>是</span><span style='font-weight:bold' lang=en-US>32</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>8</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>27</span><span style='font-weight:bold'
lang=zh-CN>，其中</span><span style='font-weight:bold' lang=en-US>32</span><span
style='font-weight:bold' lang=zh-CN>是</span><span style='font-weight:bold'
lang=en-US>batch_size</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>8</span><span style='font-weight:bold'
lang=zh-CN>是</span><span style='font-weight:bold' lang=en-US>block_size</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>27</span><span style='font-weight:bold' lang=zh-CN>是</span><span
style='font-weight:bold' lang=en-US>vocab_size</span><span style='font-weight:
bold' lang=zh-CN>。经过</span><span style='font-weight:bold' lang=en-US>model</span><span
style='font-weight:bold' lang=zh-CN>的变化历程为：首先经过</span><span style='font-weight:
bold' lang=en-US>Embedding</span><span style='font-weight:bold' lang=zh-CN>层，</span><span
style='font-weight:bold' lang=en-US>shape</span><span style='font-weight:bold'
lang=zh-CN>变为</span><span style='font-weight:bold' lang=en-US>32</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>8</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>24</span><span style='font-weight:bold'
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>24</span><span
style='font-weight:bold' lang=zh-CN>是</span><span style='font-weight:bold'
lang=en-US>n_embedding</span><span style='font-weight:bold' lang=zh-CN>，经过</span><span
style='font-weight:bold' lang=en-US> FlattenConsecutive(2)</span><span
style='font-weight:bold' lang=zh-CN>变为</span><span style='font-weight:bold'
lang=en-US>32</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>4</span><span style='font-weight:bold'
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>24*2</span><span
style='font-weight:bold' lang=zh-CN>，经过</span><span style='font-weight:bold'
lang=en-US> Linear(n_embd * 2, n_hidden, bias=False)</span><span
style='font-weight:bold' lang=zh-CN>变为</span><span style='font-weight:bold'
lang=en-US>32</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>4</span><span style='font-weight:bold'
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>n_hidden</span><span
style='font-weight:bold' lang=zh-CN>，然后</span><span style='font-weight:bold'
lang=en-US>Batchnorm</span><span style='font-weight:bold' lang=zh-CN>和</span><span
style='font-weight:bold' lang=en-US>tanh</span><span style='font-weight:bold'
lang=zh-CN>层不改变</span><span style='font-weight:bold' lang=en-US>shape</span><span
style='font-weight:bold' lang=zh-CN>，再次经过</span><span style='font-weight:bold'
lang=en-US>FlattenConsecutive(2)</span><span style='font-weight:bold'
lang=zh-CN>变为</span><span style='font-weight:bold' lang=en-US>32</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>2</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>n_hidden*2</span><span style='font-weight:
bold' lang=zh-CN>，经过</span><span style='font-weight:bold' lang=en-US>
Linear(n_hidden* 2, n_hidden, bias=False)</span><span style='font-weight:bold'
lang=zh-CN>变为</span><span style='font-weight:bold' lang=en-US>32</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>2</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>n_hidden</span><span style='font-weight:
bold' lang=zh-CN>，然后</span><span style='font-weight:bold' lang=en-US>Batchnorm</span><span
style='font-weight:bold' lang=zh-CN>和</span><span style='font-weight:bold'
lang=en-US>tanh</span><span style='font-weight:bold' lang=zh-CN>层不改变</span><span
style='font-weight:bold' lang=en-US>shape</span><span style='font-weight:bold'
lang=zh-CN>，再次经过</span><span style='font-weight:bold' lang=en-US>FlattenConsecutive(2)</span><span
style='font-weight:bold' lang=zh-CN>变为</span><span style='font-weight:bold'
lang=en-US>32</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>1</span><span style='font-weight:bold'
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>n_hidden*2</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>FlattenConsecutive</span><span style='font-weight:bold' lang=zh-CN>会把</span><span
style='font-weight:bold' lang=en-US>32</span><span style='font-weight:bold'
lang=zh-CN>，</span><span style='font-weight:bold' lang=en-US>1</span><span
style='font-weight:bold' lang=zh-CN>，</span><span style='font-weight:bold'
lang=en-US>n_hidden*2<span style='mso-spacerun:yes'>  </span>squeeze </span><span
style='font-weight:bold' lang=zh-CN>成</span><span style='font-weight:bold'
lang=en-US>32,n_hidden*2</span><span style='font-weight:bold' lang=zh-CN>，经过</span><span
style='font-weight:bold' lang=en-US> Linear(n_hidden* 2, n_hidden, bias=False)</span><span
style='font-weight:bold' lang=zh-CN>变为</span><span style='font-weight:bold'
lang=en-US> 32</span><span style='font-weight:bold' lang=zh-CN>，</span><span
style='font-weight:bold' lang=en-US>n_hidden</span><span style='font-weight:
bold' lang=zh-CN>，然后</span><span style='font-weight:bold' lang=en-US>Batchnorm</span><span
style='font-weight:bold' lang=zh-CN>和</span><span style='font-weight:bold'
lang=en-US>tanh</span><span style='font-weight:bold' lang=zh-CN>层不改变</span><span
style='font-weight:bold' lang=en-US>shape</span><span style='font-weight:bold'
lang=zh-CN>，最后经过</span><span style='font-weight:bold' lang=en-US>
Linear(n_hidden, vocab_size)</span><span style='font-weight:bold' lang=zh-CN>变为</span><span
style='font-weight:bold' lang=en-US> 32,vocab_size</span></p>

<p style='margin:0in;line-height:12pt;font-family:微软雅黑;font-size:12.0pt;
color:#C00000'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#7F7F7F'># parameter init</span><span style='font-weight:bold;color:#212121'><br>
</span><span style='font-weight:bold;color:#1A7F37'>with</span><span
style='font-weight:bold;color:#212121'> torch</span><span style='font-weight:
bold;color:#8250DF'>.</span><span style='font-weight:bold;color:#212121'>no_grad</span><span
style='font-weight:bold;color:#0055AA'>():</span><span style='font-weight:bold;
color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>model</span><span style='font-weight:
bold;color:#8250DF'>.</span><span style='font-weight:bold;color:#212121'>layers</span><span
style='font-weight:bold;color:#0055AA'>[</span><span style='font-weight:bold;
color:#8250DF'>-</span><span style='font-weight:bold;color:#1A7F37'>1</span><span
style='font-weight:bold;color:#0055AA'>]</span><span style='font-weight:bold;
color:#8250DF'>.</span><span style='font-weight:bold;color:#212121'>weight </span><span
style='font-weight:bold;color:#8250DF'>*= </span><span style='font-weight:bold;
color:#1A7F37'>0.1 </span><span style='font-weight:bold;color:#C00000'># last
layer make less confident</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121'>parameters </span><span style='font-weight:bold;color:#8250DF'>=</span><span
style='color:#212121'> model</span><span style='font-weight:bold;color:#8250DF'>.</span><span
style='color:#212121'>parameters</span><span style='color:#0055AA'>()</span><span
style='color:#212121'><br>
print</span><span style='color:#0055AA'>(</span><span style='color:#212121'>sum</span><span
style='color:#0055AA'>(</span><span style='color:#212121'>p</span><span
style='font-weight:bold;color:#8250DF'>.</span><span style='color:#212121'>nelement</span><span
style='color:#0055AA'>() </span><span style='font-weight:bold;color:#1A7F37'>for</span><span
style='color:#212121'> p </span><span style='font-weight:bold;color:#8250DF'>in</span><span
style='color:#212121'> parameters</span><span style='color:#0055AA'>)) </span><span
style='font-style:italic;color:#59636E'># number of parameters in total</span><span
style='color:#212121'><br>
</span><span style='font-weight:bold;color:#1A7F37'>for</span><span
style='color:#212121'> p </span><span style='font-weight:bold;color:#8250DF'>in</span><span
style='color:#212121'> parameters</span><span style='color:#0055AA'>:</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>  </span>p</span><span style='font-weight:bold;
color:#8250DF'>.</span><span style='color:#212121'>requires_grad </span><span
style='font-weight:bold;color:#8250DF'>= </span><span style='font-weight:bold;
color:#1A7F37'>True</span></p>

<p style='margin:0in;line-height:12pt;font-family:微软雅黑;font-size:12.0pt;
color:#0055AA'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#0055AA' lang=en-US>PS</span><span style='color:#0055AA' lang=zh-CN>：如果</span><span
style='color:#0055AA' lang=en-US>Linear</span><span style='color:#0055AA'
lang=zh-CN>层不进行参数共享，而是单独定义</span><span style='color:#0055AA' lang=en-US>context_length/2</span><span
style='color:#0055AA' lang=zh-CN>个</span><span style='color:#0055AA'
lang=en-US>linear</span><span style='color:#0055AA' lang=zh-CN>层，那么应该重新定义</span><span
style='color:#0055AA' lang=en-US>custumlinear</span><span style='color:#0055AA'
lang=zh-CN>层，并且把</span><span style='color:#212121' lang=zh-CN>FlattenConsecutive层集成</span><span
style='color:#212121' lang=en-US> </span><span style='color:#212121'
lang=zh-CN>到</span><span style='color:#212121' lang=en-US>custumlinear</span><span
style='color:#212121' lang=zh-CN>层中</span><span style='color:#0055AA'
lang=zh-CN>：</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121' lang=zh-CN>class </span><span style='color:#212121' lang=en-US>Custum</span><span
style='color:#212121' lang=zh-CN>Linear</span><span style='color:#0055AA'
lang=zh-CN>:</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt'><span style='color:
#212121' lang=zh-CN><span style='mso-spacerun:yes'>  </span></span><span
style='color:#212121' lang=en-US>def _init_(self,context_length</span><span
style='color:#212121' lang=zh-CN>，</span><span style='color:#212121'
lang=en-US>n, </span><span style='color:#212121' lang=zh-CN>fan_in</span><span
style='color:#0055AA' lang=zh-CN>,</span><span style='color:#212121'
lang=zh-CN> fan_out</span><span style='color:#212121' lang=en-US>): </span><span
style='color:#C00000' lang=en-US># n</span><span style='color:#C00000'
lang=zh-CN>表示相邻</span><span style='color:#C00000' lang=en-US>n</span><span
style='color:#C00000' lang=zh-CN>个字母进行组合</span><span style='color:#C00000'
lang=en-US><span style='mso-spacerun:yes'>  </span>fan_in = C*self.n</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>self.n =n </p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>self.context_length = context_length</p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt'><span
style='color:#212121' lang=en-US>assert context_length%n == 0<span
style='mso-spacerun:yes'>   </span></span><span style='color:#C00000'
lang=en-US><span style='mso-spacerun:yes'> </span>#</span><span
style='color:#C00000' lang=zh-CN>保证</span><span style='color:#C00000'
lang=en-US>context_length</span><span style='color:#C00000' lang=zh-CN>是</span><span
style='color:#C00000' lang=en-US>n</span><span style='color:#C00000'
lang=zh-CN>的倍数</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#C00000'><span lang=en-US>#</span><span lang=zh-CN>创建</span><span
lang=en-US>context_length//n</span><span lang=zh-CN>个</span><span lang=en-US>linear</span><span
lang=zh-CN>层</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>self.linear_list = []</p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>for _ in range(context_length//n):</p>

<p style='margin:0in;margin-left:1.125in;font-family:微软雅黑;font-size:12.0pt'><span
style='color:#212121' lang=en-US>l = Linear(</span><span style='color:#212121'
lang=zh-CN>fan_in</span><span style='color:#0055AA' lang=zh-CN>,</span><span
style='color:#212121' lang=zh-CN> fan_out</span><span style='color:#212121'
lang=en-US>, bias = True)</span></p>

<p style='margin:0in;margin-left:1.125in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>self.linear_list.append(l)</p>

<p style='margin:0in;margin-left:1.125in;line-height:12pt;font-family:微软雅黑;
font-size:12.0pt;color:#212121' lang=en-US>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='color:#212121'>def __call__</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>self</span><span style='color:#0055AA'>,</span><span
style='color:#212121'> x</span><span style='color:#0055AA'>):</span></p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=en-US><span style='mso-spacerun:yes'> </span></span><span
lang=zh-CN><span style='mso-spacerun:yes'> </span>B, T, C = x.shape</span><span
lang=en-US><span style='mso-spacerun:yes'>  </span></span><span lang=zh-CN><br>
<span style='mso-spacerun:yes'>  </span>x = x.view(B, T//self.n, C*self.n)</span></p>

<p style='margin:0in;margin-left:1.125in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>outputs = []</p>

<p style='margin:0in;margin-left:1.125in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>for i in range(context_length//n):</p>

<p style='margin:0in;margin-left:1.875in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=en-US>input = x[</span><span lang=zh-CN>：</span><span
lang=en-US>,<span style='mso-spacerun:yes'>  </span>i , </span><span
lang=zh-CN>：</span><span lang=en-US>]<span style='mso-spacerun:yes'>   </span>#
input shape </span><span lang=zh-CN>是</span><span lang=en-US> B,<span
style='mso-spacerun:yes'>  </span>C*n</span></p>

<p style='margin:0in;margin-left:1.875in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=en-US>//input = torch.reshape(input, ( -1</span><span
lang=zh-CN>，</span><span lang=en-US>C*self.n)) # input</span><span lang=zh-CN>的</span><span
lang=en-US>shape</span><span lang=zh-CN>是（</span><span lang=en-US>B , C*self.n)</span></p>

<p style='margin:0in;margin-left:1.875in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=en-US>output = self.linear_list[i]( input )<span
style='mso-spacerun:yes'>   </span># output</span><span lang=zh-CN>的</span><span
lang=en-US> shape</span><span lang=zh-CN>是</span><span lang=en-US> B,<span
style='mso-spacerun:yes'>  </span>fan_out</span></p>

<p style='margin:0in;margin-left:1.875in;font-family:微软雅黑;font-size:12.0pt;
color:#212121' lang=en-US>outputs.append(output)<span
style='mso-spacerun:yes'>                    </span></p>

<p style='margin:0in;margin-left:1.875in;line-height:12pt;font-family:微软雅黑;
font-size:12.0pt;color:#212121' lang=en-US>&nbsp;</p>

<p style='margin:0in;margin-left:.75in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=en-US>final_output = torch.stack(outputs, dim =
1)<span style='mso-spacerun:yes'>  </span># final_output </span><span
lang=zh-CN>的</span><span lang=en-US>shape</span><span lang=zh-CN>是</span><span
lang=en-US> B</span><span lang=zh-CN>，</span><span lang=en-US>context_length//n
</span><span lang=zh-CN>，</span><span lang=en-US> fan_out</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt;
color:#212121'><span lang=zh-CN><span style='mso-spacerun:yes'>   
</span>return </span><span lang=en-US>final_output</span></p>

<p style='margin:0in;margin-left:.375in;font-family:微软雅黑;font-size:12.0pt'><span
style='color:#212121'><span style='mso-spacerun:yes'>  </span><br>
def parameters</span><span style='color:#0055AA'>(</span><span
style='color:#212121'>self</span><span style='color:#0055AA'>):</span><span
style='color:#212121'><br>
<span style='mso-spacerun:yes'>    </span>return</span></p>

</div>

</div>

</div>

<div>

<p style='margin:0in'>&nbsp;</p>

<p style='text-align:left;margin:0in;font-family:Arial;font-size:9pt;
color:#969696;direction:ltr'>已使用 OneNote 创建。</p>

</div>

</body>

</html>
