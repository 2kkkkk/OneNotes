<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:dt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=OneNote.File>
<meta name=Generator content="Microsoft OneNote 15">
<link id=Main-File rel=Main-File href="Basic_2.htm">
<link rel=File-List href="Basic_2.files/filelist.xml">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:12.0pt'>

<div style='direction:ltr;border-width:100%'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:26.2659in'>

<div style='direction:ltr;margin-top:0in;margin-left:.2416in;width:1.4923in'>

<p style='margin:0in;font-family:微软雅黑;font-size:20.0pt' lang=en-US>Basic_2</p>

</div>

<div style='direction:ltr;margin-top:.0423in;margin-left:.2416in;width:1.7388in'>

<p style='margin:0in;font-size:10.0pt;color:#767676'><span style='font-family:
Calibri'>2025</span><span style='font-family:微软雅黑'>年</span><span
style='font-family:Calibri'>10</span><span style='font-family:微软雅黑'>月</span><span
style='font-family:Calibri'>30</span><span style='font-family:微软雅黑'>日</span></p>

<p style='margin:0in;font-family:Calibri;font-size:10.0pt;color:#767676'>19:48</p>

</div>

<div style='direction:ltr;margin-top:.4777in;margin-left:.159in;width:21.7173in'><nobr><img
src="Basic_2.files/image001.png" width=2880 height=1440
alt="高bias时应该如何处理？1.bigger network 2.train longer 3. nn architecture search.&#13;&#10;高variance时应该如何处理？&#13;&#10;1.more data或者是data augmentation比如一幅图像旋转后仍然是cat &#13;&#10;2.add regularization如l2,dropout&#13;&#10;3.early stopping&#13;&#10;4.architeccture search.&#13;&#10;通常来说，当有足够多的数据以及足够big的神经网络，那么bias 和 variance会同时降低。&#13;&#10;&#13;&#10;★关于earlystopping：&#13;&#10;存在的问题：&#13;&#10;1.early stopping是在train set上训练和最小化train set上的损失函数，并以dev set上的最低loss作为停止的标准。也就是说，train set上训练得到的网络参数应该是让train set上的损失最小，用train set上训练得到的网络在dev set上的效果作为评价标准，这种方式和通常的逻辑不符（照猫画虎，训练一个小孩看着猫的样子画一只猫，什么时候评价他画的最好呢，就是看他的画最像老虎的时候）。这种方式同时解决减小偏差和减小方差这两个问题，而不是Orthogonal地解决（先解决一个，再解决下一个）。&#13;&#10;2.early stopping 是对dev set的过拟合。&#13;&#10;因此，通常训练神经网络用l2 正则而不是early stopping。但l2正则需要cross validation确定lambda等超参数，需要超参数搜索。而earlystopping不需要繁杂的超参数搜索过程，省时省力，这也是它的优点。&#13;&#10;&#13;&#10;&#13;&#10;为什么l2正则比l1正则更常用？l1 regularization makes model sparse and helps very little in practice, so not used too much.&#13;&#10;&#13;&#10;为什么正则可以防止overfit？l2正则让权重参数w很小，相当于限制了模型的拟合能力，因此不会过拟合。（从激活函数的角度，w很小，z=wx+b也很小，tanh(z)在z很小时接近线性，整个神经网络趋近于线性函数，拟合能力也就很小，也就不会过拟合）。&#13;&#10;&#13;&#10;★关于Dropout:&#13;&#10;为什么dropout可以防止overfit? &#13;&#10;1.相当于训练了一个smaller的网络。&#13;&#10;2.Dropout helps us to ensure that the model is not getting biased towards a particular feature, i.e. to ensure it performs well even in the absence of that particular feature.&#13;&#10;3.can't rely on one particular feature, so the weights are spread out, 起到了shrink weight的作用(在某种程度上起到了和l2正则同样的效果)&#13;&#10;&#13;&#10;d3=np.random.rand(n_data,len(a3))&lt;0.8,n_data是样本数量，len(a3)是第3层神经元个数，也就是说，对每个样本drop了不同的神经元。a3 = np.multiply(a3,d3),a3/=0.8。&#13;&#10;为什么需要除以keep-prob0.8，因为不想让a3的期望发生改变，进而影响后面层的计算。&#13;&#10;预测时不使用dropout，因为不想让输出random，it just adds noise to your predictions.&#13;&#10;&#13;&#10;Dropout并不是一定要用，当你的网络没有过拟合时，就不需要。而且dropout也不一定适用于所有情景 ，要结合具体数据来看。&#13;&#10;Dropout的一个缺点是：当加入了dropout后，由于引入了随机性，损失函数变得 not well defined。&#13;&#10;&#13;&#10;&#13;&#10;&#13;&#10;关于l2正则被称为weight decay:&#13;&#10;"><img
src="Basic_2.files/image002.png" width=247 height=1440
alt="1.early stopping是在train set上训练和最小化train set上的损失函数，并以dev set上的最低loss作为停止的标准。也就是说，train set上训练得到的网络参数应该是让train set上的损失最小，用train set上训练得到的网络在dev set上的效果作为评价标准，这种方式和通常的逻辑不符（照猫画虎，训练一个小孩看着猫的样子画一只猫，什么时候评价他画的最好呢，就是看他的画最像老虎的时候）。这种方式同时解决减小偏差和减小方差这两个问题，而不是Orthogonal地解决（先解决一个，再解决下一个）。&#13;&#10;"><br>
<img src="Basic_2.files/image003.png" width=2880 height=190
alt="关于l2正则被称为weight decay:&#13;&#10;&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"><img
src="Basic_2.files/image004.png" width=247 height=190><br>
</nobr></div>

<div style='direction:ltr;margin-top:.393in;margin-left:0in;width:.1375in'><img
src="Basic_2.files/image005.png" width=20 height=24></div>

<div style='direction:ltr;margin-top:.8673in;margin-left:.2416in;width:20.5944in'>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>★</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>关于</span><span style='font-family:Calibri' lang=en-US>N</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>ormalize </span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>数据（</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>其实是</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>Standardization</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>）</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'><span
lang=zh-CN>即</span><span style='font-weight:bold' lang=en-US>0</span><span
style='font-weight:bold' lang=zh-CN>均值化，和方差归一，然后用训练集上的均值和方差，</span><span
style='font-weight:bold' lang=en-US>normalize test set.</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'><span
lang=zh-CN>为什么需要</span><span lang=en-US>Normalization?</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:#2E75B5' lang=en-US>The intuition that cost function will be more
round(the contour is circular rather than ellipse), and easier and faster to
optimize when features are all on similar scales. </span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>椭圆的切线的垂线（即梯度的方向）并不是指向中心那个红点的（局部最小），而圆的切线的垂线（即梯度的方向）始终指向中心那个红点的（局部最小），因此，对于</span><span
style='font-weight:bold;color:#C00000' lang=en-US>contour</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>是圆的</span><span
style='font-weight:bold;color:#C00000' lang=en-US>loss</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>超曲面来说，</span><span
style='font-weight:bold;color:#C00000' lang=en-US>gradient descent</span><span
style='font-weight:bold;color:#C00000' lang=zh-CN>需要的步数更少，优化更快。</span></p>

</div>

<div style='direction:ltr;margin-top:.409in;margin-left:.7229in;width:2.5416in'><img
src="Basic_2.files/image006.png" width=366 height=156
alt="墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"></div>

<div style='direction:ltr;margin-top:.5729in;margin-left:.2416in;width:26.0243in'><nobr><img
src="Basic_2.files/image007.png" width=2880 height=990
alt="&#13;&#10;&#13;&#10;什么时候需要Normalization?&#13;&#10;当features之间的scale差别很大时 ，比如x1~[0,1], x2~[1,10000]，当相差不大时，比如x1~[0,1], x2~[1,2]，可以不Normalize。&#13;&#10;&#13;&#10;Standardization 对outliers不敏感，Normalization是对特征的norm进行归一化，如min max scaler，适用于基于距离的算法。 &#13;&#10;&#13;&#10;★关于梯度消失和爆炸&#13;&#10;假设网络有100层，第10-100层的权重W的模都大于1，相当于前10层的W被后90层的W逐层放大，类似于x乘以10000，此时x变化很小，放大10000倍后的变化很大，也就是梯度爆炸；同理，当第10-100层的权重W的模都小于1，相当于前10层的W被后90层的W逐层缩小，类似于x乘以1e-10，此时x的变化对y几乎 没有影响，也就是梯度消失。&#13;&#10;可以通过初始化权重来缓解梯度消失和爆炸，使得梯度不会消失或爆炸地 too quickly. 有多种初始化方法，基本可以分为均匀分布和正态分布，正态分布的均值通常为0，方差可以是1，也可以是constant/n ，constant可以是1、2、6等，n是权重矩阵W的元素个数，或者是这一层的神经元个数。&#13;&#10;&#13;&#10;★关于mini batch&#13;&#10;Mini batch 的Loss曲线是振荡的，因为每个batch的数据是不同的，而且batch中有noise，用当前batch计算得到的梯度去更新参数，得到的参数在下一个batch上的loss可能会增加。&#13;&#10;&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"><img
src="Basic_2.files/image008.png" width=868 height=990
alt="假设网络有100层，第10-100层的权重W的模都大于1，相当于前10层的W被后90层的W逐层放大，类似于x乘以10000，此时x变化很小，放大10000倍后的变化很大，也就是梯度爆炸；同理，当第10-100层的权重W的模都小于1，相当于前10层的W被后90层的W逐层缩小，类似于x乘以1e-10，此时x的变化对y几乎 没有影响，也就是梯度消失。&#13;&#10;可以通过初始化权重来缓解梯度消失和爆炸，使得梯度不会消失或爆炸地 too quickly. 有多种初始化方法，基本可以分为均匀分布和正态分布，正态分布的均值通常为0，方差可以是1，也可以是constant/n ，constant可以是1、2、6等，n是权重矩阵W的元素个数，或者是这一层的神经元个数。&#13;&#10;"><br>
</nobr></div>

<div style='direction:ltr;margin-top:.6215in;margin-left:.2416in;width:24.2437in'>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑'>★</span><span style='font-family:"Microsoft YaHei"'>指数加权平均</span></p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>0</m:t></m:r></m:sub></m:sSub><m:r><m:t>=0&nbsp;&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub><m:r><m:t>=</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#120573;</m:t></m:r><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r><m:r><m:t>−1</m:t></m:r></m:sub></m:sSub><m:r><m:t>+</m:t></m:r><m:d><m:dPr><m:ctrlPr/></m:dPr><m:e><m:r><m:t>1−</m:t></m:r><m:r><m:t>&#120573;</m:t></m:r></m:e></m:d><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#120579;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub></m:oMath><![endif]--><span
style='font-family:Calibri' lang=en-US><span style='mso-spacerun:yes'> </span></span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>展开就是指数形式，相当于越靠近当前</span><span
style='font-family:Calibri' lang=en-US>t</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>的</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#120579;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>权重越大，越远离当前</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>t</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>的权重越小，且呈指数递减。</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>v_t</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>大概是</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>1/</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>（</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>1-</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>&#120573;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>）天的平均，再往前权重就特别小了。</span><![if !msEquation]><img
src="Basic_2.files/image009.png" width=2113 height=42><![endif]></p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>为什么用</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>&nbsp;</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub><m:r><m:t>=</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#120573;</m:t></m:r><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r><m:r><m:t>−1</m:t></m:r></m:sub></m:sSub><m:r><m:t>+</m:t></m:r><m:d><m:dPr><m:ctrlPr/></m:dPr><m:e><m:r><m:t>1−</m:t></m:r><m:r><m:t>&#120573;</m:t></m:r></m:e></m:d><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#120579;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，而不是直接计算</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>10</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>个时间步的均值？</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>因为后者需要记录</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>10</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>个时间步的每个值，也就是</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>10</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>个值，而移动平均只需要记录</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>v_</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>t一个值就可以，节省存储空间，且计算效率更高。</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>Especially
when you need to compute the averages of lots of variables, </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>移动平均的空间和时间效率都更高。</span><![if !msEquation]><img
src="Basic_2.files/image010.png" width=3506 height=42><![endif]></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
SimSun' lang=en-US>Bias estimation:</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>由于</m:t></m:r><m:r><m:t>&nbsp;</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>0</m:t></m:r></m:sub></m:sSub><m:r><m:t>=0&nbsp;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，在初始化阶段，</span><span
style='font-family:"Cambria Math"' lang=en-US>v_t</span><span style='font-family:
SimSun' lang=zh-CN>的值很小，尤其当</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>&#120573;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>的值很大时，需要很长个</span><span
style='font-family:"Cambria Math"' lang=en-US>t</span><span style='font-family:
SimSun' lang=zh-CN>。因此做出改进，</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub><m:r><m:t>=</m:t></m:r><m:sSub><m:sSubPr><m:ctrlPr/></m:sSubPr><m:e><m:r><m:t>&#119907;</m:t></m:r></m:e><m:sub><m:r><m:t>&#119905;</m:t></m:r></m:sub></m:sSub><m:r><m:t>/(1</m:t></m:r><m:r><m:t>−</m:t></m:r><m:sSup><m:sSupPr><m:ctrlPr/></m:sSupPr><m:e><m:r><m:t>&#120573;</m:t></m:r></m:e><m:sup><m:r><m:t>&#119905;</m:t></m:r></m:sup></m:sSup><m:r><m:t>)</m:t></m:r></m:oMath><![endif]--><span
style='font-family:SimSun' lang=zh-CN>，当</span><span style='font-family:SimSun'
lang=en-US>t</span><span style='font-family:SimSun' lang=zh-CN>很小时，将</span><span
style='font-family:SimSun' lang=en-US>v_t</span><span style='font-family:SimSun'
lang=zh-CN>放大，当</span><span style='font-family:SimSun' lang=en-US>t</span><span
style='font-family:SimSun' lang=zh-CN>很大时，几乎不改变原来的</span><span
style='font-family:SimSun' lang=en-US>v_t</span><span style='font-family:SimSun'
lang=zh-CN>。</span><![if !msEquation]><img src="Basic_2.files/image011.png"
width=2158 height=42><![endif]></p>

<p style='margin:0in;font-family:SimSun;font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>★</span><span style='font-family:Calibri' lang=en-US>M</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>o</span><span
style='font-family:Calibri' lang=en-US>mentum gradient descent</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>就是对梯度进行指数加权平均，通过对历史梯度的平均，如果梯度在某个方向上振荡，那么通过平均可以减小振荡，如果梯度在某个方向上保持，那么通过平均还会使梯度保持在这个方向，达到加速收敛的效果。</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
Calibri' lang=en-US>Momentum</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>梯度下降时一般不需要做</span><span style='font-family:Calibri' lang=en-US>Bias
estimation</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>修正，因为相当于</span><span
style='font-family:Calibri' lang=en-US>warm-up</span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>了。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>两个版本：</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>没啥大的区别，区别在于学习率不同罢了，不乘以</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>1−</m:t></m:r><m:r><m:t>&#120573;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，梯度的值会大一些，学习率就相应小一些罢了。</span><![if !msEquation]><img
src="Basic_2.files/image012.png" width=1205 height=42><![endif]></p>

<p style='margin:0in;font-family:SimSun;font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>★</span><span style='font-family:Calibri' lang=en-US>RMS</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>prop</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'><span
lang=zh-CN>历史梯度平方的加权平均，然后用这个</span><span lang=en-US>sqrt(</span><span
lang=zh-CN>加权平均值</span><span lang=en-US>)</span><span lang=zh-CN>对最新的梯度进行缩放，值越大，步长越小。</span><span
lang=en-US>RMSprop</span><span lang=zh-CN>类似于</span><span lang=en-US>M</span><span
lang=zh-CN>o</span><span lang=en-US>mentum</span><span lang=zh-CN>，同样可以消除振荡。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>★</span><span style='font-family:Calibri' lang=en-US>A</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>da</span><span
style='font-family:Calibri' lang=en-US>m</span></p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>在更新梯度时，</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>M</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>omentum</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>相当于用历史梯度的加权平均替换了当前梯度，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>Rmsprop</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>相当于用历史梯度平方的加权平均值对当前梯度进行缩放，而</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>A</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>dam结合了</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>momentum </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>和</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>Rmsprop</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'><span
lang=en-US>4</span><span lang=zh-CN>个超参数</span></p>

</div>

<div style='direction:ltr;margin-top:.3868in;margin-left:1.2236in;width:11.5493in'><img
src="Basic_2.files/image013.png" width=1663 height=1169
alt="墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"></div>

<div style='direction:ltr;margin-top:.0868in;margin-left:1.1569in;width:13.0458in'><img
src="Basic_2.files/image014.png" width=1879 height=636
alt="墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"></div>

<div style='direction:ltr;margin-top:.4763in;margin-left:.4916in;width:23.6784in'>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#2E75B5'>★超参数搜索</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>不要用</span><span style='font-family:Calibri' lang=en-US>grid
search</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>（原因是很费时间，而且不同超参数的重要性不一样，</span><span
style='font-family:Calibri' lang=en-US>grid search</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>会浪费很多时间在不重要的超参数上），用</span><span
style='font-family:Calibri' lang=en-US>random </span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>sea</span><span style='font-family:Calibri'
lang=en-US>rch</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>代替，</span><span
style='font-family:Calibri' lang=en-US>random</span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>不是均匀的</span><span style='font-family:Calibri'
lang=en-US>random</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>，需要</span><span
style='font-family:Calibri' lang=en-US>scale search</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，如学习率的搜索范围是</span><span
style='font-family:Calibri' lang=en-US>[0.001,1]</span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>，应该在</span><span style='font-family:Calibri'
lang=en-US>[0.001,0.01]</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>、</span><span style='font-family:Calibri' lang=en-US>[0.001,0.1]</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>、</span><span
style='font-family:Calibri' lang=en-US>[0.1,1]</span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>这三个区间内</span><span style='font-family:Calibri'
lang=en-US>random</span><span style='font-family:"Microsoft YaHei"' lang=zh-CN>搜索。为什么要这种指数式地搜索而不是直接在</span><span
style='font-family:Calibri' lang=en-US>[0.0001,1]</span><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>区间上线性搜索，原因是超参数对网络的影响不是线性的，比如</span><span
style='font-family:Calibri' lang=en-US>M</span><span style='font-family:"Microsoft YaHei"'
lang=en-US>omentum</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>中的</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>&#120573;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:微软雅黑' lang=zh-CN>，</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:t>&#120573;</m:t></m:r></m:oMath><![endif]--><span
style='font-family:微软雅黑' lang=zh-CN>从</span><span style='font-family:微软雅黑'
lang=en-US>0.9000</span><span style='font-family:微软雅黑' lang=zh-CN>增加到</span><span
style='font-family:微软雅黑' lang=en-US>0.9005</span><span style='font-family:微软雅黑'
lang=zh-CN>，意味着从计算历史</span><span style='font-family:微软雅黑' lang=en-US>10</span><span
style='font-family:微软雅黑' lang=zh-CN>个</span><span style='font-family:微软雅黑'
lang=en-US>batch</span><span style='font-family:微软雅黑' lang=zh-CN>的梯度平均值增加到计算历史</span><span
style='font-family:微软雅黑' lang=en-US>10.05</span><span style='font-family:微软雅黑'
lang=zh-CN>个</span><span style='font-family:微软雅黑' lang=en-US>batch</span><span
style='font-family:微软雅黑' lang=zh-CN>的梯度平均值，而当</span><!--[if gte msEquation 12]><m:oMath xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"><m:r><m:rPr><m:sty m:val="p"/></m:rPr><m:t>β</m:t></m:r></m:oMath><![endif]--><span
style='font-family:微软雅黑' lang=zh-CN>从</span><span style='font-family:微软雅黑'
lang=en-US>0.999</span><span style='font-family:微软雅黑' lang=zh-CN>增加到</span><span
style='font-family:微软雅黑' lang=en-US>0.9995</span><span style='font-family:微软雅黑'
lang=zh-CN>，意味着从计算历史</span><span style='font-family:微软雅黑' lang=en-US>1000</span><span
style='font-family:微软雅黑' lang=zh-CN>个</span><span style='font-family:微软雅黑'
lang=en-US>batch</span><span style='font-family:微软雅黑' lang=zh-CN>的梯度平均值增加到计算历史</span><span
style='font-family:微软雅黑' lang=en-US>2000</span><span style='font-family:微软雅黑'
lang=zh-CN>个</span><span style='font-family:微软雅黑' lang=en-US>batch</span><span
style='font-family:微软雅黑' lang=zh-CN>的梯度平均值。</span><![if !msEquation]><img
src="Basic_2.files/image015.png" width=3425 height=125><![endif]></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-family:微软雅黑;font-size:12.0pt;color:#2E75B5'>★关于标准化和归一化</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold;color:#222832'>Standardization</span><span
style='color:#2E75B5'>&nbsp;of datasets is a&nbsp;</span><span
style='font-weight:bold;color:#222832'>common requirement for many machine
learning estimators</span><span style='color:#2E75B5'>&nbsp;implemented in
scikit-learn; they might behave badly if the individual features do not more or
less look like standard normally distributed data: Gaussian with&nbsp;</span><span
style='font-weight:bold;color:#222832'>zero mean and unit variance</span><span
style='color:#2E75B5'>.</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='color:#2E75B5'>Centering and scaling happen</span><span
style='font-weight:bold;color:#2E75B5'> independently on each feature</span><span
style='color:#2E75B5'> by computing the relevant statistics on the samples in
the training set. Mean and standard deviation are then stored to be used on
later data using&nbsp;</span><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform"><span
style='font-weight:bold'>transform</span></a><span style='color:#2E75B5'>.</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt'><span
style='font-weight:bold;color:#222832'>Normalization</span><span
style='color:#2E75B5'>&nbsp;is the process of</span><span style='font-weight:
bold;color:black'>&nbsp;scaling individual samples to have unit norm.</span><span
style='color:#2E75B5'> This process can be useful if you plan to use a
quadratic form such as the dot-product or any other kernel to quantify the
similarity of any pair of samples.</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>来自
&lt;<a
href="https://scikit-learn.org/stable/modules/preprocessing.html#normalization">https://scikit-learn.org/stable/modules/preprocessing.html#normalization</a>&gt;
</p>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p><cite style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;
color:#2E75B5'><span lang=zh-CN>也就是说，</span><span lang=en-US>standardization</span><span
lang=zh-CN>是按列进行，每个特征的均值为</span><span lang=en-US>0</span><span lang=zh-CN>，方差为</span><span
lang=en-US>1</span><span lang=zh-CN>。</span><span lang=en-US>Normalization</span><span
lang=zh-CN>是按行进行，每个样本的</span><span lang=en-US>norm</span><span lang=zh-CN>是</span><span
lang=en-US>1</span><span lang=zh-CN>。</span></cite></p>

<p style='margin:0in;font-family:Calibri;font-size:12.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
微软雅黑' lang=zh-CN>★关于</span><span style='font-family:Calibri' lang=en-US>Batchnorm</span></p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
Calibri' lang=en-US>I</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>n</span><span style='font-family:Calibri' lang=en-US>tuition:</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>不能只对输入</span><span
style='font-family:Calibri' lang=en-US>x</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>做</span><span style='font-family:"Microsoft YaHei"' lang=en-US>0</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>均值和方差</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>1</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>的操作，也需要对中间隐藏层的神经元做相应的操作，在输入激活函数之前做batchnorm，并引入两个可学习参数对其进行缩放平移。</span></p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-family:
"Microsoft YaHei"' lang=zh-CN>在引入Batchnorm层后，该层神经元的偏置项z</span><span
style='font-family:Calibri' lang=en-US>=wx+b</span><span style='font-family:
"Microsoft YaHei"' lang=en-US>中的</span><span style='font-family:Calibri'
lang=en-US>b</span><span style='font-family:"Microsoft YaHei"' lang=en-US>可以不要</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，因为无论b是多少，batchnorm都会把z的均值变为</span><span
style='font-family:Calibri' lang=en-US>0</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>batchnorm好处：</p>

<ol type=1 style='direction:ltr;unicode-bidi:embed;margin-top:0in;margin-bottom:
 0in;font-family:Calibri;font-size:12.0pt;font-weight:normal;font-style:normal'>
 <li value=1 style='margin-top:0;margin-bottom:0;vertical-align:middle;
     color:#2E75B5'><span style='font-family:"Microsoft YaHei";font-size:12.0pt;
     font-weight:normal;font-style:normal;font-family:"Microsoft YaHei";
     font-size:12.0pt'>前面层的输出变得稳定，也就是后面层的神经元的输入变得稳定，训练起来更加容易。</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#2E75B5'><span
     style='font-family:"Microsoft YaHei";font-size:12.0pt' lang=zh-CN>无论前面几层的神经元输出如何变化，都不会对本层的z造成太大影响，因为z始终是均值</span><span
     style='font-family:Calibri;font-size:12.0pt' lang=en-US>0</span><span
     style='font-family:"Microsoft YaHei";font-size:12.0pt' lang=en-US>方差</span><span
     style='font-family:Calibri;font-size:12.0pt' lang=en-US>1</span><span
     style='font-family:"Microsoft YaHei";font-size:12.0pt' lang=zh-CN>，并且batchnorm的两个可学习参数也不依赖于前面层，减弱了后面层对前面层的依赖，使得各个层相对独立一些。</span></li>
</ol>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>batchnorm有轻微的正则化作用</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>，因为batcnorm在每个batch上计算均值方差，而不是在整个数据集上计算均值方差，这就相当于在每个神经元上引入了noise，既引入了加性noise（减去均值），有引入了乘性noise（除以标准差），对于batchnorm来说，batch
size越大，正则作用越小。类似于dropout，</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>dropout也相当于在每个神经元上引入了乘性噪声（乘以</span><span style='font-weight:bold;
font-family:Calibri' lang=en-US>1</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=en-US>或者乘以</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>0</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>）。引入噪声就会起到正则作用</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US> </span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>preventing the model from
fitting training data too closely and acting as a form of regularization.</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:12.0pt;color:#2E75B5'>&nbsp;</p>

<p style='margin:0in;font-size:12.0pt;color:#2E75B5'><span style='font-weight:
bold;font-family:Calibri' lang=en-US>B</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>at</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>chnomr</span><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>对</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>batchsize</span><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>敏感。</span></p>

</div>

</div>

</div>

<div>

<p style='margin:0in'>&nbsp;</p>

<p style='text-align:left;margin:0in;font-family:Arial;font-size:9pt;
color:#969696;direction:ltr'>已使用 OneNote 创建。</p>

</div>

</body>

</html>
