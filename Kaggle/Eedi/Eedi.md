# Eedi

A Diagnostic Question is a multiple-choice question with four options: one correct answer and three distractors (incorrect answers). Each distractor is carefully crafted to capture a specific misconception.

Tagging distractors with appropriate misconceptions.

## My story

é˜…è¯»äº†é«˜voteçš„public notebookåï¼Œæˆ‘è®¤è¯†åˆ°è¿™ä¸ªæ¯”èµ›çš„æµç¨‹æ˜¯recall+rerankã€‚

å¯¹äºrecallï¼Œpublic notebookçš„æ–¹æ³•æ˜¯    ç”¨

```python
task='Given a math question with correct answer and a misconcepted incorrect answer, retrieve the most accurate misconception for the incorrect answer.'

query_text =f"### SubjectName: {row['SubjectName']}\n### ConstructName: {row['ConstructName']}\n### Question: {row['QuestionText']}\n### Correct Answer: {correct_answer}\n### Misconcepte Incorrect answer: {option}.{row[f'Answer{option}Text']}"
```

æ„å»ºæ•°æ®é›†,é€šè¿‡contrastive learning å’Œ hard negative mining æ¥finetune sftæˆ–è€…qwen-14b,æœ€åé€šè¿‡ä¸misceptionsåº“çš„emeddingè¿›è¡ŒåŒ¹é…æ¥recallã€‚

ä½†æ˜¯æ²¡æœ‰å…¬å¼€çš„finetuneä»£ç ï¼Œåªæœ‰å°†åˆ«äººå¾®è°ƒå¥½çš„loraç›´æ¥æ‹¿æ¥ç”¨ã€‚

å¯¹äºrecallï¼Œæˆ‘ä¸ä¼šå¾®è°ƒï¼Œæ‰€ä»¥æˆ‘çš„æƒ³æ³•æ˜¯ï¼Œåªç”¨subjectname , constructnameï¼ˆå†åŠ ä¸Šllmæ€»ç»“ çš„questionå…³é”®å¥ï¼‰å†åŠ ä¸Šè‡ªå·±è®¾è®¡çš„promtï¼ˆwhat are misconceptions that might happens in a math problem under this subjectname and constructname?ï¼‰ æ¥è¿›è¡Œå¬å›ï¼Œæ¨¡å‹ç”¨ç°æˆçš„mtebä¸­çš„æ¨¡å‹ã€‚

å°è¯•äº†bge-largeï¼Œbge-iclï¼Œbge-embedder, stella_en,ä»¥åŠä¸åŒçš„subject_construct+question+answerç»„åˆï¼Œä½†æäº¤åç»“æœè¾ƒå·®ï¼Œ0.29å·¦å³ï¼Œæ­¤æ—¶æˆ‘å†³å®šè¿˜æ˜¯ç›´æ¥ç”¨public notebookä¸­äººå®¶å·²ç»Finetuneå¥½çš„Loraæ¨¡å‹å§ã€‚



å¯¹äºRerankï¼Œpublic kernelæ˜¯ç”¨QW32B+logits_zooï¼Œé€‰å‡ºæœ€ä¼˜çš„ä¸€ä¸ªï¼Œå…¶ä»–24ä¸ªç›´æ¥ç”¨recallçš„æ’åºç»“æœã€‚

æˆ‘åœ¨æŸ¥mtebæ—¶ï¼Œæˆ‘å‘ç°æœ‰bge çš„reranker model,"reranker model uses question and documents as input and directly output the similarity instead of embedding"ï¼Œæˆ‘ä¸€çœ‹è¿™ä¸æ˜¯å°±é€‚åˆrerankä»»åŠ¡å˜›ï¼Œäºæ˜¯æˆ‘æ‰“ç®—è¯•è¯•rerankeræ¨¡å‹ï¼Œä½†æ˜¯åé¢æˆ‘ä¸€æƒ³ï¼Œå…¶å®rerankeræ¨¡å‹ä¹Ÿæ˜¯llmçš„ä¸€ç§ï¼Œæœ¬è´¨æ˜¯ä¸€æ ·ï¼Œå¯èƒ½è¿˜ä¸å¦‚ç›´æ¥é—®llmã€‚äºæ˜¯æˆ‘ä»ä¸¤æ–¹é¢ä¼˜åŒ–public çš„rerankéƒ¨åˆ†ï¼š

1ï¼‰ æˆ‘æƒ³èµ·discussion https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/540759ä¸­çœ‹åˆ°çš„ï¼Œthe trick of using LLM is:

- understand that LLM is just a parrot, it does not reason,plan . it doesn't even understand language
- always think of how to increase "the conditional probability" of "generating" your desired answer, rather than the logic to get your answer

äºæ˜¯æˆ‘changeäº† prompt ï¼Œåœ¨promptä¸­åŠ å…¥äº†background çŸ¥è¯†å’Œä¸€ä¸ªexampleï¼Œå¯¹äºpublicçš„qw14Bæ¨¡å‹ï¼Œåˆ†æ•°æå‡äº†0.02ï¼Œæ’åç›´æ¥åˆ°200ï¼Œä½†æ˜¯å¯¹äºpublicçš„sft modelï¼Œåˆ†æ•°é™äº†ï¼Œä½†æ˜¯æˆ‘åªåœ¨æ„æå‡ï¼Œè§‰å¾—æ˜¯sftæ¨¡å‹ä¸å¤Ÿå¥½çš„åŸå› ï¼Œ**ç°åœ¨æƒ³æƒ³å…¶å®è°ƒpromptä¸åº”è¯¥ä»¥public lbçš„ç»“æœä½œä¸ºè¯„åˆ¤æ ‡å‡†ï¼Œæ˜¯å®¹æ˜“è¿‡æ‹Ÿåˆçš„ä¸€ç§è¡Œä¸ºã€‚** åˆ†æ•°æå‡åï¼Œæˆ‘åˆçº ç»“å°è¯•åœ¨promptä¸­åŠ å…¥æ›´å¤šä¾‹å­ï¼Œä½†æ˜¯å½±å“ä¸å¤§ï¼Ÿï¼ˆè€Œä¸”ä¼šè¶…æ—¶ï¼‰ã€‚

2ï¼‰public kernelä¸­ç”¨QW32B+logits_zooï¼Œé€‰å‡ºæœ€ä¼˜çš„ä¸€ä¸ªï¼Œåªsurviveäº†ä¸€æ¬¡ï¼Œå› æ­¤æˆ‘å°è¯•survive ä¸¤æ¬¡å’Œä¸‰æ¬¡ï¼Œåˆ†æ•°æé«˜äº†ï¼Œè¿™ä¸ªå¯¹äºpublic sft å’Œpublic qwen14bä¸¤ä¸ªæ¨¡å‹æœ€ååˆ†æ•°éƒ½æå‡äº†ï¼Œ**è¿™æ‰æ˜¯robustçš„åšæ³•**ã€‚



æˆ‘åœ¨discussionä¸­è¿˜çœ‹åˆ°æœ‰äººå°è¯•ç”¨qw72bä»£æ›¿32bæ¥rerankï¼Œæˆ‘å°è¯•äº†ä½†ç»“æœé™ä½äº†ä¸€ç‚¹ï¼Œæˆ‘å°±æ²¡ç”¨ï¼Œä½†æ˜¯private å…¬å¸ƒåscoreå…¶å®æé«˜äº†å¾ˆå¤šã€‚



å¯¹äºrobustçš„ç­”æ¡ˆé€‰æ‹©ï¼Œæˆ‘çš„åšæ³•æ˜¯å‰3ä¸ªç­”æ¡ˆç”¨qw14bæ¨¡å‹åŠrerankçš„ç»“æœ ï¼Œå22ä¸ªç»“æœç›´æ¥ç”¨sub+con+quetion ç”¨æ²¡å¾®è°ƒçš„bge-largeè®¡ç®—embedding similarityå¬å›çš„ç»“æœã€‚**ç°åœ¨æƒ³æƒ³ï¼Œå…œåº•ä¹Ÿè¦è€ƒè™‘åå·®ï¼Œä¸ç”¨åå·®å¤ªå¤§äº†ï¼Œpublic lbåˆ†æ•°å¾ˆä½ï¼Œé‚£ä¹ˆprivate lb çš„åˆ†æ•°ä¹Ÿæ²¡å¤ªå¤§çš„å¸Œæœ›ã€‚å…œåº•robuståº”è¯¥ç”¨æ›´ç¨³å¥çš„æ–¹æ³•ï¼Œæ¯”å¦‚è¿™ä¸ªæ¯”èµ›ä¸­ç”¨qw72bä»£æ›¿32bæ¥rerankï¼Œè™½ç„¶public lb åˆ†æ•°é™ä½äº†ä¸€ç‚¹ï¼ˆè·Ÿè¿™ä¸ªæ¯”èµ›scoreçš„æ³¢åŠ¨ç›¸æ¯”å…¶å®æ— æ‰€è°“ï¼‰ï¼Œä½†æ˜¯private lbçš„åˆ†æ•°æé«˜å¾ˆå¤§ï¼›å†æ¯”å¦‚æ–‡ç« è¯„åˆ†çš„æ¯”èµ›ä¸­ï¼Œtrain_dataä¸­è¿‡æ»¤æ‰åˆ†æ•°å°äº3çš„å­¦ç”Ÿæ–‡ç« ï¼Œè™½ç„¶public lb æ²¡æé«˜ï¼Œä½†æ˜¯private lbæé«˜å¾ˆå¤§ã€‚è¿™äº›ç†è®ºä¸Šrobustçš„åšæ³•ï¼Œå½“åœ¨public lbçš„åˆ†æ•°æ²¡æœ‰å¤§çš„è¿›æ­¥æ—¶ï¼Œéœ€è¦æ³¨æ„å¹¶é‡‡ç”¨ã€‚**



æˆ‘åº”è¯¥å°è¯•ç”¨0.48é‚£ä¸ªkernelhttps://www.kaggle.com/code/anhvth226/eedi-11-21-14bçš„ï¼Œè™½ç„¶è·‘ä¸åŠ¨ï¼Œä½†æ˜¯æœ‰Loraæ¨¡å‹ï¼Œåº”è¯¥è‡ªå·±è°ƒè¯•ä¸€ä¸‹ã€‚

## Top solutions

## æœ‰ä»£ç 

### 1st Place Detailed Solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551688

- [Training code](https://github.com/rbiswasfc/eedi-mining-misconceptions)
- [Inference Notebook](https://www.kaggle.com/code/conjuring92/eedi-a2-pipeline?scriptVersionId=211785645)
- [Dataset with Synthetic + Competition MCQ](https://www.kaggle.com/datasets/conjuring92/eedi-mcq-dataset)
- [CoT Dataset](https://www.kaggle.com/datasets/conjuring92/eedi-cot-sonnet-6k)

### 5th Place Solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551391

https://github.com/ebinan92/Eedi-5th-solution?tab=readme-ov-file



### Efficiency 2nd Place Solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/552686

- https://www.kaggle.com/code/rsakata/eedi-1-misconception-explanation
- https://www.kaggle.com/code/rsakata/eedi-2-train-embedding-model
- https://www.kaggle.com/code/rsakata/eedi-3-retrieval

train-embedding-modelè¿™ä¸ªä»£ç æˆ‘çœ‹äº†ï¼Œå¹¶åšäº†æ³¨é‡Šã€‚

### 3rd Place Solution (with Magic Boost)

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551498

The inference code can be found at:
https://www.kaggle.com/code/threerabbits/eedi-11-21-myq14b-q32b-rerank-mod-novel-local-suf

**Let's Experiment**

On the second-to-last day of the competition (yes, I really dared to use two submissions for experiments at this point XD), I did this LB probing:

- Predicted only 1 misconception per question
- Tested twice:
  1. Using only seen misconceptions from training data: got 0.154
  2. Using only unseen misconceptions: got 0.444

Seeing these results, I made a bold guess that the seen-to-unseen ratio in the testing data was roughly 1:3.

**The Final Magic Touch**

So I implemented a simple post-processing:

- Multiplied the probabilities of all predicted unseen misconceptions by a constant C
- Adjusted until unseen misconceptions made up 75% of the first predictions

This little magic trick made the scores skyrocket ğŸ˜®:

- Public LB: 0.590 â†’ 0.658
- Private LB: 0.564 â†’ 0.600

### 8th Place Solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551412

- Inference code: https://www.kaggle.com/code/yannan90/eedi-recall-rerank-lb-0-601-pb-0-584
- Training & Quantization code: https://github.com/yannan90/kaggle-2024-Eedi-8th-place-training-code

### 4th Place Solution

takoi part : https://github.com/TakoiHirokazu/kaggle-Eedi-4th-solution
charmq part : https://github.com/charmq00/kaggle_eedi_public
Inference : https://www.kaggle.com/code/charmq/eedi-pp040-ret15-exp345-341-348-multi-32b-ret-c015

### 2nd place solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551651

train code: [https://github.com/wangqihanginthesky/Eedi_kaggle\](https://github.com/wangqihanginthesky/Eedi_kaggle/)
inference code: https://www.kaggle.com/code/honglihang/2nd-place-inference-code

### (Almost) Zero-Shot Solution - Private 64h

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551449

### 31st place solution

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/553317

I finetuned (lora) a Qwen2.5-32b-awq reranker via trl.SFTTrainer. Here are my hyper parameters

My demo training notebook: https://www.kaggle.com/code/doublezeta/train-reranker Actually I did the training in Colab.

### 94th Bronze Solution Summary (only public notebooks with simple tricks)

https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551396

1. - Rerank only the first 3 candidates and focus on precision: I predicted the answer for 3 shuffled lists of misconceptions (because LLMs are biased to answers position), then take the answer only if it was chosen in all attempts.



## éœ€è¦learning

è¿˜æ˜¯è¦è‡ªå·±ä¼šfinetune

contrastive learning

embedding model (sentence transformer) BGE

flag embedding

flash attention

lora_config(task_type='casual_llm'å’Œ'feature_extract'çš„åŒºåˆ«)