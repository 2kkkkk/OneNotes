<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:dt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=OneNote.File>
<meta name=Generator content="Microsoft OneNote 15">
<link id=Main-File rel=Main-File href="Batchnorm%20layernorm.htm">
<link rel=File-List href="Batchnorm%20layernorm.files/filelist.xml">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:36.0pt'>

<div style='direction:ltr;border-width:100%'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:36.1569in'>

<div style='direction:ltr;margin-top:0in;margin-left:0in;width:2.9881in'>

<p style='margin:0in;font-family:"Calibri Light";font-size:20.0pt' lang=en-US>Batchnorm
layernorm</p>

</div>

<div style='direction:ltr;margin-top:.0423in;margin-left:0in;width:1.6687in'>

<p style='margin:0in;font-size:10.0pt;color:#767676'><span style='font-family:
Calibri'>2025</span><span style='font-family:"Microsoft YaHei"'>年</span><span
style='font-family:Calibri'>3</span><span style='font-family:"Microsoft YaHei"'>月</span><span
style='font-family:Calibri'>20</span><span style='font-family:"Microsoft YaHei"'>日</span></p>

<p style='margin:0in;font-family:Calibri;font-size:10.0pt;color:#767676'>20:23</p>

</div>

<div style='direction:ltr;margin-top:.5152in;margin-left:.1861in;width:35.9652in'>

<ul style='direction:ltr;unicode-bidi:embed;margin-top:0in;margin-bottom:0in'>
 <p style='margin:0in;font-size:36.0pt'><span style='font-weight:bold;
 font-family:inherit;color:#6C6C6D;background:#F3F4F7' lang=en-US>Class </span><span
 style='font-weight:bold;font-family:FreightSans;color:#6C6C6D;background:#F3F4F7'
 lang=en-US>t</span><span style='font-weight:bold;font-family:FreightSans;
 color:#6C6C6D;background:#F3F4F7' lang=zh-CN>orch.nn.BatchNorm1d</span><span
 style='font-weight:bold;font-family:IBMPlexMono;color:#262626;background:#F3F4F7'
 lang=zh-CN>(</span><span style='font-weight:bold;font-style:italic;font-family:
 IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>num_features</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>eps=1e-05</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>momentum=0.1</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>affine=True</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>track_running_stats=True</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>device=None</span><span
 style='font-weight:bold;font-family:FreightSans;color:#262626;background:#F3F4F7'
 lang=zh-CN>,&nbsp;</span><span style='font-weight:bold;font-style:italic;
 font-family:IBMPlexMono;color:#6C6C6D;background:#F3F4F7' lang=zh-CN>dtype=None</span><span
 style='font-weight:bold;font-family:IBMPlexMono;color:#262626;background:#F3F4F7'
 lang=zh-CN>)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#262626'><span
 style='background:white'>Applies Batch Normalization over a 2D or 3D input.</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='font-weight:bold;background:white'>Parameters</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>num_features</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#int"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>int</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – number of features or channels&nbsp;</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>C</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;of the input</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>eps</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a value added to the denominator for
      numerical stability. Default: 1e-5</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>momentum</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/typing.html#typing.Optional"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>Optional</span></a><span style='font-style:italic;font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>[</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-style:italic;font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>]</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>) – the value used for the running_mean and running_var
      computation. Can be set to&nbsp;</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#6C6C6D;background:white'>None</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>&nbsp;for cumulative moving average (i.e. simple average).
      Default: 0.1</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>affine</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module has
      learnable affine parameters. Default:&nbsp;</span><span style='font-family:
      Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>True</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>track_running_stats</span><span style='font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module tracks the
      running mean and variance, and when set to&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>False</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>, this module does not track such
      statistics, and initializes statistics buffers&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>running_mean</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;and&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>running_var</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>&nbsp;as&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>None</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>. When these buffers are&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>None</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>, this module always uses batch
      statistics. in both training and eval modes. Default:&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>True</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#6C6C6D'><span
 style='background:white'>&gt; </span></p>
 <p style='margin:0in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>Shape:</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white' lang=zh-CN>Input:&nbsp;(N,C)&nbsp;or&nbsp;(N,C,L),
      where&nbsp;N</span><span style='font-style:italic;font-family:Calibri;
      font-size:36.0pt;background:white' lang=zh-CN>N</span><span
      style='font-family:Calibri;font-size:36.0pt;background:white' lang=zh-CN>&nbsp;is
      the batch size,&nbsp;C&nbsp;is the number of features or channels,
      and&nbsp;L</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white' lang=en-US> </span><span style='font-family:Calibri;
      font-size:36.0pt;background:white' lang=zh-CN>is the sequence length</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>Output:&nbsp;(N,C)or&nbsp;(N,C,L)(same
      shape as input)</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>Examples:</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt'><span
 style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt; </span><span
 style='font-style:italic;color:#6C6C6D;background:white'># With Learnable
 Parameters</span><span style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>m =
 nn.BatchNorm1d(</span><span style='color:#009999;background:white'>100</span><span
 style='font-weight:bold;color:black;background:white'>)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-style:italic;color:#6C6C6D;background:white'>#
 Without Learnable Parameters</span><span style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>m =
 nn.BatchNorm1d(</span><span style='color:#009999;background:white'>100</span><span
 style='font-weight:bold;color:black;background:white'>, affine=False)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='color:#0086B3;background:white'>input </span><span
 style='font-weight:bold;color:black;background:white'>= torch.randn(</span><span
 style='color:#009999;background:white'>20</span><span style='font-weight:bold;
 color:black;background:white'>, </span><span style='color:#009999;background:
 white'>100</span><span style='font-weight:bold;color:black;background:white'>)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>output = m(</span><span
 style='color:#0086B3;background:white'>input</span><span style='font-weight:
 bold;color:black;background:white'>)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#6C6C6D'><span
 style='font-weight:bold;background:#F3F4F7'>Class
 torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True,
 track_running_stats=True, device=None, dtype=None)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#6C6C6D'>&nbsp;</p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#262626'><span
 style='background:white'>Applies Batch Normalization over a 4D input.</span></p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#262626'><span
 style='background:white'>4D is a mini-batch of 2D inputs with additional
 channel dimension. </span></p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#262626'><span
 style='background:white'>Because the Batch Normalization is done over
 the&nbsp;C&nbsp;dimension, computing statistics on&nbsp;(N, H, W)&nbsp;slices,
 it’s common terminology to call this Spatial Batch Normalization.</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='font-weight:bold;background:white'>Parameters</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>num_features</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#int"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>int</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) –&nbsp;C&nbsp;from an expected input of
      size&nbsp;(N,C,H,W)</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>eps</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a value added to the denominator for
      numerical stability. Default: 1e-5</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>momentum</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/typing.html#typing.Optional"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>Optional</span></a><span style='font-style:italic;font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>[</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-style:italic;font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>]</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>) – the value used for the running_mean and running_var
      computation. Can be set to&nbsp;</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#6C6C6D;background:white'>None</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>&nbsp;for cumulative moving average (i.e. simple average).
      Default: 0.1</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>affine</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module has
      learnable affine parameters. Default:&nbsp;</span><span style='font-family:
      Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>True</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>track_running_stats</span><span style='font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module tracks the
      running mean and variance, and when set to&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>False</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>, this module does not track such
      statistics, and initializes statistics buffers&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>running_mean</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;and&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>running_var</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>&nbsp;as&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>None</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>. When these buffers are&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>None</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>, this module always uses batch
      statistics. in both training and eval modes. Default:&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>True</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='font-weight:bold;background:white'>Shape:</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>Input:&nbsp;(N,C,H,W</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>Output:&nbsp;(N,C,H,W)&nbsp;(same
      shape as input)</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'># With Learnable Parameters</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>m = nn.BatchNorm2d(100)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'># Without Learnable Parameters</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>m = nn.BatchNorm2d(100, affine=False)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>input = torch.randn(20, 100, 35, 45)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>output = m(input)</span></p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#6C6C6D'>&nbsp;</p>
 <p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#6C6C6D'><span
 style='font-weight:bold;background:#F3F4F7'>Class
 torch.nn.InstanceNorm1d(num_features,&nbsp;eps=1e-05,&nbsp;momentum=0.1,&nbsp;affine=False,&nbsp;track_running_stats=False,&nbsp;device=None,&nbsp;dtype=None)</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>Applies Instance Normalization.</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>This operation applies Instance Normalization over a
 2D (</span><span style='font-weight:bold;background:white'>unbatched</span><span
 style='background:white'>) or 3D (</span><span style='font-weight:bold;
 background:white'>batched</span><span style='background:white'>) input as
 described in the paper&nbsp;</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='font-weight:bold;background:white'>Parameters</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>num_features</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#int"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>int</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – number of features or channels&nbsp;C</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>C</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;of the input</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>eps</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a value added to the denominator for
      numerical stability. Default: 1e-5</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>momentum</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/typing.html#typing.Optional"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>Optional</span></a><span style='font-style:italic;font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>[</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>float</span></a><span style='font-style:italic;font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>]</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>) – the value used for the running_mean and running_var
      computation. Default: 0.1</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>affine</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module has
      learnable affine parameters, initialized the same way as done for batch
      normalization. Default:&nbsp;</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#6C6C6D;background:white'>False</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#262626;background:
      white'>.</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
      background:white'>track_running_stats</span><span style='font-family:
      Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
      font-size:36.0pt;color:#262626;background:white'>, this module tracks the
      running mean and variance, and when set to&nbsp;</span><span
      style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:
      white'>False</span><span style='font-family:Calibri;font-size:36.0pt;
      color:#262626;background:white'>, this module does not track such
      statistics and always uses batch statistics in both training and eval
      modes. Default:&nbsp;</span><span style='font-family:Calibri;font-size:
      36.0pt;color:#6C6C6D;background:white'>False</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>Shape:</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>Input:&nbsp;(N,C,L)(</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>N</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>,</span><span style='font-style:italic;font-family:
      Calibri;font-size:36.0pt;background:white'>C</span><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>L</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>)&nbsp;or&nbsp;(C,L)(</span><span style='font-style:
      italic;font-family:Calibri;font-size:36.0pt;background:white'>C</span><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>L</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>)</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>Output:&nbsp;(N,C,L)(</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>N</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>,</span><span style='font-style:italic;font-family:
      Calibri;font-size:36.0pt;background:white'>C</span><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>L</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>)&nbsp;or&nbsp;(C,L)(</span><span style='font-style:
      italic;font-family:Calibri;font-size:36.0pt;background:white'>C</span><span
      style='font-family:Calibri;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
      white'>L</span><span style='font-family:Calibri;font-size:36.0pt;
      background:white'>)&nbsp;(same shape as input)</span></li>
 </ul>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
 style='background:white'>Examples:</span></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt'><span
 style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt; </span><span
 style='font-style:italic;color:#6C6C6D;background:white'># Without Learnable
 Parameters</span><span style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>m =
 nn.InstanceNorm1d(</span><span style='color:#009999;background:white'>100</span><span
 style='font-weight:bold;color:black;background:white'>)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-style:italic;color:#6C6C6D;background:white'># With
 Learnable Parameters</span><span style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>m =
 nn.InstanceNorm1d(</span><span style='color:#009999;background:white'>100</span><span
 style='font-weight:bold;color:black;background:white'>, affine=True)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='color:#0086B3;background:white'>input </span><span
 style='font-weight:bold;color:black;background:white'>= torch.randn(</span><span
 style='color:#009999;background:white'>20</span><span style='font-weight:bold;
 color:black;background:white'>, </span><span style='color:#009999;background:
 white'>100</span><span style='font-weight:bold;color:black;background:white'>,
 </span><span style='color:#009999;background:white'>40</span><span
 style='font-weight:bold;color:black;background:white'>)</span><span
 style='color:#212529;background:white'><br>
  </span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
 </span><span style='font-weight:bold;color:black;background:white'>output = m(</span><span
 style='color:#0086B3;background:white'>input</span><span style='font-weight:
 bold;color:black;background:white'>)</span></p>
</ul>

</div>

<div style='direction:ltr;margin-top:.3562in;margin-left:.2437in;width:34.9055in'>

<ul style='direction:ltr;unicode-bidi:embed;margin-top:0in;margin-bottom:0in'>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span
 style='font-weight:bold;color:#6C6C6D;background:#F3F4F7'>classtorch.nn.InstanceNorm2d</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>(</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>num_features</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>eps=1e-05</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>momentum=0.1</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>affine=False</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>track_running_stats=False</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>device=None</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>,&nbsp;</span><span
 style='font-weight:bold;font-style:italic;color:#6C6C6D;background:#F3F4F7'>dtype=None</span><span
 style='font-weight:bold;color:#262626;background:#F3F4F7'>)</span><a
 href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#InstanceNorm2d"><span
 style='font-weight:bold;background:#F3F4F7'>[source]</span></a><a
 href="https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L241"><span
 style='font-weight:bold;background:#F3F4F7'>[source]</span></a></p>
 <p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#262626'><span
 style='background:white'>Applies Instance Normalization.</span></p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span
 style='color:#262626;background:white'>This operation applies Instance
 Normalization over a 4D input (a mini-batch of 2D inputs with additional
 channel dimension) as described in the paper&nbsp;</span><a
 href="https://arxiv.org/abs/1607.08022"><span style='background:white'>Instance
 Normalization: The Missing Ingredient for Fast Stylization</span></a><span
 style='color:#262626;background:white'>.</span></p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#262626'>&nbsp;</p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#262626'><span
 style='font-weight:bold;background:white'>Parameters</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>num_features</span><span style='font-family:微软雅黑;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#int"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>int</span></a><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>) –&nbsp;C</span><span style='font-style:
      italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>C</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>&nbsp;from
      an expected input of size&nbsp;(N,C,H,W)(</span><span style='font-style:
      italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>N</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>C</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>,</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>H</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>W</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>)&nbsp;or&nbsp;(C,H,W)(</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>C</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>,</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>H</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>W</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>)</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>eps</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>float</span></a><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>) – a value added to the denominator for
      numerical stability. Default: 1e-5</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>momentum</span><span style='font-family:微软雅黑;
      font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/typing.html#typing.Optional"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>Optional</span></a><span style='font-style:italic;font-family:
      微软雅黑;font-size:36.0pt;color:#262626;background:white'>[</span><a
      href="https://docs.python.org/3/library/functions.html#float"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>float</span></a><span style='font-style:italic;font-family:微软雅黑;
      font-size:36.0pt;color:#262626;background:white'>]</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>)
      – the value used for the running_mean and running_var computation.
      Default: 0.1</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>affine</span><span style='font-family:微软雅黑;font-size:
      36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:微软雅黑;font-size:36.0pt;color:#6C6C6D;
      background:#F3F4F7'>True</span><span style='font-family:微软雅黑;font-size:
      36.0pt;color:#262626;background:white'>, this module has learnable affine
      parameters, initialized the same way as done for batch normalization.
      Default:&nbsp;</span><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#6C6C6D;background:#F3F4F7'>False</span><span style='font-family:
      微软雅黑;font-size:36.0pt;color:#262626;background:white'>.</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-weight:bold;font-family:微软雅黑;font-size:36.0pt;color:#262626;
      background:white'>track_running_stats</span><span style='font-family:
      微软雅黑;font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
      href="https://docs.python.org/3/library/functions.html#bool"><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>bool</span></a><span style='font-family:微软雅黑;font-size:36.0pt;
      color:#262626;background:white'>) – a boolean value that when set
      to&nbsp;</span><span style='font-family:微软雅黑;font-size:36.0pt;color:#6C6C6D;
      background:#F3F4F7'>True</span><span style='font-family:微软雅黑;font-size:
      36.0pt;color:#262626;background:white'>, this module tracks the running
      mean and variance, and when set to&nbsp;</span><span style='font-family:
      微软雅黑;font-size:36.0pt;color:#6C6C6D;background:#F3F4F7'>False</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#262626;background:white'>,
      this module does not track such statistics and always uses batch
      statistics in both training and eval modes. Default:&nbsp;</span><span
      style='font-family:微软雅黑;font-size:36.0pt;color:#6C6C6D;background:#F3F4F7'>False</span></li>
 </ul>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#262626'><span
 style='background:#F3F4F7'>Shape:</span></p>
 <ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
  margin-bottom:0in'>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>Input:&nbsp;(N,C,H,W)(</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>N</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>,</span><span style='font-style:italic;font-family:微软雅黑;
      font-size:36.0pt;background:white'>C</span><span style='font-family:微软雅黑;
      font-size:36.0pt;background:white'>,</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;background:white'>H</span><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>W</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>)&nbsp;or&nbsp;(C,H,W)(</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;background:white'>C</span><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>H</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>,</span><span style='font-style:italic;font-family:微软雅黑;
      font-size:36.0pt;background:white'>W</span><span style='font-family:微软雅黑;
      font-size:36.0pt;background:white'>)</span></li>
  <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>Output:&nbsp;(N,C,H,W)(</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>N</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>,</span><span style='font-style:italic;font-family:微软雅黑;
      font-size:36.0pt;background:white'>C</span><span style='font-family:微软雅黑;
      font-size:36.0pt;background:white'>,</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;background:white'>H</span><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>W</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>)&nbsp;or&nbsp;(C,H,W)(</span><span style='font-style:italic;
      font-family:微软雅黑;font-size:36.0pt;background:white'>C</span><span
      style='font-family:微软雅黑;font-size:36.0pt;background:white'>,</span><span
      style='font-style:italic;font-family:微软雅黑;font-size:36.0pt;background:
      white'>H</span><span style='font-family:微软雅黑;font-size:36.0pt;background:
      white'>,</span><span style='font-style:italic;font-family:微软雅黑;
      font-size:36.0pt;background:white'>W</span><span style='font-family:微软雅黑;
      font-size:36.0pt;background:white'>)&nbsp;(same shape as input)</span></li>
 </ul>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#262626'><span
 style='background:white'>Examples:</span></p>
 <p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span
 style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='font-style:italic;color:#6C6C6D'># Without Learnable Parameters</span><span
 style='color:#212529'><br>
  </span><span style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='font-weight:bold;color:black'>m = nn.InstanceNorm2d(</span><span
 style='color:#009999'>100</span><span style='font-weight:bold;color:black'>)</span><span
 style='color:#212529'><br>
  </span><span style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='font-style:italic;color:#6C6C6D'># With Learnable Parameters</span><span
 style='color:#212529'><br>
  </span><span style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='font-weight:bold;color:black'>m = nn.InstanceNorm2d(</span><span
 style='color:#009999'>100</span><span style='font-weight:bold;color:black'>,
 affine=True)</span><span style='color:#212529'><br>
  </span><span style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='color:#0086B3'>input </span><span style='font-weight:bold;color:black'>=
 torch.randn(</span><span style='color:#009999'>20</span><span
 style='font-weight:bold;color:black'>, </span><span style='color:#009999'>100</span><span
 style='font-weight:bold;color:black'>, </span><span style='color:#009999'>35</span><span
 style='font-weight:bold;color:black'>, </span><span style='color:#009999'>45</span><span
 style='font-weight:bold;color:black'>)</span><span style='color:#212529'><br>
  </span><span style='font-weight:bold;color:#555555'>&gt;&gt;&gt; </span><span
 style='font-weight:bold;color:black'>output = m(</span><span style='color:
 #0086B3'>input</span><span style='font-weight:bold;color:black'>)</span></p>
</ul>

</div>

<div style='direction:ltr;margin-top:1.9347in;margin-left:.4597in;width:35.6916in'>

<p style='margin:0in;font-size:36.0pt'><span style='font-weight:bold;
font-family:Calibri;color:black;background:white' lang=en-US>BatchNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>和</span><span style='font-weight:bold;font-family:Calibri;
color:black;background:white' lang=en-US>I</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:black;background:white' lang=zh-CN>n</span><span
style='font-weight:bold;font-family:Calibri;color:black;background:white'
lang=en-US>stanceNorm</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=zh-CN>的参数都是num</span><span style='font-weight:
bold;font-family:Calibri;color:black;background:white' lang=en-US>_features</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>，即</span><span style='font-weight:bold;font-family:Calibri;
color:black;background:white' lang=en-US>channel</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:black;background:white' lang=zh-CN>的个数或者特征的个数（对于</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=en-US>2Dtensor</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:black;background:white' lang=zh-CN>来说），也就是说都是对每个cha</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=en-US>nnel</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=zh-CN>独立地计算均值和方差，区别在于，对于</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=en-US>channel A</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:black;background:white' lang=zh-CN>来说，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=en-US>B</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=zh-CN>at</span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:black;background:white' lang=en-US>chNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>统计均值和方差时用到的是</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:black;background:white' lang=en-US>batch</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>中所有样本的值，而</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:black;background:white' lang=en-US>I</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>n</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=en-US>stanceNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>统计均值和方差时用到的是单个样本的值。</span><span style='font-weight:bold;
font-family:Calibri;color:black;background:white' lang=en-US>BatchNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:black;background:
white' lang=zh-CN>和</span><span style='font-weight:bold;font-family:Calibri;
color:black;background:white' lang=en-US>I</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:black;background:white' lang=zh-CN>n</span><span
style='font-weight:bold;font-family:Calibri;color:black;background:white'
lang=en-US>stanceNorm</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=zh-CN>都有两个可学习参数，这两个参数的</span><span
style='font-weight:bold;font-family:Calibri;color:black;background:white'
lang=en-US>shape</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:black;background:white' lang=zh-CN>都是</span><span style='font-weight:
bold;font-family:Calibri;color:#262626;background:white' lang=zh-CN>num_features</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#262626;background:
white' lang=zh-CN>。</span></p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>

<p style='margin:0in;font-size:36.0pt;color:#0070C0'><span style='font-family:
微软雅黑;background:white' lang=zh-CN>★</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>对于</span><span style='font-family:Calibri;
background:white' lang=en-US>Instancenorm</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>来说，如果特征是标量，不是</span><span style='font-family:Calibri;
background:white' lang=en-US>vector</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>，那么就没办法做</span><span style='font-family:Calibri;
background:white' lang=en-US>InstanceNorm</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>，因为只有一个数，没法算平均值，只有</span><span style='font-family:
Calibri;background:white' lang=en-US>vector</span><span style='font-family:
"Microsoft YaHei";background:white' lang=zh-CN>才能算平均值。所以对</span><span
style='font-weight:bold;font-family:FreightSans;background:#F3F4F7' lang=zh-CN>InstanceNorm1d</span><span
style='font-family:"Microsoft YaHei";background:white' lang=zh-CN>来说，当输入是</span><span
style='font-family:Calibri;background:white' lang=en-US>2D</span><span
style='font-family:"Microsoft YaHei";background:white' lang=zh-CN>的时候</span><span
style='font-family:"Microsoft YaHei";background:white' lang=en-US> </span><span
style='font-family:"Microsoft YaHei";background:white' lang=zh-CN>，是</span><span
style='font-family:"Microsoft YaHei";background:white' lang=en-US>unbatched</span><span
style='font-family:"Microsoft YaHei";background:white' lang=zh-CN>的，也就是这个</span><span
style='font-family:"Microsoft YaHei";background:white' lang=en-US>2D</span><span
style='font-family:"Microsoft YaHei";background:white' lang=zh-CN>输入是单个样本。而</span><span
style='font-weight:bold;font-family:FreightSans;background:#F3F4F7' lang=zh-CN>BatchNorm1d</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:#F3F4F7'
lang=en-US> </span><span style='font-family:"Microsoft YaHei";background:white'
lang=zh-CN>就没有这个问题，当</span><span style='font-weight:bold;font-family:FreightSans;
background:#F3F4F7' lang=zh-CN>BatchNorm1d</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>的输入是</span><span style='font-family:"Microsoft YaHei";
background:white' lang=en-US>2D</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>的时候，这个输入也是</span><span style='font-family:"Microsoft YaHei";
background:white' lang=en-US>batched</span><span style='font-family:"Microsoft YaHei";
background:white' lang=zh-CN>。</span></p>

</div>

<div style='direction:ltr;margin-top:1.2222in;margin-left:.4597in;width:34.9402in'>

<p style='margin:0in;font-size:36.0pt'><span style='font-family:Calibri'
lang=en-US>Instancenorm</span><span style='font-family:"Microsoft YaHei"'
lang=zh-CN>没法用于</span><span style='font-family:Calibri' lang=en-US>NLP</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>中。</span></p>

<p style='margin:0in;font-size:36.0pt'><span style='font-weight:bold;
font-family:Calibri' lang=en-US>BatchNorm</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>可以。对于</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>NLP</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>来说，</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>input</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>的s</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>hape</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>是</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>[batch_size, seq_len, embedding_len</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>（</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>hidden_size</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>）</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>]</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，用的时候，将前两维</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>flatten</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，即</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>reshape</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>成</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US> [batch_size*
seq_len, embedding_len]</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>的</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>2D </span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>ten</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>sor</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>。用</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>B</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>at</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>chnorm1d</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>。有两种方式，效果是一样的。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt'><span
style='font-weight:bold'>第一种：</span></p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'><span lang=zh-CN>feature = torch.randn(4, 2,
5)<span style='mso-spacerun:yes'>  </span># [ batch, seq_len, hidden_size
]<br>
feature = feature.transpose(1, 2)<span style='mso-spacerun:yes'>  </span># [
batch, hidden_size, seq_len ]</span><span lang=en-US> </span><span
style='font-weight:bold' lang=zh-CN>输入是</span><span style='font-weight:bold'
lang=en-US>3D</span><span style='font-weight:bold' lang=zh-CN>的，</span></p>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'>bn = nn.BatchNorm1d(5, eps=1e-5)<span
style='mso-spacerun:yes'>  </span># hidden_dim<br>
output = bn(feature1)</p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F' lang=en-US>Output = output.reshape(4,2,5)</p>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt'><span
style='font-weight:bold'>第二种：</span></p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'><span lang=zh-CN>feature = torch.randn(4, 2,
5)<span style='mso-spacerun:yes'>  </span># [ batch, seq_len, hidden_size
]<br>
feature = feature.</span><span lang=en-US>reshape</span><span lang=zh-CN>(</span><span
lang=en-US>4*2, 5</span><span lang=zh-CN>)<span style='mso-spacerun:yes'> 
</span># [ batch</span><span lang=en-US> * </span><span lang=zh-CN>seq_len ,
hidden_size</span><span lang=en-US> </span><span lang=zh-CN>]</span><span
lang=en-US><span style='mso-spacerun:yes'>  </span></span><span
style='font-weight:bold' lang=zh-CN>输入是</span><span style='font-weight:bold'
lang=en-US>2D</span><span style='font-weight:bold' lang=zh-CN>的</span></p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'>bn = nn.BatchNorm1d(5, eps=1e-5)<span
style='mso-spacerun:yes'>  </span># hidden_dim<br>
output = bn(feature1)</p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F' lang=en-US>Output = output.reshape(4,2,5)</p>

<p style='margin:0in;margin-left:.375in;font-family:"Microsoft YaHei";
font-size:36.0pt;color:#191B1F'>&nbsp;</p>

<p style='margin:0in;font-size:36.0pt'><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#191B1F' lang=zh-CN>总结：</span><span
style='font-weight:bold;font-family:Calibri;color:#191B1F' lang=en-US>Batchnorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#191B1F'
lang=zh-CN>是按照特征进行操作的，对于每个特征，计算</span><span style='font-weight:bold;font-family:
Calibri;color:#191B1F' lang=en-US>batch</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#191B1F' lang=zh-CN>中所有样本的均值和标准差，然后进行</span><span
style='font-weight:bold;font-family:Calibri;color:#191B1F' lang=en-US>norm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#191B1F'
lang=zh-CN>以及缩放。</span><span style='font-weight:bold;font-family:Calibri;
color:#C00000' lang=en-US>Batchnorm</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>有四个参数，</span><span
style='font-weight:bold;font-family:Calibri;color:#C00000' lang=en-US>gamma
,beta,running_mean,running_variance</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>，对于每一个特征来说，都有这样</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>4</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>个参数，即</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";color:#C00000' lang=en-US>gamma.shape == beta.shape ==
running_mean.shape == running_var.shape == </span><span style='font-weight:
bold;font-family:"Microsoft YaHei";color:#C00000' lang=zh-CN>num</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";color:#C00000'
lang=en-US>_features</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
color:#C00000' lang=zh-CN>。</span></p>

<p style='margin:0in;font-size:36.0pt;color:#191B1F'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>对于</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>image</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>来说，特征的数目</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>=channel</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的数目，一张图片是一个样本，样本的特征数目</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>=</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>图片的通道数，单个样本的单个特征是</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>2D </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>tensor</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>.</span></p>

<p style='margin:0in;font-size:36.0pt;color:#191B1F'><span style='font-weight:
bold;font-family:"Microsoft YaHei"' lang=zh-CN>对于</span><span style='font-weight:
bold;font-family:Calibri' lang=en-US>NLP</span><span style='font-weight:bold;
font-family:"Microsoft YaHei"' lang=zh-CN>来说，特征的数目</span><span
style='font-weight:bold;font-family:Calibri' lang=en-US>= token </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US> embedding </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>size</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>,</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>或者</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US> token </span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>的</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>hidden_size</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，一个</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>token</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>是一个样本，样本的特征数目</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=en-US>= hidden_size</span><span
style='font-weight:bold;font-family:"Microsoft YaHei"' lang=zh-CN>，单个样本的单个特征是一个标量。</span></p>

</div>

<div style='direction:ltr;margin-top:.2625in;margin-left:.4597in;width:34.602in'>

<p style='margin:0in;font-size:36.0pt'><span style='font-family:微软雅黑'
lang=zh-CN>★</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>为什么</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>B</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>at</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>chnorm</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>不用于</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>T</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>ra</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=en-US>nsformer</span><span style='font-weight:bold;font-family:"Microsoft YaHei"'
lang=zh-CN>中？</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt'><span
lang=zh-CN>一个bat</span><span lang=en-US>ch</span><span lang=zh-CN>中</span><span
lang=en-US>text_length</span><span lang=zh-CN>是不同的，需要统一</span><span lang=en-US>padding</span><span
lang=zh-CN>到</span><span lang=en-US>max_length</span><span lang=zh-CN>，正是因为</span><span
style='font-weight:bold;color:#191B1F' lang=zh-CN>一个</span><span
style='font-weight:bold;color:#191B1F' lang=en-US>token</span><span
style='font-weight:bold;color:#191B1F' lang=zh-CN>是一个样本，有些</span><span
style='font-weight:bold;color:#191B1F' lang=en-US>token</span><span
style='font-weight:bold;color:#191B1F' lang=zh-CN>是</span><span
style='font-weight:bold;color:#191B1F' lang=en-US>padding token</span><span
style='font-weight:bold;color:#191B1F' lang=zh-CN>，</span><span lang=zh-CN>这些</span><span
lang=en-US>padding</span><span lang=zh-CN>会影响均值和方差的计算。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt'>The
fundamental issue is that padding tokens, although necessary for alignment, are
not part of the original data. They introduce a lot of zeros into the dataset,
which can mislead the normalization process. This is why batch normalization is
not applied in the context of self-attention in transformers.</p>

<p><cite style='margin:0in;font-family:Calibri;font-size:9.0pt;color:#595959'>&nbsp;</cite></p>

<p style='margin:0in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>

<p style='margin:0in;font-size:36.0pt'><span style='font-family:Calibri'
lang=en-US>B</span><span style='font-family:"Microsoft YaHei"' lang=en-US>atchnorm</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>进行计算时，计算每个</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>batch</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>的均值和方差，计算方差时需要注意用</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>bessel correction</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>。</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>pytorch</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>里</span><span
style='font-family:"Microsoft YaHei"' lang=en-US>unbiased = True</span><span
style='font-family:"Microsoft YaHei"' lang=zh-CN>。</span></p>

</div>

<div style='direction:ltr;margin-top:1.6777in;margin-left:.4597in;width:35.6972in'>

<p style='margin:0in;font-family:FreightSans;font-size:36.0pt;color:#6C6C6D'><span
style='font-weight:bold;background:#F3F4F7'>Class
torch.nn.LayerNorm(normalized_shape,&nbsp;eps=1e-05,&nbsp;elementwise_affine=True,&nbsp;bias=True,&nbsp;device=None,&nbsp;dtype=None)</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt;color:#6C6C6D'>&nbsp;</p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt'><span
style='color:#262626;background:white'>The mean and standard-deviation are
calculated over the last&nbsp;D&nbsp;dimensions, where&nbsp;D&nbsp;is the
dimension of&nbsp;</span><span style='color:#6C6C6D;background:white'>normalized_shape</span><span
style='color:#262626;background:white'>. For example, if&nbsp;</span><span
style='color:#6C6C6D;background:white'>normalized_shape</span><span
style='color:#262626;background:white'>&nbsp;is&nbsp;</span><span
style='color:#6C6C6D;background:white'>(3,</span><span style='color:#262626;
background:white'>&nbsp;</span><span style='color:#6C6C6D;background:white'>5)</span><span
style='color:#262626;background:white'>&nbsp;(a 2-dimensional shape), the mean
and standard-deviation are computed over the last 2 dimensions of the input
(i.e.&nbsp;</span><span style='color:#6C6C6D;background:white'>input.mean((-2,</span><span
style='color:#262626;background:white'>&nbsp;</span><span style='color:#6C6C6D;
background:white'>-1))</span><span style='color:#262626;background:white'>).&nbsp;γ</span><span
style='font-style:italic;color:#262626;background:white'>γ</span><span
style='color:#262626;background:white'>&nbsp;and&nbsp;β</span><span
style='font-style:italic;color:#262626;background:white'>β</span><span
style='color:#262626;background:white'>&nbsp;are learnable affine transform
parameters of&nbsp;</span><span style='color:#6C6C6D;background:white'>normalized_shape</span><span
style='color:#262626;background:white'>&nbsp;if&nbsp;</span><span
style='color:#6C6C6D;background:white'>elementwise_affine</span><span
style='color:#262626;background:white'>&nbsp;is&nbsp;</span><span
style='color:#6C6C6D;background:white'>True</span><span style='color:#262626;
background:white'>. The variance is calculated via the biased estimator,
equivalent to&nbsp;torch.var(input, unbiased=False).</span></p>

<p><cite style='margin:0in;font-family:"Microsoft YaHei";font-size:9.0pt;
color:#595959'>&nbsp;</cite></p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'>&nbsp;</p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
style='background:white'>This layer uses statistics computed from input data in
both training and evaluation modes.</span></p>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:36.0pt;
color:#262626'><span style='font-weight:bold;background:white'>Parameters</span></p>

<ul type=circle style='direction:ltr;unicode-bidi:embed;margin-top:0in;
 margin-bottom:0in'>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>normalized_shape</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
     href="https://docs.python.org/3/library/functions.html#int"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>int</span></a><span style='font-style:italic;font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;or&nbsp;</span><a
     href="https://docs.python.org/3/library/stdtypes.html#list"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>list</span></a><span style='font-style:italic;font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;or&nbsp;</span><a
     href="https://pytorch.org/docs/stable/size.html#torch.Size"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>torch.Size</span></a><span style='font-family:Calibri;font-size:
     36.0pt;color:#262626;background:white'>) –<br>
          input shape from an expected input of size<br>
          [</span><span style='font-family:"Cambria Math";font-size:36.0pt;
     color:#262626;background:white'>∗</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>×normalized_shape[0]×normalized_shape[1]×…×normalized_shape[−1]][</span><span
     style='font-family:"Cambria Math";font-size:36.0pt;color:#262626;
     background:white'>∗</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#262626;background:white'>×normalized_shape[0]×normalized_shape[1]×…×normalized_shape[−1]]<br>
          If a single integer is used, it is treated as a singleton list, and
     this module will normalize over the last dimension which is expected to be
     of that specific size.</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>eps</span><span style='font-family:Calibri;font-size:
     36.0pt;color:#262626;background:white'>&nbsp;(</span><a
     href="https://docs.python.org/3/library/functions.html#float"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>float</span></a><span style='font-family:Calibri;font-size:36.0pt;
     color:#262626;background:white'>) – a value added to the denominator for
     numerical stability. Default: 1e-5</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>elementwise_affine</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;(</span><a
     href="https://docs.python.org/3/library/functions.html#bool"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
     color:#262626;background:white'>) – a boolean value that when set to&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>True</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>,
     this module has learnable per-element affine parameters initialized to
     ones (for weights) and zeros (for biases). Default:&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>True</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>.</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>bias</span><span style='font-family:Calibri;font-size:
     36.0pt;color:#262626;background:white'>&nbsp;(</span><a
     href="https://docs.python.org/3/library/functions.html#bool"><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>bool</span></a><span style='font-family:Calibri;font-size:36.0pt;
     color:#262626;background:white'>) – If set to&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>False</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>,
     the layer will not learn an additive bias (only relevant if&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>elementwise_affine</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;is&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>True</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>).
     Default:&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>.</span></li>
</ul>

<p style='margin:0in;margin-left:.75in;font-family:Calibri;font-size:36.0pt;
color:#262626'><span style='font-weight:bold;background:white'>Variables</span></p>

<ul type=circle style='direction:ltr;unicode-bidi:embed;margin-top:0in;
 margin-bottom:0in'>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>weight</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;– the learnable
     weights of the module of
     shape&nbsp;normalized_shapenormalized_shape&nbsp;when&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>elementwise_affine</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;is
     set to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>. The values are
     initialized to 1.</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>bias</span><span style='font-family:Calibri;font-size:
     36.0pt;color:#262626;background:white'>&nbsp;– the learnable bias of the
     module of shape&nbsp;normalized_shapenormalized_shape&nbsp;when&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>elementwise_affine</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;is
     set to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>. The values are
     initialized to 0.</span></li>
</ul>

<p style='margin:0in;margin-left:.75in;font-family:Calibri;font-size:36.0pt;
color:#262626'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:36.0pt;
color:#262626'><span style='font-weight:bold;background:white'>Variables</span></p>

<ul type=circle style='direction:ltr;unicode-bidi:embed;margin-top:0in;
 margin-bottom:0in'>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>weight</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>&nbsp;– the learnable
     weights of the module of
     shape&nbsp;normalized_shapenormalized_shape&nbsp;when&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>elementwise_affine</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;is
     set to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>. The values are
     initialized to 1.</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-weight:bold;font-family:Calibri;font-size:36.0pt;color:#262626;
     background:white'>bias</span><span style='font-family:Calibri;font-size:
     36.0pt;color:#262626;background:white'>&nbsp;– the learnable bias of the
     module of shape&nbsp;normalized_shapenormalized_shape&nbsp;when&nbsp;</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#6C6C6D;background:white'>elementwise_affine</span><span
     style='font-family:Calibri;font-size:36.0pt;color:#262626;background:white'>&nbsp;is
     set to&nbsp;</span><span style='font-family:Calibri;font-size:36.0pt;
     color:#6C6C6D;background:white'>True</span><span style='font-family:Calibri;
     font-size:36.0pt;color:#262626;background:white'>. The values are
     initialized to 0.</span></li>
</ul>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:36.0pt;
color:#262626'>&nbsp;</p>

<p style='margin:0in;margin-left:.375in;font-family:Calibri;font-size:36.0pt;
color:#262626'><span style='background:white'>Shape:</span></p>

<ul type=disc style='direction:ltr;unicode-bidi:embed;margin-top:0in;
 margin-bottom:0in'>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-family:Calibri;font-size:36.0pt;background:white'>Input:&nbsp;(N,</span><span
     style='font-family:"Cambria Math";font-size:36.0pt;background:white'>∗</span><span
     style='font-family:Calibri;font-size:36.0pt;background:white'>)(</span><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>N</span><span style='font-family:Calibri;font-size:36.0pt;
     background:white'>,</span><span style='font-family:"Cambria Math";
     font-size:36.0pt;background:white'>∗</span><span style='font-family:Calibri;
     font-size:36.0pt;background:white'>)</span></li>
 <li style='margin-top:0;margin-bottom:0;vertical-align:middle;color:#262626'><span
     style='font-family:Calibri;font-size:36.0pt;background:white'>Output:&nbsp;(N,</span><span
     style='font-family:"Cambria Math";font-size:36.0pt;background:white'>∗</span><span
     style='font-family:Calibri;font-size:36.0pt;background:white'>)(</span><span
     style='font-style:italic;font-family:Calibri;font-size:36.0pt;background:
     white'>N</span><span style='font-family:Calibri;font-size:36.0pt;
     background:white'>,</span><span style='font-family:"Cambria Math";
     font-size:36.0pt;background:white'>∗</span><span style='font-family:Calibri;
     font-size:36.0pt;background:white'>)&nbsp;(same shape as input)</span></li>
</ul>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:#262626'><span
style='background:white'>Examples:</span></p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt'><span
style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt; </span><span
style='font-style:italic;color:#6C6C6D;background:white'># NLP Example</span><span
style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>batch,
sentence_length, embedding_dim = </span><span style='color:#009999;background:
white'>20</span><span style='font-weight:bold;color:black;background:white'>, </span><span
style='color:#009999;background:white'>5</span><span style='font-weight:bold;
color:black;background:white'>, </span><span style='color:#009999;background:
white'>10</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>embedding =
torch.randn(batch, sentence_length, embedding_dim)</span><span
style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>layer_norm =
nn.LayerNorm(embedding_dim)</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-style:italic;color:#6C6C6D;background:white'>#
Activate module</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>layer_norm(embedding)</span><span
style='color:#212529;background:white'><br>
</span><span style='color:#888888;background:white'>&gt;&gt;&gt;</span><span
style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-style:italic;color:#6C6C6D;background:white'># Image
Example</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>N, C, H, W =
</span><span style='color:#009999;background:white'>20</span><span
style='font-weight:bold;color:black;background:white'>, </span><span
style='color:#009999;background:white'>5</span><span style='font-weight:bold;
color:black;background:white'>, </span><span style='color:#009999;background:
white'>10</span><span style='font-weight:bold;color:black;background:white'>, </span><span
style='color:#009999;background:white'>10</span><span style='color:#212529;
background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='color:#0086B3;background:white'>input </span><span
style='font-weight:bold;color:black;background:white'>= torch.randn(N, C, H, W)</span><span
style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-style:italic;color:#6C6C6D;background:white'>#
Normalize over the last three dimensions (i.e. the channel and spatial
dimensions)</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-style:italic;color:#6C6C6D;background:white'># as
shown in the image below</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>layer_norm =
nn.LayerNorm([C, H, W])</span><span style='color:#212529;background:white'><br>
</span><span style='font-weight:bold;color:#555555;background:white'>&gt;&gt;&gt;
</span><span style='font-weight:bold;color:black;background:white'>output =
layer_norm(</span><span style='color:#0086B3;background:white'>input</span><span
style='font-weight:bold;color:black;background:white'>)</span></p>

<p style='margin:0in;font-family:Calibri;font-size:36.0pt;color:black'>&nbsp;</p>

<p style='margin:0in;font-size:36.0pt;color:black'><span style='font-weight:
bold;font-family:Calibri;background:white'>LayerNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'>中不会像</span><span
style='font-weight:bold;font-family:Calibri;background:white'>BatchNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'>那样跟踪统计全局的均值方差，因此</span><span
style='font-weight:bold;font-family:Calibri;background:white'>train()</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'>和</span><span
style='font-weight:bold;font-family:Calibri;background:white'>eval()</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'>对</span><span
style='font-weight:bold;font-family:Calibri;background:white'>LayerNorm</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'>没有影响。</span></p>

<p style='margin:0in;line-height:18pt;font-family:"Microsoft YaHei";font-size:
36.0pt;color:black'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>normalized_shape：</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>如果传入整数，比如4，则被看做只有一个整数的list，此时LayerNorm会对输入的最后一维进行归一化，这个int值需要和输入的最后一维一样大。</span></p>

<p style='margin:0in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>假设此时输入的数据维度是[3,
4]，则对3个长度为4的向量求均值方差，得到3个均值和3个方差，分别对这3行进行归一化（每一行的4个数字都是均值为0，方差为1）；LayerNorm中的weight和bias也分别包含4个数字，重复使用3次，对每一行进行仿射变换（仿射变换即乘以weight中对应的数字后，然后加bias中对应的数字），并会在反向传播时得到学习。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>如果输入的是个list或者torch.Size，比如[3,
4]或torch.Size([3, 4])，则会对网络最后的两维进行归一化，且要求输入数据的最后两维尺寸也是[3, 4]。</span></p>

<p style='margin:0in;font-family:Calibri;font-size:11.0pt'>&nbsp;</p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>假设此时输入的数据维度也是[3,
4]，首先对这12个数字求均值和方差，然后归一化这个12个数字；weight和bias也分别包含12个数字，分别对12个归一化后的数字进行仿射变换（仿射变换即乘以weight中对应的数字后，然后加bias中对应的数字），并会在反向传播时得到学习。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>假设此时输入的数据维度是[N, 3,
4]，则对着N个[3,4]做和上述一样的操作，只是此时做仿射变换时，weight和bias被重复用了N次。</span></p>

<p style='margin:0in;font-family:"Microsoft YaHei";font-size:36.0pt;color:black'><span
style='font-weight:bold;background:white'>假设此时输入的数据维度是[N, T, 3,
4]，也是一样的，维度可以更多。</span></p>

<p style='margin:0in;font-size:36.0pt;color:black'><span style='font-weight:
bold;font-family:"Microsoft YaHei";background:white' lang=zh-CN>注意：显然LayerNorm中weight和bias的shape就是传入的normalized_shape。对于</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=en-US>NLP</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=zh-CN>来说，</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";background:white' lang=en-US>weight</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=zh-CN>和</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=en-US>bias</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";background:white' lang=zh-CN>的sh</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=en-US>ape</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=zh-CN>是e</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";background:white' lang=en-US>mbedding_dim</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=zh-CN>，对于</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=en-US>Image</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";background:white' lang=zh-CN>来说，</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=en-US>weight</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=zh-CN>和</span><span style='font-weight:bold;font-family:
"Microsoft YaHei";background:white' lang=en-US>bias</span><span
style='font-weight:bold;font-family:"Microsoft YaHei";background:white'
lang=zh-CN>的sh</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=en-US>ape</span><span style='font-weight:bold;
font-family:"Microsoft YaHei";background:white' lang=zh-CN>是</span><span
style='font-weight:bold;font-family:Calibri;background:white' lang=zh-CN>[C, H,
W]</span><span style='font-weight:bold;font-family:"Microsoft YaHei";
background:white' lang=zh-CN>。</span></p>

</div>

<div style='direction:ltr;margin-top:1.7569in;margin-left:1.4902in;width:15.5395in'><img
src="Batchnorm%20layernorm.files/image001.png" width=2238 height=171
alt="墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;墨迹绘图&#13;&#10;"></div>

<div style='direction:ltr;margin-top:1.2777in;margin-left:.4597in;width:32.1666in'>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt' lang=en-US><span
style='font-weight:bold;background:lime;mso-highlight:lime'>Batchnorm make sure
that across batch dimension, any individual neuron has unit gaussian
distribution.</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span style='font-weight:
bold' lang=zh-CN>★以最简单的</span><span style='font-weight:bold' lang=en-US>Batchnorm1D</span><span
style='font-weight:bold' lang=zh-CN>和</span><span style='font-weight:bold'
lang=en-US>LayerNorm1D</span><span style='font-weight:bold' lang=zh-CN>来说，也就是输入是</span><span
style='font-weight:bold' lang=en-US>2</span><span style='font-weight:bold'
lang=zh-CN>维的，</span><span style='font-weight:bold' lang=en-US>shape<span
style='mso-spacerun:yes'>  </span>= batch_size, d</span><span style='font-weight:
bold' lang=zh-CN>，其中d是特征的个数，</span><span style='font-weight:bold' lang=en-US>Batchnorm1D</span><span
style='font-weight:bold' lang=zh-CN>是对每一列（每个特征）进行归一化，</span><span
style='font-weight:bold' lang=en-US>LayerNorm1D</span><span style='font-weight:
bold' lang=zh-CN>是对每一行（每个样本）进行归一化。</span></p>

<p style='margin:0in;font-family:微软雅黑;font-size:36.0pt'><span style='font-weight:
bold' lang=zh-CN>对于</span><span style='font-weight:bold' lang=en-US>NLP</span><span
style='font-weight:bold' lang=zh-CN>来说，特征的个数</span><span style='font-weight:
bold' lang=en-US>==token</span><span style='font-weight:bold' lang=zh-CN>的</span><span
style='font-weight:bold' lang=en-US>embedding</span><span style='font-weight:
bold' lang=zh-CN>的长度，一个样本</span><span style='font-weight:bold' lang=en-US>==</span><span
style='font-weight:bold' lang=zh-CN>一个</span><span style='font-weight:bold'
lang=en-US>token</span></p>

</div>

</div>

</div>

<div>

<p style='margin:0in'>&nbsp;</p>

<p style='text-align:left;margin:0in;font-family:Arial;font-size:9pt;
color:#969696;direction:ltr'>已使用 OneNote 创建。</p>

</div>

</body>

</html>
